---
layout: post
title: "Kalesha Bullard -- Learning through Interaction in Multi-Agent Systems"
---

{% include youtubePlayer.html yturl="https://www.youtube.com/watch?v=Em4rgAn9ecM" %}

## Bio

Kalesha Bullard is a postdoctoral researcher at Facebook AI Research. She completed her PhD in Computer Science at Georgia Institute of Technology in 2019, where her research lied at the intersection of human-robot interaction and machine learning, in interactive robot learning. During her postdoc, Kalesha has expanded her research to explore the space of multi-agent reinforcement learning, currently investigating how to enable embodied multi-agent populations to learn general communication protocols. More broadly, Kaleshaâ€™s research interests span the space of autonomous reasoning and decision making for artificial agents in multi-agent settings. To date, her research has focused on models and algorithms for enabling agents to learn through interaction with other agents (human or artificial). Kalesha has also participated in a number of service roles throughout her research career. She currently serves as a member of the organizing committee for the NeurIPS 2020 Workshop on Zero-Shot Emergent Communication and on the program committee for the NeurIPS 2020 Cooperative AI Workshop. And recent prior appointments include serving as an Area Chair for the 2019 NeurIPS Women in Machine Learning Workshop, a Program Committee (PC) member for the 2019 International Conference on Autonomous Agents and Multi-Agent Systems, and PC Co-Chair for the 2017 AAAI Fall Symposium on Artificial Intelligence for Human-Robot Interaction.

## Abstract

Effective communication is an important skill for enabling information exchange and cooperation in multi-agent settings. My talk will present research that investigates methods for enabling agents to learn to achieve shared goals through interactions with other agents. In particular, the talk will focus on my ongoing work within Multi-Agent Reinforcement Learning, on Emergent Communication for embodied agent populations. Indeed, emergent communication is now a vibrant field of research, with common settings involving discrete cheap-talk channels. One limitation of this setting is that it does not allow for the emergent protocols to generalize beyond the training partners. Furthermore, so far emergent communication has primarily focused on the use of symbolic channels (via discrete symbols, e.g. words). In the work presented, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a 3D simulated environment. We show that under realistic assumptions, a non-uniform distribution over intents and a common-knowledge energy cost, agents can learn communication protocols that generalize to novel partners. We also explore and analyze specific difficulties associated with finding globally optimal solutions in practice. Overall, while there are many interesting open challenges that remain, this work opens up exciting avenues for exploring continuous action communication protocols in virtually or physically embodied agents.
