---
layout: post
title: "Zhou Yu -- Building dialog systems with fewer data and less supervision"
---

{% include youtubePlayer.html yturl="https://www.youtube.com/watch?v=dFWkyhQNSuc" %}

## Bio

Zhou Yu joined the CS department at Columbia University in Jan 2021 as an Assistant Professor (http://www.cs.columbia.edu/~zhouyu/). Before that, she was an Assistant Professor at UC Davis. She obtained her Ph.D. from Carnegie Mellon University in 2017.  Zhou has built various dialog systems that have a real impact, such as a job interview training system, a depression screening system, and a second language learning system. Her research interest includes dialog systems, language understanding and generation, vision and language, human-computer interaction, and social robots. Zhou received an ACL 2019 best paper nomination, featured in Forbes 2018 30 under 30 in Science, and won the 2018 Amazon Alexa Prize.

## Abstract

Neural network-based models have shown good performance on various NLP tasks. However, they require a lot of data to train. Thus, how to train dialog models with fewer data and less supervision is a practical problem. This talk will introduce some work that utilizes meta-learning, semi-supervised learning, and zero-shot learning algorithms for task-oriented dialog system training.
