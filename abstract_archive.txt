{"data": [{"website": "https://www.cs.cmu.edu/~bdhingra/", "bio": "Bhuwan Dhingra is a final year PhD student at Carnegie Mellon University, advised by William Cohen and Ruslan Salakhutdinov. His research uses natural language processing and machine learning to build an interface between AI applications and world knowledge (facts about people, places and things). His work is supported by the Siemens FutureMakers PhD fellowship. Prior to joining CMU, Bhuwan completed his undergraduate studies at IIT Kanpur in 2013, and spent two years at Qualcomm Research in the beautiful city of San Diego.", "title": "Text as a Virtual Knowledge Base", "abstract": "Structured Knowledge Bases (KBs) are extremely useful for applications such as question answering and dialog, but are difficult to populate and maintain. People prefer expressing information in natural language, and hence text corpora, such as Wikipedia, contain more detailed up-to-date information. This raises the question -- can we directly treat text corpora as knowledge bases for extracting information on demand? In this talk I will focus on two problems related to this question. First, I will look at augmenting incomplete KBs with textual knowledge for question answering. I will describe a graph neural network model for processing heterogeneous data from the two sources. Next, I will describe a scalable approach for compositional reasoning over the contents of the text corpus, analogous to following a path of relations in a structured KB to answer multi-hop queries. I will conclude by discussing interesting future research directions in this domain.", "affiliation": "Carnegie Mellon University", "semester": "Fall", "speaker": "Bhuwan Dhingra", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-12-05", "video": "https://www.youtube.com/watch?v=0qaL7A7gM8U"}, {"website": "https://www.cc.gatech.edu/~dyang888/", "bio": "Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech, also affiliated with the Machine Learning Center (ML@GT) at Georgia Tech. Diyi received her PhD from the Language Technologies Institute at Carnegie Mellon University, and her bachelor's degree from Shanghai Jiao Tong University, China. She is interested in computational semantics of human language (such as text analysis, generation, discourse) and computational social science. She has published more than 40 papers at leading NLP/HCI conferences and journals, and received one Notable Dataset Award from EMNLP 2015, one Best Paper Award Nomination from ICWSM 2016, and two Best Paper Honorable Mentions from SIGCHI 2019. Diyi has been awarded Carnegie Mellon Presidential Fellowship and Facebook Ph.D. Fellowship.", "title": "Building Language Technologies for Better Online Communities", "abstract": "We live in an era where many aspects of our daily activities are recorded as textual and activity data, from social media posts, to medical and financial records, to work activities captured by Wikipedia and other online tools. My research combines techniques in natural language processing, machine learning and theories in social science to study human behavior in online communities, with the goal of developing theories and systems to build better socio-technical systems. In this talk, I will explain my research from two specific studies. The first one studies what makes language persuasive by introducing a simple semi-supervised neural network to recognize persuasion strategies in loan requests on crowdfunding platforms.  The second focuses on modeling how people seek and offer support via language in online cancer support communities and building interventions to support patient communication.  Through these two examples, I show how we can accurately and efficiently model human communication to build better social systems", "affiliation": "Georgia Tech", "semester": "Fall", "speaker": "Diyi Yang", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-21", "video": "https://www.youtube.com/watch?v=19UgKTd2rFA"}, {"website": "https://www.ri.cmu.edu/ri-people/yuxiong-wang/", "bio": "Yuxiong Wang is a postdoctoral fellow in the Robotics Institute at Carnegie Mellon University. He received a Ph.D. in robotics in 2018 from Carnegie Mellon University. His research interests lie in the intersection of computer vision, machine learning, and robotics, with a particular focus on few-shot learning and meta-learning. He has spent time at Facebook AI Research (FAIR).", "title": "Learning to Learn More with Less", "abstract": "Understanding how humans and machines learn from few examples remains a fundamental challenge. Humans are remarkably able to grasp a new concept from just few examples, or learn a new skill from just few trials. By contrast, state-of-the-art machine learning techniques typically require thousands of training examples and often break down if the training sample set is too small. In this talk, I will discuss our efforts towards endowing visual learning systems with few-shot learning ability. Our key insight is that the visual world is well structured and highly predictable not only in feature spaces but also in under-explored model and data spaces. Such structures and regularities enable the systems to learn how to learn new tasks rapidly by reusing previous experiences. I will focus on a few topics to demonstrate how to leverage this idea of learning to learn, or meta-learning, to address a broad range of few-shot learning tasks: meta-learning in model space and task-oriented generative modeling. I will also discuss some ongoing work towards building machines that are able to operate in highly dynamic and open environments, making intelligent and independent decisions based on insufficient information.", "affiliation": "FAIR", "semester": "Fall", "speaker": "Yuxiong Wang", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-20", "video": ""}, {"website": "https://sites.google.com/site/ssamadi/", "bio": "Samira Samadi is a Ph.D. candidate at the School of Computer Science, Georgia Tech where she works with Santosh Vempala. Prior to this, she was a research associate at the School of Computer Science at the University of Waterloo where she worked with Shai Ben-David. She received her M.Sc. in Computer Science from the University of British Columbia under the supervision of Nick Harvey and her B.Sc. in Mathematics at the Sharif University of Technology. Her primary research interests are in ethics in AI, machine learning, algorithms, and human computation.", "title": "Fair Machine Learning: PCA and Spectral Clustering", "abstract": "In this talk, I investigate several ML paradigms from the viewpoint of fairness. In the first line of work, I study fairness for Principal Component Analysis (PCA), one of the most commonly used dimensionality reduction techniques. I show on real-world data sets that PCA can inadvertently produce low-dimensional representations with different fidelity for two different demographics. This motivates our study of Fair PCA and more generally multi-criteria dimensionality reduction. I present an exact polynomial-time algorithm for Fair PCA when there are two demographics in the data and approximation algorithms for a broad class of multi-criteria dimensionality reduction when there are multiple demographic groups. In the second line of work, I study spectral clustering (SC) with the constraint that every demographic is proportionally represented in each cluster. We develop variants of both normalized and unnormalized constrained SC and show that they help find fairer clusterings on both synthetic and real data. We also provide a theoretical analysis of our algorithms on a natural variant of the stochastic block model, where the demographic groups have strong inter-group connectivity, but also exhibit a \u201cnatural\u201d clustering structure which is proportionally balanced. We prove that our algorithms can recover this underlying balanced clustering with high probability.", "affiliation": "Georgia Tech", "semester": "Fall", "speaker": "Samira Samadi", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-14", "video": "https://www.youtube.com/watch?v=drkJcv9WT6Y"}, {"website": "http://www.cs.columbia.edu/~vondrick/", "bio": "Carl Vondrick is an Assistant Professor of Computer Science at Columbia University. Previously, he was a research scientist at Google. He completed his Ph.D. at the Massachusetts Institute of Technology in 2017.", "title": "Learning from Unlabeled Video", "abstract": "I will discuss our research to use large amounts of unlabeled video in order to efficiently train models for visual recognition. Leveraging millions of videos, our work develops methods for machines to learn perception tasks such as anticipating human actions in the immediate future, tracking visual objects, and recognizing ambient sounds.  We show how to take advantage of the natural context available in video in order to learn without human supervision, for example through the natural synchronization of vision and sound, or the temporal coherence of motion and color.", "affiliation": "Columbia University.", "semester": "Fall", "speaker": "Carl Vondrick", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-06", "video": "https://www.youtube.com/watch?v=9aR0-mK1GhI"}, {"website": "https://ziw.mit.edu/", "bio": "Zi Wang is a Ph.D. candidate at MIT Computer Science and Artificial Intelligence Laboratory advised by Prof. Leslie Pack Kaelbling and Prof. Tomas Lozano-Perez. Her PhD research focuses on tackling problems related to robot learning, active learning for planning and Bayesian optimization. She received her M.S. degree in Electrical Engineering and Computer Science from MIT in Feb 2016 and B.Eng. degree in Computer Science and Technology from Tsinghua University in Jul 2014. Zi is a recipient of MIT Graduate Women of Excellence Award, Rising Star in EECS and Google Anita Borg Scholarship. While at MIT, she served as co-president of Graduate Women in Course 6 (EECS), co-organizer of the first Machine Learning Across MIT Retreat and research mentor for several undergraduate and MEng students.", "title": "Bayesian Optimization for Global Optimization of Expensive Black-box Functions", "abstract": "Many problems in areas ranging from finance and product design to engineering in general all boil down to the problem of optimizing expensive black-box functions. Bayesian optimization uses probabilistic methods to address this problem with assumptions usually expressed by a Gaussian process prior. Motivated by real-world applications in high-dimensional parameter-tuning problems for complex machine learning algorithms and expensive active learning problems in robotics, we study the theoretical understandings of Bayesian optimization, connections among existing methods, and develop efficient and provably correct Bayesian optimization methods for these applications. In this talk, I will give an in-depth tour of our study of Bayesian optimization on how to design a better data acquisition strategy, how to scale up the method to higher-dimensional and larger-scale data and how to analyze the sample complexity without assuming the full knowledge of the prior. Finally, I will also briefly show how we utilized some of these ideas to tackle problems in robot learning and planning for complex long-horizon problems.", "affiliation": "MIT", "semester": "Fall", "speaker": "Zi Wang", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-31", "video": "https://www.youtube.com/watch?v=Fufcr5As3AI"}, {"website": "https://www.cs.cornell.edu/~laurejt/", "bio": "Laure Thompson is a final-year Ph.D. candidate in Computer Science at Cornell University where she is advised by David Mimno. Her research interests are in the areas of natural language processing, machine learning, and digital humanities. Driven by humanistic applications, her work uses a wide range of cultural heritage corpora: from texts of science fiction novels and the Patrologia Graeca to images of avant-garde journals and engraved gemstones. Laure is a recipient of an NSF Graduate Research Fellowship and a COLING best paper award. She received her bachelor's degrees in computer science and electrical engineering with minors in mathematics and classical studies from the University of Washington in 2013.", "title": "Understanding and Directing What Models Learn", "abstract": "Machine learning and statistical methods, such as unsupervised semantic models, are popular and useful techniques for making massive digital collections more explorable and analyzable. But what underlying patterns do these models actually learn, and which patterns are they most likely to repeatedly learn? Moreover, how might we direct what these models learn so that they are useful to a wider range of scholarly inquiry? For example, while it might be useful to organize novels by authors, learning this structure is seldom useful when already known and can be problematic if it is mischaracterized as a cross-cutting pattern. In this talk, I will discuss my recent work on measuring and mitigating topic-metadata correlation in topic models. I will show how intentional data modification can make topics more cross-cutting, specific, and stable.", "affiliation": "Cornell University", "semester": "Fall", "speaker": "Laure Thompson", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-23", "video": "https://www.youtube.com/watch?v=_0NDe9EU88s"}, {"website": "https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Veronika.Thost", "bio": "Veronika is a Postdoctoral Researcher in the MIT-IBM Watson AI Lab at IBM Research, Cambridge, MA. Her work focuses on the combination of symbolic knowledge representations and reasoning with learning: on learning logical theories and to guide reasoning over such theories, and on how the information in knowledge graphs can be used as structured, external knowledge to support learning. Previously, Veronika worked as a Postdoctoral Researcher at TU Dresden, Germany, where she also received her Ph.D. in Computer Science in 2017. At that time, she worked on query answering over knowledge graphs, existential rules, and in description logics. Her work has been published at IJCAI, KR, ISWC, ESWC, KR, JWS, and TOCL", "title": "Knowledge Representations & Reasoning Meets Machine Learning", "abstract": "In many domains, there is structured knowledge which can be leveraged for reasoning in an informed way in order to obtain high quality answers. Symbolic approaches for knowledge representation and reasoning are less prominent today - mainly due to their lack of scalability - but their strength lies in the verifiable and interpretable reasoning that can be accomplished. In this talk, we present work about how symbolic knowledge representations and reasoning can be combined with machine learning. We will present new datasets to evaluate logical rule learning, show how reinforcement learning can support logical reasoning, and consider knowledge graphs as external information for learning (e.g., for recognizing textual entailment).", "affiliation": "", "semester": "Fall", "speaker": "Veronika Thost", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-16", "video": "https://www.youtube.com/watch?v=2lXEv2sph2I"}, {"website": "https://gvanhorn38.github.io/", "bio": "Grant is a postdoc at Cornell Lab of Ornithology. He earned his PhD at Caltech advised by Prof. Pietro Perona, and BS and MS degrees at UCSD advised by Prof. Serge Belongie. His research focuses on efficient dataset collection and fine-grained visual categorization, particularly for the natural world. He works closely with iNaturalist and the Cornell Lab of Ornithology where he puts his research into production.", "title": "Visipedia + iNaturalist: integrating machine learning into a naturalist community", "abstract": "iNaturalist is a community of over 2 million nature enthusiasts that share observations of the natural world. These observations consist of at least one photo, a GPS coordinate, and a taxonomic label from the tree of life. The iNaturalist community has recorded over 30 million observations of organisms from around the world. These recordings are exported to GBIF for scientists and conservationists to use in research and reports. As the iNaturalist community grows and the expertise becomes more diffuse, the need for automation becomes crucial for maintaining an engaging user experience and for ensuring the accuracy of data exported to GBIF. In this talk I will describe our work on learning the taxonomic identification skills of iNaturalist users, using these skills to assign taxonomic labels to images, and subsequently training computer vision systems on the resulting dataset. These computer vision systems can be accessed in the Apple App Store or Google Play Store in both the \u201ciNaturalist\u201d and \u201cSeek by iNaturalist\u201d apps as well as the iNaturalist website.", "affiliation": "", "semester": "Fall", "speaker": "Grant Van Horn", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-10", "video": "https://www.youtube.com/watch?v=KRTj3Xl6ldw"}, {"website": "https://www.cs.cmu.edu/~sprabhum/", "bio": "Shrimai is a second-year Ph.D. student at Language Technologies, School of Computer Science, Carnegie Mellon University. She is advised by\u00a0Prof. Alan W Black\u00a0and\u00a0Prof. Ruslan Salakhutdinov. She is broadly interested in natural language generation with special focus on style transfer and content transfer. During the course of her Ph.D., she has interned at Facebook AI Research and Microsoft Research.", "title": "Controlling style, content, and structure in natural language generation", "abstract": "The 21st century is witnessing a major shift in the way people interact with technology and Natural Language Generation (NLG) is playing a central role. The increasing ubiquity of computing technologies has led to situation-aware applications that are required to produce naturalistic (informative, coherent, and appropriate) outputs. But situation-aware NLG is hard. Devices must not only generate natural sentences - already a challenging task - but include ever more complex data as inputs, and sound more natural every year. How can we expect machines to understand this and make the right choice for what to say? Solving a problem like this requires tackling at least three core tasks of NLG. The first is content determination: the information to be conveyed. Next comes discourse planning: the structure that a document will take on when it is articulated, given the preceding context and the rhetorical intent of the speaker. And finally, lexicalization: the particular words and phrases that convey the content of a sentence with a particular style or tone, given the appropriate structure in the discourse context.", "affiliation": "Carnegie Mellon University", "semester": "Fall", "speaker": "Shrimai Prabhumoye", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-03", "video": "https://www.youtube.com/watch?v=p3XRBkvCUrg"}, {"website": "http://www.byronwallace.com/", "bio": "Byron Wallace is an assistant professor in the Khoury College of Computer Sciences at Northeastern University. He holds a PhD in Computer Science from Tufts University, where he was advised by Carla Brodley. He has previously held faculty positions at the University of Texas at Austin and at Brown University. His research is in machine learning and natural language processing, with an emphasis on their application in health informatics.  Wallace's work has been supported by grants from the National Science Foundation (including a CAREER award), the National Institutes for Health, and the Army Research Office. He won the Tufts University 2012 Outstanding Graduate Researcher award, and his thesis work was recognized as The Runner Up for the 2013 ACM Special Interest Group on Knowledge Discovery and Data Mining (SIG KDD) Dissertation Award. He co-authored the winning submission for the Health Care Data Analytics Challenge at the 2015 IEEE International Conference on Healthcare Informatics, and co-authored the 2017 Distinguished Clinical Research Informatics Paper Award winner at the American Medical Informatics Association Joint Summits on Translational Sciences. He also received the 2018 Early Career Award from the Society for Research Synthesis.", "title": "What does the evidence say? Models to help make sense of the biomedical literature", "abstract": "How do we know if a particular medical intervention actually works better than the alternatives for a given condition and outcome? Ideally one would consult all available evidence from relevant trials that have been conducted to answer this question. Unfortunately, such results are primarily disseminated in natural language articles that describe the conduct and results of clinical trials. This imposes substantial burden on physicians and other domain experts trying to make sense of the evidence. In this talk I will discuss work on designing tasks, corpora, and models that aim to realize natural language technologies that can extract key attributes of clinical trials from articles describing them, and infer the reported findings regarding these. The hope is to use such methods to help domain experts (such as physicians) access and make sense of unstructured biomedical evidence.  More specifically, I will discuss models to automatically extract trial population characteristics (e.g., conditions), interventions/comparators (treatments), and outcomes studied in a given clinical trial; together these \"PICO\" elements compose well-formed clinical questions. I will then present ongoing work on corpora and models for inferring the comparative effectiveness of a given treatment, as compared to a specified comparator, and with respect to a particular outcome of interest. If successfully realized (a big if), such models would effectively facilitate real-time clinical question answering over reports of clinical trials, in turn enabling evidence-based care", "affiliation": "Northeastern University", "semester": "Fall", "speaker": "Byron Wallace", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-09-26", "video": "https://www.youtube.com/watch?v=qsw5QPtEwiU"}, {"website": "", "bio": "Yoon Kim is a fifth-year Ph.D. candidate in computer science at Harvard University. He is advised by Alexander Rush. He is supported by a Google Fellowship.", "title": "Neural Grammar Induction", "abstract": "Grammar induction is the task of inducing hierarchical syntactic structure from observed sentences alone. It is a longstanding problem in AI/NLP with potential scientific implications for understanding human language acquisition and engineering implications for improving machine learning systems. In this talk, I will discuss two recent works on unsupervised grammar induction with neural networks: (1) a method for learning a good generative model of language (i.e. language model) while at the same time inducing linguistically meaningful tree structures; (2) an approach to learning non-context free grammars by revisiting and extending the classical approach to grammar induction with probabilistic context-free grammars.", "affiliation": "Harvard University", "semester": "Fall", "speaker": "Yoon Kim", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-09-19", "video": ""}, {"website": "", "bio": "Ehi Nosakhare is an AI Data Scientist at Microsoft's New England Research and Development Center (NERD). She designs, develops and leads the implementation of machine learning solutions in application projects for Microsoft's products and services. In August 2018, she earned her Ph.D. in Electrical Engineering and Computer Science (EECS) from the Massachusetts Institute of Technology (MIT), Cambridge, MA. Her PhD research focused on probabilistic latent variable models and applying them to understand subjective well-being. She is generally interested in developing interpretable ML models and using these models to solve real world problems, as a result, she is curious about the ethical implications of AI/ML. Ehi got her S.M. in EECS from MIT, and graduated with a B.Sc. in Electrical Engineering, summa cum laude, from Howard University, Washington DC. As a student, she completed internships at Microsoft and IBM T. J. Watson Research Center. She is a recipient of a best paper award at the NeurIPS ML for Healthcare Workshop. In 2017, she was an organizer for the Women in Machine Learning (WiML) workshop, co-located with NeurIPS. Ehi has been honored as a Tau Beta Pi Scholar and Fellow. In her spare time, she enjoys reading and re-learning to play the cello.  ", "title": "Probabilistic Latent Variable Modeling for Predicting Future Well-Being and Assessing Behavioral Influences on Stress", "abstract": "Health research has an increasing focus on promoting well-being and positive mental health, to prevent disease and to more effectively treat disorders. The availability of rich multi-modal datasets and advances in machine learning methods are now enabling data science research to begin to objectively assess well-being. However, most existing studies focus on detecting the current state or predicting the future state of well-being using stand-alone health behaviors. There is a need for methods that can handle a complex combination of health behaviors, as arise in real-world data. Building on our previous work where we predict future well-being, in this talk, I'll present a framework to 1) map multi-modal messy data collected in the \"wild\" to meaningful feature representations of health behavior, 2) uncover latent patterns comprising multiple health behaviors that best predict well-being, and 3) propose how these patterns may be used to recommend healthy behaviors to participants. We show how to use supervised latent Dirichlet allocation (sLDA) to model the observed behaviors, and we apply variational inference to uncover the latent patterns. Implementing and evaluating the model on 5,397 days of data from a group of 244 college students, we find that these latent patterns are indeed predictive of self-reported stress, one of the largest components affecting well-being. We investigate the modifiable behaviors present in these patterns and uncover some ways in which the factors work together to influence well-being. This work contributes a new method using objective data analysis to help individuals monitor their well-being using real-world measurements. Insights from this study advance scientific knowledge on how combinations of daily modifiable human behaviors relate to human well-being.", "affiliation": "Microsoft NERD", "semester": "Fall", "speaker": "Ehimwenma Nosakhare", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-09-12", "video": "https://www.youtube.com/watch?v=KiAtYSRmVog"}, {"website": "https://research.fb.com/people/roller-stephen/", "bio": "Stephen Roller is a Research Engineer at Facebook AI Research. His research focuses primarily on generation in neural dialogue agents. Before joining FAIR, Stephen completed his PhD at the University of Texas at Austin under the supervision of Katrin Erk, where his research focused primarily on hypernymy and lexical entailment. Stephen additionally completed part of studies as a visiting PhD student at the University of Stuttgart, where he researched multimodal lexical semantics under the supervision of Sabine Schulte im Walde.", "title": "ParlAI and Open-Domain Dialogue Research", "abstract": "We present ParlAI (pronounced \"parley\"), an all-in-one dialogue and chatbot research platform. ParlAI provides tools for all aspects of conversational research, including allowing one to develop novel models; train and test models on a wide variety of existing datasets; compare to standard baselines; collect rich new datasets and conduct human evaluations using Mechanical Turk, and deploy models to users over Facebook Messenger. We present two research projects built using ParlAI. The first paper we present, \"What Makes a Good Conversation?\", compares two methods for controllable text generation in neural sequence models, and applies them to chit chat. We consider four controllable variables for text, and provide a detailed analysis of their effects on high-level human judgements of conversational aspects. We show that by controlling combinations of these variables, our models demonstrate clear improvements in human quality judgements. The second paper we present, \"The Wizard of Wikipedia\", considers the expectation of users that chatbots should exhibit strong, open-domain factual world knowledge. We present a new dataset of conversations which contains explicit groundings in facts from Wikipedia. We propose novel models for integrating knowledge into conversations, and compare to standard \"generate and hope\" neural models. We show our models exhibit the ability to recall and incorporate factual knowledge, even when discussing previously unseen topics.", "affiliation": "FAIR, NY", "semester": "Spring", "speaker": "Stephen Roller", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-04-25", "video": ""}, {"website": "https://dylanfoster.net/", "bio": "Dylan Foster is a postdoctoral researcher at the MIT Institute for Foundations of Data Science. In 2018 he received his PhD in computer science at Cornell University, advised by Karthik Sridharan. His research focuses on theory for machine learning in real-world settings. He is particularly interested in all aspects of generalization theory and related algorithmic questions, particularly as it applies to interactive learning, deep learning, and non-convex optimization. Dylan previously received his BS and MS in Electrical Engineering from USC in 2014. He has received awards including the NDSEG PhD fellowship, Facebook PhD fellowship, and best student paper award at COLT 2018.", "title": "Logistic Regression: The Importance of Being Improper", "abstract": "Logistic regression is a fundamental task in machine learning and statistics. For the simple case of linear models, Hazan et al. (2014) showed that any logistic regression algorithm that estimates model weights from samples must exhibit exponential dependence on the weight magnitude. As an alternative, we explore a counterintuitive technique called improper learning, whereby one estimates a linear model by fitting a non-linear model. Past success stories for improper learning have focused on cases where it can improve computational complexity. Surprisingly, we show that for sample complexity (number of examples needed to achieve a desired accuracy level), improper learning leads to a doubly-exponential improvement in dependence on weight magnitude over estimation of model weights, and more broadly over any so-called \"proper\" learning algorithm. This provides a positive resolution to a COLT 2012 open problem of McMahan and Streeter. As a consequence of this improvement, we also resolve two open problems on the sample complexity of boosting and bandit multi-class classification.", "affiliation": "MIT", "semester": "Spring", "speaker": "Dylan Foster", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-04-18", "video": ""}, {"website": "https://christophriedl.net/", "bio": "Christoph Riedl is assistant professor for Information Systems at the D'Amore-McKim School of Business at Northeastern University. He holds a joint appointment with the Khoury College of Computer Sciences and is a core faculty member at the Network Science Institute. He is a fellow at the Institute for Quantitative Social Science (IQSS) at Harvard. He is recipient of a Young Investigator Award (YIP) from the Army Research Office (ARO) for his work on social networks in collaborative decision-making. Before joining Northeastern University he was a post-doctoral fellow at Harvard Business School and IQSS. He received a PhD in Information Systems from Technische Universitat Munchen (TUM), Germany in 2011, a MSc in Information Systems in 2007, and a BSc in Computer Science in 2006. His work has been funded by NSF, ARO, ONR, and DARPA, and has been published in leading journals including Science, Organization Science, Management Science, Information Systems Research, Academy of Management Discoveries, and the Journal of the Royal Society Interface.", "title": "Quantifying Reputation and Success in Art", "abstract": "In areas of human activity where performance is difficult to quantify in an objective fashion, reputation and networks of influence play a key role in determining access to resources and rewards. To understand the role of these factors, we reconstructed the exhibition history of half a million artists, mapping out the co-exhibition network that captures the movement of art between institutions. Centrality within this network captured institutional prestige, allowing us to explore the career trajectory of individual artists in terms of access to coveted institutions. Early access to prestigious central institutions offered life-long access to high-prestige venues and reduced dropout rate. By contrast, starting at the network periphery resulted in a high dropout rate, limiting access to central institutions. A Markov model predicts the career trajectory of individual artists and documents the strong path and history dependence of valuation in art.", "affiliation": "Northeastern University", "semester": "Spring", "speaker": "Christoph Riedl", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-04-11", "video": ""}, {"website": "http://nlp.seas.harvard.edu/rush.html", "bio": "Alexander \"Sasha\" Rush is an Assistant Professor at Harvard University, where he studies natural language processing and machine learning. Sasha received his PhD from MIT supervised by Michael Collins and was a postdoc at Facebook NY under Yann LeCun. His group supports open-source development, running several projects including OpenNMT. His research has received several best paper awards at NLP conferences, an NSF Career award, and faculty awards from Google, Facebook, and others. He is currently the senior program chair of ICLR 2019.", "title": "Controllable Text Generation with Deep Latent-Variable Models", "abstract": "Progress in deep learning has led to optimism for automatic text generation. Yet state-of-the-art systems still predict inaccurate output on a non-trivial percentage of examples. Lack of user control to correct these issues makes it difficult to deploy these models in real applications. In this talk, I will argue that discrete latent-variable models provide a natural declarative framework for more controllable text models. I will present two recent works exploring this theme: (1) a method for learning neural template models that can be adjusted directly by users; (2) a variational approach to soft attention that learns alignment as a latent variable. I will end by discussing research challenges for making it easy to design and fit these models for large scale applications.", "affiliation": "Harvard University", "semester": "Spring", "speaker": "Alexander Rush", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-04-04", "video": ""}, {"website": "http://swabhs.com/", "bio": "Swabha Swayamdipta is a PhD candidate at the Language Technologies Institute at Carnegie Mellon University (currently a visiting student at University of Washington). She works with Noah Smith and Chris Dyer on developing efficient algorithms for linguistic structured prediction, with a focus on incorporating syntactic inductive biases. Prior to joining her PhD program, she earned a Masters degree from Columbia University. She has done research internships at Google AI, New York and at Allen Institute of Artificial Intelligence in Seattle.", "title": "Learning Challenges in Natural Language Processing", "abstract": "As the availability of data for language learning grows, the role of linguistic structure is under scrutiny. At the same time, it is imperative to closely inspect patterns in data which might present loopholes for models to obtain high performance on benchmarks. In a two-part talk, I will address each of these challenges.| First, I will introduce the paradigm of scaffolded learning. Scaffolds enable us to leverage inductive biases from one structural source for prediction of a different, but related structure, using only as much supervision as is necessary. We show that the resulting representations achieve improved performance across a range of tasks, indicating that linguistic structure remains beneficial even with powerful deep learning architectures. In the second part of the talk, I will showcase some of the properties exhibited by NLP models in large data regimes. Even as these models report excellent performance, sometimes claimed to beat humans, a closer look reveals that predictions are not a result of complex reasoning, and the task is not being completed in a generalizable way. Instead, this success can be largely attributed to exploitation of some artifacts of annotation in the datasets. I will discuss some questions our finding raises, as well as directions for future work.", "affiliation": "CMU", "semester": "Spring", "speaker": "Swabha Swayampdipta", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-04-02", "video": ""}, {"website": "https://imisra.github.io/", "bio": "Ishan is a Research Scientist at Facebook AI Research. He graduated from Carnegie Mellon University where his PhD thesis was titled \"Visual Learning with Minimal Human Supervision\" and got the Runner Up SCS Distinguished Dissertation Award. This work was about learning recognition models with minimal supervision by exploring structure and biases in the labels (multi-task), classifiers (meta learning) and data (self supervision). His current research interests are in self supervised approaches, understanding vision and language models, and in compositional models for small sample learning.", "title": "Scaling Self-supervised Visual Representation Learning", "abstract": "Self-supervised learning aims to learn representations from the data itself without explicit manual supervision. Existing efforts ignore a crucial aspect of self-supervised learning - the ability to scale to large amount of data because self-supervision requires no manual labels. In this work, we revisit this principle and scale two popular self-supervised approaches to 100 million images. Scaling these methods also provides many interesting insights into the limitations of current self-supervised techniques and evaluations. We conclude that current self-supervised methods are not complex enough to take full advantage of large scale data and do not seem to learn effective high level semantic representations. Finally, we show how scaling current self-supervised methods provides state-of-the-art results that sometimes match or surpass supervised representations on tasks such as object detection, surface normal estimation and visual navigation.", "affiliation": "Facebook AI Research, NY", "semester": "Spring", "speaker": "Ishan Misra", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-03-28", "video": ""}, {"website": "http://www.cs.rpi.edu/~gittea/", "bio": "Alex Gittens is an assistant professor of computer science at Rensselaer Polytechnic Institute. He obtained his PhD in applied mathematics from CalTech in 2013, and BSes in mathematics and electrical engineering from the University of Houston. After his PhD, he joined the eBay machine learning research group, then the AMPLab (now the RISELab) at UC Berkeley, before joining RPI. His research interests lie at the intersection of randomized linear algebra and large-scale machine learning, in particular encompassing nonlinear and multilinear low-rank approximations; sketching for nonlinear and multilinear problems; and scalable and data-dependent kernel learning.", "title": "Intelligent Randomized Algorithms for the Low CP-Rank Tensor Approximation Problem", "abstract": "In the context of numerical linear algebra algorithms, where it is natural to sacrifice accuracy in return for quicker computation of solutions whose errors are only slightly larger than optimal, the time-accuracy tradeoff of randomized sketching has been well-characterized. Algorithms such as Blendenpik and LSRN have shown that carefully designed randomized algorithms can outperform industry standard linear algebra codes such as those provided in LAPACK. For numerical tensor algorithms, where the size of problems grow exponentially with the order of the tensor, it is even more desirable to use randomization. However, in this setting, the time-accuracy tradeoff of randomized sketching is more difficult to understand and exploit, as: (1) in the first place, tensor problems are non-convex, (2) the properties of the data change from iteration to iteration, and (3) straightforward applications of standard results on randomized sketching allow for the error to increase from iteration to iteration. On the other hand, the iterative nature of such algorithms opens up the opportunity to learn how to sketch more accurately in an online manner. In this talk we consider the problem of speeding up the computation of low CP-rank (canonical polyadic) approximations of tensors through regularized sketching. We establish for the first time a sublinear convergence rate to approximate critical points of the objective under standard conditions, and further provide algorithms that adaptively select the sketching and regularization rates.", "affiliation": "Rensselaer Polytechnic Institute", "semester": "Spring", "speaker": "Alex Gittens", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-03-07", "video": ""}, {"website": "https://www.uml.edu/sciences/computer-science/faculty/pourkamali-anaraki-farhad.aspx", "bio": "Farhad Pourkamali Anaraki is an Assistant Professor of Computer Science at UMass Lowell. He received his PhD from University of Colorado Boulder under the supervision of Prof. Stephen Becker in 2017. His current research focuses on theoretical foundations of modern data science, and developing efficient and robust machine learning algorithms. He also works on extending the use of machine learning algorithms to other domains, including \u00e5reliability analysis of critical infrastructures in Civil Engineering and advanced manufacturing in Mechanical Engineering.", "title": "Scalable and Robust Sparse Subspace Clustering", "abstract": "Sparse subspace clustering (SSC) is a popular method in machine learning and computer vision for clustering high-dimensional data points that lie near a union of low-dimensional linear or affine subspaces. Using a two-step approach, the first step involves representing each data point as a linear combination of all other data points, so-called self-expressiveness property, to form an undirected similarity graph. Spectral clustering is then applied to produce the final segmentation and infer the underlying subspaces. The sparse optimization program in the first step of SSC is typically solved by the alternating direction method of multipliers (ADMM) that scales cubically with the number of data points. In addition, the process of optimal parameter selection for ADMM requires a significantly increased amount of computational time. Orthogonal matching pursuit (OMP) has been used as a more efficient alternative; however, OMP is incapable of handling affine subspaces and the choice of sparsity parameter notably impacts the accuracy of SSC.", "affiliation": "UMass Lowell", "semester": "Spring", "speaker": "Farhad Pourkamali Anaraki", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-28", "video": ""}, {"website": "http://irenechen.net/", "bio": "Irene Chen is a PhD student at MIT in Electrical Engineering and Computer Science in the Clinical Machine Learning Group. Her research focuses on building machine learning methods that to advance knowledge in health care and fairness. Before MIT, she received her AB/SM from Harvard in Applied Math and Computational Engineering and worked at Dropbox for two years as a Data Scientist, Machine Learning Engineer, and Chief of Staff.", "title": "Why is my classifier discriminatory?", "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.", "affiliation": "MIT CSAIL", "semester": "Spring", "speaker": "Irene Chen", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-21", "video": "https://www.youtube.com/watch?v=gbvloQN2NiA"}, {"website": "https://people.cs.umass.edu/~pat/", "bio": "Patrick Verga is a final year PhD candidate in the College of Information and Computer Sciences at UMass Amherst, advised by Andrew McCallum. His research contributes to knowledge representation and reasoning, with a focus on large knowledge base construction from unstructured text, with applications to general domain, commonsense, and biomedicine. Pat previously interned at Google and the Chan Zuckerberg Initiative and received the best long paper award at EMNLP 2018. Over the past several years he has advised multiple M.S. and junior PhD students, resulting in published research in fine-grained entity typing, unsupervised parsing, and partially labeled named entity extraction. He holds M.S. and B.A degrees in computer science as well as a B.S. in neuroscience.", "title": "Neural Knowledge Representation and Reasoning", "abstract": "Making complex decisions in science, government policy, finance, and clinical treatments all require integrating and reasoning over disparate sources of information. While some decisions can be made from a single piece of evidence, others require considering information that exists outside of the current context. A long-term store of abstracted knowledge over related concepts can facilitate this type of reasoning, while also influencing interpretation as well as enhancing the acquisition of new knowledge. A symbolic graph over a fixed, human-defined schema encoding facts about entities and their relations is the predominant method of representing knowledge, but this method is brittle, lacks specificity, and is inevitably highly incomplete. On the other extreme, recent work on purely text based knowledge models lack abstractions necessary for complex reasoning. In this talk I will present a middle ground incorporating powerful neural network models with rich structured ontologies and unstructured raw text to improve the representations of entities and their relations. We first discuss our work on universal schema, a method for learning a latent schema over both existing structured resources and unstructured free text data, embedding them jointly within a shared semantic space. Next we inject additional hierarchical structure into the embedding space of concepts, resulting in more efficient statistical sharing amongst related concepts and improving accuracy in both fine-grained entity typing and linking. We then present initial work to represent knowledge in context, including a single model for extracting all entities and long-range relations simultaneously over full paragraphs while jointly linking these entities to a knowledge graph. Lastly, we propose future directions for representing knowledge in context by incorporating cognitive theories of human memory systems and discuss how these models can address longstanding shortcomings in knowledge representation.", "affiliation": "UMass, Amherst", "semester": "Spring", "speaker": "Patrick Verga", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-14", "video": "https://www.youtube.com/watch?v=BNQLWb4V7s0"}, {"website": "http://alanesuhr.com/", "bio": "Alane Suhr is a PhD student in the Computer Science department at Cornell University, focusing on building agents that understand natural language grounded in complex interactions. She is the recipient of an AI2 Key Scientific Challenges Award and a Microsoft Research Women's Fellowship, and is a National Science Foundation Graduate Research Fellow. She has received paper awards at ACL 2017 and NAACL 2018. Alane received a Bachelor's degree in Computer Science and Engineering from Ohio State University in 2016.", "title": "Modeling and Learning Agents that Understand Language in Context", "abstract": "The meaning of a natural language utterance is influenced by the context in which it occurs, including interaction history and situated context. I will discuss two recent projects in context-dependent natural language understanding for building natural language interfaces to databases and following sequences of instructions. In the first part, I will introduce a model for mapping from natural language to executable SQL queries in an interaction. To resolve the meaning of later utterances, the system must consider the interaction history, including previous user utterances and previously-generated queries. We show how using both implicit and explicit mechanisms for making use of interaction history allows the system to effectively generate context-dependent representations. In the second part, I will describe an approach to map sequences of natural language instructions to system actions that modify an environment, focusing on learning without direct supervision on action sequences. We introduce an exploration-based learning approach that effectively learns to compose system actions to carry out user instructions in context of the environment and interaction.", "affiliation": "Cornell University", "semester": "Spring", "speaker": "Alane Suhr", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-07", "video": ""}, {"website": "http://cs-people.bu.edu/sbargal/", "bio": "Sarah is a Postdoctoral Associate in the Image and Video Computing Group working with Prof. Stan Sclaroff and Prof. Kate Saenko. Sarah first joined the Image and Video Computing Group in 2013 where she then completed her PhD with Prof. Stan Sclaroff. She is a recipient of the IBM PhD Fellowship and the Hariri Graduate Fellowship. Her research interests lie in the intersection of Computer Vision and Machine Learning.", "title": "Grounding Deep Models of Visual Data", "abstract": "Deep models are state-of-the-art for many computer vision tasks including object classification, action recognition, and captioning. As Artificial Intelligence systems that utilize deep models are becoming ubiquitous, it is also becoming crucial to explain why they make certain decisions: Grounding model decisions. In this talk I will present: 1) Spatial Grounding for Improving Model Classification at Training Time. We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction. This approach penalizes neurons that are most relevant for model prediction. By dropping such high-saliency neurons, the network is forced to learn alternative paths in order to maintain loss minimization. We demonstrate better generalization ability, an increased utilization of network neurons, and a higher resilience to network compression. 2) Spatial Grounding for Improving Model Classification at Test Time. We propose Guided Zoom, an approach that utilizes spatial grounding to make more informed predictions at test time. Guided Zoom compares the evidence used to make a preliminary decision with the evidence of correctly classified training examples to ensure evidence/prediction consistency, otherwise refines the prediction. We demonstrate accuracy gains for fine-grained classification. 3) Spatiotemporal Grounding. We devise a formulation that simultaneously grounds evidence in space and time, in a single pass, using top-down saliency. We visualize the spatiotemporal cues that contribute to a deep recurrent neural network's classification/captioning output. Based on these spatiotemporal cues, we are able to localize segments within a video that correspond with a specific action, or phrase from a caption, without explicitly optimizing/training for these tasks.", "affiliation": "Boston University", "semester": "Spring", "speaker": "Sarah Adel Bargal", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-01-31", "video": ""}, {"website": "http://www.aolteanu.com/", "bio": "Alexandra Olteanu is a computational social science and social computing researcher. Currently, she is a Postdoctoral Researcher in the Fairness, Accountability, Transparency and Ethics (FATE) Group at Microsoft Research Montr\u00e9al (though she sits with Microsoft Research NYC). Prior to joining the FATE group, she was a Social Good Fellow at the IBM T.J. Watson Research Center, NY. She is interested in how data and methodological limitations delimit what we can learn from online social traces, and how we can make the systems that leverage such data safer, fairer, and generally less biased. The problems she tackles are often motivated by existing societal challenges such as hate speech, racial discrimination, climate change, and disaster relief. Her work has won two best paper awards (WISE 2014, Eurosys' SNS workshop 2012), and has been featured in the UN OCHA's \"World Humanitarian Data and Trends\" and in popular media outlets, including The Washington Post, VentureBeat, and ZDNet. More recently, she co-authored a survey of biases and methodological pitfalls when working with online social data, and has been co-organizing several tutorials on the topic at a variety of major data mining, and web and social media conferences, including ICWSM, KDD, WSDM, WWW, and SDM. She has also served on the program committees of the main social media and web conferences, including ICWSM, WWW, WebSci, CIKM, and SIGIR, on the steering committee of the new ACM Conference on Fairness, Accountability, and Transparency (FAT*), and as the Tutorial Co-chair for ICWSM 2018 and FAT* 2018. Alexandra holds a PhD (2016) from \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland. She draws her experience from academic institutions and research labs across 5 different countries.", "title": "Social Data: Biases, Methodological Pitfalls, and Social Good Applications", "abstract": "Data-driven computational systems and studies already make assessments about the physical or mental health of individuals, or about their personality or political views, in order to drive policies, to change behaviors, to shape products and services, and for automated decision making. An important source of data for many of these systems are the ever-growing datasets of online user traces, which promise to offer captivating insights into human phenomena. Alas, some of these systems and studies conjecture that such social datasets are adequate, often as-is, for the problem at hand, with little or no scrutiny. Yet, this is rarely the case.  In this talk, we will challenge such adequacy assumptions, and cover several types of biases and limits that surface when leveraging social datasets, related to both the characteristics of these datasets, as well as of the methods for acquiring and analyzing them. I will focus on identifying, quantifying, or minimizing such risks. Understanding these risks is particularly important when tackling significant societal challenges, where the dichotomy between maximizing benefits and minimizing risks is often more palpable. Thus, I will ground our discussion in several social good applications, such as humanitarian crises, news coverage of climate change, minority issues and advocacy, hate speech, and health. I will also overview domain specific insights to showcase the potential benefits of such applications.", "affiliation": "Microsoft Research Montr\u00e9al", "semester": "Fall", "speaker": "Alexandra Olteanu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-11-28", "video": ""}, {"website": "https://sroy9.github.io/", "bio": "Subhro is a Postdoctoral Associate at the Computer Science and AI Laboratory (CSAIL) at MIT working with Prof. Nicholas Roy. His research focuses on grounding natural language instructions and commonsense knowledge acquisition; aimed towards capable service robots that interact seamlessly with humans. His research contributes towards programs funded by the US Army Research Labs and the Toyota Research Institute. Subhro obtained his Ph.D. at the University of Illinois, Urbana Champaign, advised by Prof. Dan Roth. His doctoral research focused on models for automated numeric reasoning and word problem solving. His research led to the development of several top performing word problem solvers and the MAWPS system for standardizing datasets and evaluation in the area. His work has been published in TACL, EMNLP, NAACL, AAAI, CoRL and ISER. Subhro obtained his B. Tech. degree at the Indian Institute of Technology (IIT) Kharagpur.", "title": "Towards Natural Human Robot Communication", "abstract": "Robots are becoming more and more popular with the rise of self driving cars, autonomous drones, and warehouse automation. However, they still require experts to set up the goals for the task, and are usually devoid of a high level understanding of its environment. Language can address these issues. Non expert users can seamlessly instruct robots using natural language commands. Linguistic resources can be used to extract knowledge about the world, which can be distilled into actionable intelligence. In this talk, I will describe some of our recent work in this direction. The first focuses on robust referring expression grounding, allowing users to describe commands involving objects in the environment. The second focuses on grounding high level instructions using background knowledge from WikiHow, Conceptnet and Wordnet. I will conclude by describing some of our ongoing work in acquiring commonsense knowledge for household robots.", "affiliation": "MIT", "semester": "Fall", "speaker": "Subhro Roy", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-11-08", "video": ""}, {"website": "https://cs.brown.edu/people/epavlick/", "bio": "Ellie Pavlick is an Assistant Professor of Computer Science and Brown University and a Research Scientist at Google AI. Ellie received her PhD from University of Pennsylvania under the supervision of Chris Callison-Burch. Her current research focus is on semantics, pragmatics, and building cognitively-plausible computational models of natural language inference.", "title": "Why should we care about linguistics?", "abstract": "In just the past few months, a flurry of adversarial studies have pushed back on the apparent progress of neural networks, with multiple analyses suggesting that deep models of text fail to capture even basic properties of language, such as negation, word order, and compositionality. Alongside this wave of negative results, our field has stated ambitions to move beyond task-specific models and toward \"general purpose\" word, sentence, and even document embeddings. This is a tall order for the field of NLP, and, I argue, marks a significant shift in the way we approach our research. I will discuss what we can learn from the field of linguistics about the challenges of codifying all of language in a \"general purpose\" way. Then, more importantly, I will discuss what we cannot learn from linguistics. I will argue that the state-of-the-art of NLP research is operating close to the limits of what we know about natural language semantics, both within our field and outside it. I will conclude with thoughts on why this opens opportunities for NLP to advance both technology and basic science as it relates to language, and the implications for the way we should conduct empirical research.", "affiliation": "Brown University", "semester": "Fall", "speaker": "Ellie Pavlick", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-24", "video": "https://www.youtube.com/watch?v=PDi1z9sb_Z0"}, {"website": "http://people.dbmi.columbia.edu/noemie/", "bio": "Noemie Elhadad is an Associate Professor in Biomedical Informatics, affiliated with Computer Science and the Data Science Institute at Columbia University. Her research is at the intersection of computation, technology, and medicine with a focus on machine learning for healthcare and natural language processing of clinical and health texts. Her work is funded by the National Science Foundation, the National Library of Medicine, the National Cancer Institute, and the National Institute for General Medical Sciences.", "title": "Phenotyping Endometriosis through Mixed Membership Models of Self-Tracking Data", "abstract": "Despite the impressive past and recent advances in medical sciences, there are still a host of chronic conditions which are not well understood and lack even consensus description of their signs and symptoms. Without such consensus, research for precise treatments and ultimately a cure is at a halt. Phenotyping these conditions, that is, systematically characterizing the signs, symptoms and other aspects of these conditions, is thus particularly needed. Computational phenotyping can help identify cohorts of patients at scale and identify potential sub-groups, thus generating new hypotheses for these mysterious conditions. While traditional phenotyping algorithms rely on clinical documentation and expert knowledge, phenotyping for enigmatic conditions might benefit from patient expertise as well. In this talk I will focus on one such enigmatic condition, endometriosis, a chronic condition estimated to affect 10% of women in reproductive age. I will describe approaches needed to phenotype the condition: eliciting dimensions of disease, engaging patients in self-tracking their condition, and discovering phenotypes and sub-phenotypes of endometriosis based on patients' accounts of the disease.", "affiliation": "Columbia University", "semester": "Fall", "speaker": "No\u00e9mie Elhadad", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-18", "video": ""}, {"website": "https://www.fredjo.com/", "bio": "Fredrik Johansson is a postdoctoral associate in David Sontag's Clinical Machine Learning Group at MIT. He completed his Ph.D. at Chalmers University of Technology, Sweden in 2017, working on machine learning methods for network data. His current research is focused on theory and methodology for estimating causal effects and learning policies from observational data, often inspired by problems in the medical domain.", "title": "Estimating Causal Effects from High-Dimensional Observational Data", "abstract": "Everyone wants to make better decisions. The impact of a decision on an outcome of interest is called a causal effect, and is traditionally estimated by performing randomized experiments. However, large data sources such as electronic medical records or insurance claims present opportunities to study causal effects of interventions that are difficult to evaluate through experiments. One example is the management of septic patients in the ICU. This typically involves performing several interventions in sequence, the choice of one depending on the outcome of others. Successfully evaluating the effect of these choices depends on strong assumptions, such as having adjusted for all confounding variables. While many argue that having high-dimensional data increases the likelihood of this assumption being true, it also introduces new challenges: the more variables we use for estimating effects, the less likely that patients who received different treatments are similar in all of them. In this talk, we will discuss causal effect estimation and treatment group overlap through the lens of domain adaptation and off-policy reinforcement learning. We will introduce the potential outcomes framework, classical methods for estimating causal effects, as well as new ones, tailored for working with large datasets.", "affiliation": "MIT", "semester": "Fall", "speaker": "Fredrik Johansson", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-11", "video": ""}, {"website": "https://people.csail.mit.edu/junyanz/", "bio": "Jun-Yan Zhu is a postdoctoral researcher at MIT CSAIL. He obtained his Ph.D. in Electrical Engineering and Computer Sciences from UC Berkeley in 2017 after spending five years at CMU and UC Berkeley. He received his B.E in Computer Sciences from Tsinghua University in 2012. His research interests are in computer vision, computer graphics, and machine learning, with the goal of building machines capable of understanding and recreating our visual world. His Ph.D. work was supported by a Facebook Fellowship. His dissertation won the 2018 ACM SIGGRAPH Outstanding Doctoral Dissertation Award from SIGGRAPH and 2017-18 David J. Sakrison Memorial Prize for outstanding doctoral research from the UC Berkeley EECS Department. He has served as a Technical Paper Committee member at SIGGRAPH Asia 2018 and a guest editor of International Journal of Computer Vision.", "title": "Learning to Generate Images", "abstract": "Deep learning has revolutionized the field of visual recognition. Since 2012, we witnessed an enormous jump in recognition performance on the standard benchmarks as well as many real-world applications. Meantime, many people in computer vision and graphics were wondering if deep learning can help visual synthesis. Unfortunately, it turned out that using deep neural networks to generate high-dimensional data such as images was extremely difficult. In this talk, I will discuss its main challenges and present a few end-to-end learning frameworks (e.g., pix2pix, CycleGAN, pix2pixHD) for generating and manipulating natural images. Then, I will show various applications such as generating synthetic training data (computer vision), photo manipulation and synthesis (computer graphics), converting MRIs into CT scans (medical imaging), and applications in NLP and speech synthesis. Finally, I will briefly discuss our ongoing efforts on learning to synthesize 3D textured objects and high-res videos, with the ultimate goal of recreating our visual world.", "affiliation": "MIT", "semester": "Fall", "speaker": "Jun-Yan Zhu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-04", "video": "https://www.youtube.com/watch?v=0jVcWgTxfTc"}, {"website": "http://www.cs.uml.edu/~arogers/", "bio": "Anna is a post-doctoral associate in the Computer Science Department at Text Machine lab, University of Massachusetts (Lowell). She works at the intersection of linguistics, natural language processing, and machine learning. She holds a Ph.D. degree from the Department of Language and Information Sciences at the University of Tokyo (Japan). Her current research focuses on interpretability of deep learning, evaluation of distributional meaning representations, and semantic compositionality. She also leads annotation projects for sentiment analysis and temporal reasoning. ", "title": "What's in your embedding, and how it predicts task performance", "abstract": "Word embeddings are the most widely used kind of distributional meaning representations in both industrial and academic NLP systems, and they can make dramatic difference in the performance of the system. However, the absence of a reliable intrinsic evaluation metric makes it hard to choose between dozens of models and their parameters. This work presents Linguistic Diagnostics (LD), a new methodology for evaluation, error analysis and development of word embedding models that is implemented in an open-source Python library. In a large-scale experiment with 14 datasets LD successfully highlights the differences in the output of GloVe and word2vec algorithms that correlate with their performance on different NLP tasks.", "affiliation": "UMass Lowell", "semester": "Fall", "speaker": "Anna Rogers", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-27", "video": "https://www.youtube.com/watch?v=heKsgZSOB1Q"}, {"website": "https://mymakar.github.io/", "bio": "Maggie Makar is a graduate student at CSAIL, MIT. She works on developing models and inference tools to analyze interaction data (e.g., interactions on social networks and diffusion of contagions). She focuses on untangling causal mechanisms that govern diffusion dynamics and quantifying heterogeneous effects of interventions in connected communities. She received her BA in Mathematics and Economics from the University of Massachusetts in Amherst.", "title": "Spread of contagions in the presence of latent spreaders: identifying hidden culprits and learning the probability of infection", "abstract": "When an infection spreads in a community, an individual's probability of becoming infected depends on both her susceptibility and exposure to the contagion through contact with others. While one often has knowledge regarding an individual's susceptibility, in many cases, whether or not an individual's contacts are contagious is unknown. We study the problem of predicting if an individual will adopt a contagion in the presence of multiple modes of infection (exposure/susceptibility) and latent neighbor influence. We present a generative probabilistic model and a variational inference method to learn the parameters of our model. Through a series of experiments on synthetic data, we measure the ability of the proposed model to identify latent spreaders, and predict the risk of infection. Applied to a real dataset of 20 thousand hospital patients, we demonstrate the utility of our model in predicting the onset of a healthcare associated infection using patient room-sharing and nurse-sharing networks. Our model outperforms existing benchmarks and provides actionable insights for the design and implementation of targeted interventions to curb the spread of the infection.", "affiliation": "MIT", "semester": "Fall", "speaker": "Maggie Makar", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-20", "video": "https://www.youtube.com/watch?v=MhQ7iOlT4aE"}, {"website": "https://www.eecs.tufts.edu/~liulp/", "bio": "Liping Liu holds the position of \"The Schwartz Family Assistant Professor'' at Tufts University. His research interests include variational inference, generative models, and embedding models. Prior to joining Tufts, Liu worked as a postdoctoral associate at Columbia University. Advised by Prof. David Blei, he worked on probabilistic embedding models. He earned his doctorate degree at Oregon State University, where he studied probabilistic models and applied these techniques to ecology studies. He also has industry experiences at IBM T.J. Watson Research and Alibaba. He is a reviewer for main machine learning conferences and journals, such as ICML, NIPS, ICLR, AISTATS, JMLR, and TPAMI.", "title": "Embedding: Choose Right Relations to Embed", "abstract": "Word embeddings are a widely-used tool to analyze language. Exponential family embeddings generalize the technique to other types of data by modeling the conditional probability of a target observation (a word or an item) conditioned on the elements in the context (other words or items). One challenge to fitting embedding methods is sparse data, such as a document/term matrix that contains many zeros. We develop zero-inflated embeddings to address this issue. In a zero-inflated embedding (ZIE), a zero in the data can come from an interaction to other data (i.e., an embedding) or from a separate process by which many observations are equal to zero (i.e. a probability mass at zero). Fitting a ZIE naturally down-weights the zeros and dampens their influence on the model. Another challenge is that the appear-to-be context often contains unrelated items. The embedding model considering all context elements will encode noisy co-occurrences as item relations in the embedding. We improve the quality of the embedding representations by choosing a subset of context elements for the embedding model. We develop a probabilistic attention model and use amortized variational inference to automatically choose this subset. ", "affiliation": "Tufts", "semester": "Fall", "speaker": "Liping Liu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-13", "video": "https://www.youtube.com/watch?v=hJ8TE5zudUw"}, {"website": "https://people.csail.mit.edu/peterkty/", "bio": "Peter K.T. Yu received the degrees of B.S. in Computer Science from National Chiao-Tung University, Hsinchu, Taiwan, in 2010, and M.S. in Computer Science from National Taiwan University, Taipei, Taiwan, in 2012. He is currently a Ph.D. candidate of Electrical Engineering and Computer Science at Massachusetts Institute of Technology under the supervision of Prof. Alberto Rodriguez in the Manipulation and Mechanisms Lab. He focuses on state estimation involving contact to enable reactive control in contact manipulation tasks.", "title": "Robot Perception for Manipulation", "abstract": "Our team (MIT MCube Lab) participated in Amazon Robotics Challenge (ARC) in 2015 - 2017, and won the stowing task in 2017. The challenge was to develop a fully autonomous system to pick and place products in a warehouse setting, where various products may coexist inside a single bin. Robots are still far from achieving human speed, flexibility, and reliability. In the first half of the talk, I will describe our approach to the ARC, list the lessons we have learned, and then propose our wish list regarding technologies that will be useful for developing similar systems in the future.  One major item in the wish list is to exploit physics and contact sensing in the perception system, where vision usually plays a big role but is still insufficient in practice. This can be due to occlusions, inaccurate models, ambiguous appearances, etc. I will spend the second half of the talk on our effort on using tactile sensing to estimate the pose of an object in realtime. I will draw the connections between our problem and mobile robot localization problem and show how we can apply frameworks developed in the localization community. Our results show that incorporating extra information can improve the accuracy from vision alone. Moreover, even when visual cues are temporarily missing, our system can still reason about the object state during manipulation. ", "affiliation": "MIT", "semester": "Spring", "speaker": "Peter Yu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-04-26", "video": ""}, {"website": "http://info.dqyi.org/", "bio": "Daqing Yi is a postdoctoral researcher working with Prof. Siddhartha Srinivasa in the Personal Robotics Lab at the University of Washington. He received his Ph.D. in Computer Science under the supervision of Prof. Michael Goodrich at Brigham Young University. He works at the intersection of robotics and interactive machine intelligence. He focuses on algorithms that bootstrap robot understanding from interaction with humans, and efficiently generate robust actions in collaborating with humans. He has received a Best Conference Paper Award from the IEEE International Conference on System, Man, and Cybernetics.", "title": "Bridging probabilistic inference and motion planning with Markov Chain Monte Carlo", "abstract": "Probabilistic models have been powerful tools in modeling problems in artificial intelligence. It encodes uncertain/unknown components into stochastic substructure that works with deterministic substructure in inference problems. Markov Chain Monte Carlo (MCMC) methods follow simple designs and efficiently generate random samples that approximate a target distribution. It can provide answers to the stochastic substructure in an inference problem, which inspires us to introduce MCMC to motion planning problems.  In this talk, I will describe informed sampling methods that use MCMC in solving optimal kinodynamic motion-planning problems. Our proposed MCMC approach efficiently samples from an informed set, especially when the dimension is high and the volume of informed set gradually decreases. I will also describe how we introduce MCMC methods by directly sampling over \u201cunknown\u201d Pareto fronts in trajectory spaces. The sampled trajectories gradually converge to Pareto optimal solutions of a multi-objective motion planning problem. ", "affiliation": "UW", "semester": "Spring", "speaker": "Daqing Yi", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-04-19", "video": ""}, {"website": "https://maithraraghu.com/", "bio": "Maithra Raghu is a PhD student at Cornell, working with Jon Kleinberg, and a research resident at Google Brain. Her research interests are broadly in developing a better understanding of latent representations learned by deep neural networks, and using these insights to help guide new improvements. ", "title": "Insights from Deep Representations", "abstract": "To continue the successes of deep learning, it becomes increasingly important to better understand the phenomena exhibited by these models, ideally through a combination of systematic experiments and theory. Central to this challenge is a better understanding of deep representations. In this talk I discuss some of our work addressing questions in this space. I overview our development of measures of neural network expressivity, and quantify and empirically measure the effect of network depth and width on the latent representations. I then describe adapting Canonical Correlation Analysis (SVCCA) as a tool to directly compare latent representations, across layers, training steps, and even different networks. The results show differences in per-layer convergence and also help identify parts of the representation critical to the task. Finally, I introduce a new testbed of environments for Deep Reinforcement Learning that lets us study different RL algorithms, single agent, multiagent and self play settings, and evaluate generalization in a systematic way. ", "affiliation": "Cornell", "semester": "Spring", "speaker": "Maithra Raghu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-04-10", "video": "https://www.youtube.com/watch?v=gCia3v5Niig"}, {"website": "http://maja-rita-rudolph.com/", "bio": "As a computer science PhD student at Columbia University, Maja Rudolph studies probabilistic modeling and approximate inference. Together with her advisor David Blei, she works on embedding models and explores how they can be used to find rich, interpretable structure in large data sets. In 2013, she obtained a BS in mathematics from MIT. www.maja-rita-rudolph.com", "title": "Exponential Family Embeddings", "abstract": "Word embeddings are a powerful approach for capturing semantic similarity among terms in a vocabulary. Exponential family embeddings extend the idea of word embeddings to other types of high-dimensional data such as count data from a recommendation system or real-valued data from neural recordings. Exponential family embeddings have three ingredients; embeddings as latent variables, a predefined conditioning set for each observation called the context, and a conditional likelihood from the exponential family. The embeddings are inferred with a scalable algorithm based on stochastic gradient descent. In this talk, I discuss three highlights of the exponential family embeddings model class: (A) The approximations used for existing methods such as word2vec can be understood as a biased stochastic gradients procedure on a specific type of exponential family embedding model. (B) By choosing different likelihoods from the exponential family we can generalize the task of learning distributed representations to different application domains. (C) Finally, the probabilistic modeling perspective allows us to incorporate structure and domain knowledge in the latent space. With dynamic embeddings, we can study how word usage changes over time and structured embeddings allow us to learn embeddings that vary across related groups of data. Key to the success of our method is that the groups share statistical information and we develop three sharing strategies: dynamic modeling, hierarchical modeling, and amortization.", "affiliation": "Columbia", "semester": "Spring", "speaker": "Maja Rudolph", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-03-29", "video": ""}, {"website": "https://people.cs.umass.edu/~pthomas/", "bio": "I study a branch of artificial intelligence (AI) called reinforcement learning (RL). I am currently co-directing the Autonomous Learning Lab (ALL) at UMass Amherst with Sridhar Mahadevan. Before that I worked as a postdoc for Emma Brunskill at CMU. I completed my Ph.D. in computer science at UMass Amherst in 2015, where Andrew Barto was my adviser. I completed my B.S. and M.S. in computer science at CWRU in 2008 and 2009, where Michael Branicky was my adviser. Before that, in high school, I was introduced to computer science and mentored by David Kosbie.", "title": "New and Old Concentration Inequalities", "abstract": "In this talk I will review Hoeffding's inequality before presenting some other old and new concentration inequalities, including a strict improvement on Hoeffding's inequality (for identically distributed random variables) and a concentration inequality for conditional value at risk (CVaR).", "affiliation": "UMass", "semester": "Spring", "speaker": "Phil Thomas", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-03-22", "video": ""}, {"website": "https://jerryzli.github.io/", "bio": "Jerry Li is a Ph.D student in CSAIL, working with Ankur Moitra. His main research interests are in developing theoretically sound machine learning algorithms for real world modern systems. So far this has lead to the study of provably secure machine learning, and the study of distributed and massively parallel learning algorithms. For his research, he has been awarded a Simons Fellowship and an NSF Fellowship. ", "title": "Mixture Models, Robustness, and Sum-of-Squares Proofs", "abstract": "We use the Sum of Squares (SoS) method to develop a new efficient algorithm for clustering and mean estimation in well-separated high-dimensional mixture models, substantially improving upon the statistical guarantees achieved by previous efficient algorithms. In particular, we study mixtures of k distributions, where every pair of distributions has means separated by at least k^epsilon for any epsilon > 0. In the special case of spherical Gaussian mixtures, we give a k^O(1/epsilon^2)-time algorithm that learns the means of the components in the mixture and accurately clusters samples from the mixture. This is the first algorithm to improve on greedy (\u201csingle-linkage\u201d) and spectral clustering, breaking a long-standing barrier for efficient algorithms at separation k^1/4.  Our techniques are based on adapting algorithmic ideas from robust statistics, and are potentially of independent interest. Our main algorithm for learning mixture models provides an entirely SoS interpretation of the convex programming framework of [Diakonikolas et al, FOCS 16]. We show that many of the proofs from that paper can be replaced with much simpler proofs using only basic concentration and Holder's inequality, which allows us to approach this problem via SoS. As a corollary of this, we also obtain improved rates for robust mean estimation in certain regimes.  Joint work with Sam Hopkins, Cornell.", "affiliation": "MIT", "semester": "Spring", "speaker": "Jerry Li", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-03-08", "video": ""}, {"website": "https://www.cs.cmu.edu/~ytsvetko/", "bio": "TBA", "title": "TBA", "abstract": "TBA", "affiliation": "CMU", "semester": "Spring", "speaker": "Yulia Tsvetkov", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-03-01", "video": ""}, {"website": "http://www.cs.bc.edu/~tassarot/", "bio": "Joseph Tassarotti is a fifth year PhD student in the Computer Science Department at Carnegie Mellon University, advised by Robert Harper. His dissertation work is on the formal verification of concurrent randomized algorithms, and he is interested in the use of these algorithms in scalable machine learning systems. Joseph is the recipient of an NDSEG fellowship, and he earned an A.B. in Computer Science from Harvard College in 2013.", "title": "Hashing and Sketching for Latent Dirichlet-Categorical Models", "abstract": "When scaling up and streaming statistical inference algorithms one immediately runs into two issues: merging distributed inference results and coping with unbounded data. In this talk, we discuss how to tackle these problems by employing feature hashing, sketching, and approximate counters to represent the model's sufficient statistics. We provide novel approximation bounds for algorithms that combine count-min sketch with approximate counters and support a merge operation. Finally, we show that combining these approximations yields a distributed inference algorithm that produces the same quality approximation, but with less than a quarter of the memory. ", "affiliation": "Oracle", "semester": "Spring", "speaker": "Joseph Tassarotti", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-22", "video": ""}, {"website": "https://adjidieng.github.io/", "bio": "Adji Bousso Dieng is a PhD student at Columbia University where she works with David Blei and John Paisley. Her work at Columbia is about combining probabilistic graphical modeling and deep learning to design better sequence models. She develops these models within the framework of variational inference which enables efficient and scalable learning. Her hope is that her research can be applied to many real world applications particularly to natural language understanding.  Prior to joining Columbia, she worked as a Junior Professional Associate at the World Bank. She did her undergraduate training in France where she attended Lycee Henri IV and Telecom ParisTech---France's Grandes Ecoles system. She holds a Diplome d'Ingenieur from Telecom ParisTech and spent the third year of Telecom ParisTech's curriculum at Cornell University where she earned a Master in Statistics.  Learn more on her homepage http://stat.columbia.edu/~diengadji/ ", "title": "Deep Sequence Models: Context Representation, Regularization, and Application to Language", "abstract": "Recurrent Neural Networks (RNNs) are the most successful models for sequential data. They have achieved state-of-the-art results in many tasks including language modeling, image and text generation, speech recognition, and machine translation. Despite all these successes, RNNs still face some challenges: they fail to capture long-term dependencies (don't believe the myth that they do!) and they easily overfit.  The ability to capture long-term dependencies in sequential data depends on the way context is represented. Theoretically, RNNs capture all the dependencies in the sequence via the use of recurrence and parameter sharing. However practically, RNNs face optimization issues. Assumptions made to counter these optimization challenges hinder the capability of RNNs to capture long-term dependencies. On the other hand, the overfitting problem of RNNs stem from the strong dependence of the hidden units to each other.  I will talk about my research on context representation and regularization for RNNs. First, I will make the case that in the context of language, topic models are very effective at representing context and can be used jointly with RNNs to facilitate learning and capture long-term dependencies. Second, I will discuss our new proposed method to regularize RNNs called NOISIN. NOISIN relies on the concept of unbiased noise injection in the hidden units of RNNs to reduce co-adaptation. It significantly improves the generalization capabilities of existing RNN-based models including RNNs with dropout. ", "affiliation": "Columbia", "semester": "Spring", "speaker": "Adji Dieng", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-15", "video": "https://www.youtube.com/watch?v=0nj1hD4-9gE"}, {"website": "http://home.bharathh.info/", "bio": "Bharath Hariharan is an assistant professor at Cornell. Before joining Cornell, he spent two years as a postdoc in Facebook AI Research after obtaining a PhD from UC Berkeley with Jitendra Malik. At Berkeley, he was the recepient of the Microsoft Research fellowship. His interests are in all things visual recognition. Of late, he has become bothered by the reliance on massive labeled datasets and the scalability of such datasets to harder problems such as visual reasoning. His current work is on building recognition systems that learn with less data and / or output a much deeper understanding of images.", "title": "Visual recognition beyond large labeled training sets", "abstract": "The performance of recognition systems has grown by leaps and bounds these last 5 years. However, modern recognition systems still require thousands of examples per class to train. Furthermore, expanding the capabilities of the system by introducing new visual concepts again requires collecting thousands of examples for the new concept. In contrast, humans are known to quickly learn new visual concepts from as few as 1 example, and indeed require very little labeled data to build their powerful visual systems from scratch. The requirement for large training sets also makes it infeasible to use current machine vision systems for rare or hard-to-annotate visual concepts or new imaging modalities.  I will talk about some of our work on reducing this need for large labeled training sets. I will describe novel loss functions for training convolutional network-based feature representations so that new concepts can be learned from a few examples, and ways of hallucinating additional examples for data-starved classes. I will also discuss our attempt to learn feature representations without any labeled data by leveraging motion-based grouping cues. I will end with a discussion of where we are and thoughts on the way forward. ", "affiliation": "Cornell", "semester": "Spring", "speaker": "Bharath Hariharan", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-08", "video": "https://www.youtube.com/watch?v=rBrstWqWzbc"}, {"website": "http://www.phontron.com/", "bio": "Graham Neubig is an assistant professor at the Language Technologies Institute of Carnegie Mellon University. His work focuses on natural language processing, specifically multi-lingual models that work in many different languages, and natural language interfaces that allow humans to communicate with computers in their own language. Much of this work relies on machine learning to create these systems from data, and he is also active in developing methods and algorithms for machine learning over natural language data. He publishes regularly in the top venues in natural language processing, machine learning, and speech, and his work occasionally wins awards such as best papers at EMNLP, EACL, and WNMT. He is also active in developing open-source software, and is the main developer of the DyNet neural network toolkit.", "title": "What Can Neural Networks Teach us about Language?", "abstract": "Neural networks have led to large improvements in the accuracy of natural language processing systems. These have mainly been based on supervised learning: we create linguistic annotations for a large amount of training data, and train networks to faithfully reproduce these annotations. But what if we didn't tell the neural net about explicitly, but instead *asked it what it thought* about language without injecting our prior biases? Would the neural network be able to learn from large amounts of data and confirm or discredit our existing linguistic hypotheses? Would we be able to learn linguistic information from lower-resourced languages where this information has not been annotated? In this talk I will discuss methods for unsupervised learning of linguistic information using neural networks that attempt to answer these questions. I will also explain briefly about automatic mini-batching, a computational method (implemented in the DyNet neural network toolkit), which greatly speeds large-scale experiments with complicated network structures needed for this type of unsupervised learning.", "affiliation": "CMU", "semester": "Spring", "speaker": "Graham Neubig", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-01", "video": "https://www.youtube.com/watch?v=D0TEo_5EdWY"}, {"website": "https://cims.nyu.edu/~rajeshr/", "bio": "Rajesh Ranganath is a postdoc at Columbia University's Department of Statistics and a research affiliate at MIT's Institute for Medical Engineering and Science. He will be an assistant professor at the Courant Institute of Mathematical Sciences at NYU starting January 2018. His research interests include approximate inference, model checking, Bayesian nonparametrics, and machine learning for healthcare. Rajesh recently completed his PhD at Princeton with David Blei. Before starting his PhD, Rajesh worked as a software engineer for AMA Capital Management. He obtained his BS and MS from Stanford University with Andrew Ng and Dan Jurafsky. Rajesh has won several awards and fellowships including the NDSEG graduate fellowship and the Porter Ogden Jacobus Fellowship, given to the top four doctoral students at Princeton University.", "title": "Black Box Variational Inference: Scalable, Generic Bayesian Computation and its Applications", "abstract": "Probabilistic generative models are robust to noise, uncover unseen patterns, and make predictions about the future. Probabilistic generative models posit hidden structure to describe data. They have addressed problems in neuroscience, astrophysics, genetics, and medicine. The main computational challenge is computing the hidden structure given the data --- posterior inference. For most models of interest, computing the posterior distribution requires approximations like variational inference. Classically, variational inference was feasible to deploy in only a small fraction of models. We develop black box variational inference. Black box variational inference is a variational inference algorithm that is easy to deploy on a broad class of models and has already found use in neuroscience and healthcare. The ideas around black box variational inference also facilitate new kinds of variational methods such as hierarchical variational models. Hierarchical variational models improve the approximation quality of variational inference by building higher-fidelity approximations from coarser ones. Black box variational inference opens the doors to new models and better posterior approximations. Lastly, I will discuss some of the challenges that variational methods face moving forward.", "affiliation": "NYU", "semester": "Fall", "speaker": "Rajesh Ranganath", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-30", "video": ""}, {"website": "https://ai.stanford.edu/~cdarpino/", "bio": "Claudia P\u00e9rez D\u2019Arpino is a PhD Candidate in the Electrical Engineering and Computer Science Department at the Massachusetts Institute of Technology, advised by Prof. Julie A. Shah in the Interactive Robotics Group since 2012. She received her degrees in Electronics Engineering (2008) and Masters in Mechatronics (2010) from the Simon Bolivar University in Caracas, Venezuela, where she served as Assistant Professor in the Electronics and Circuits Department (2010-2012) with a focus on Robotics. She participated in the DARPA Robotics Challenge with Team MIT (2012-2015). Her research at CSAIL combines machine learning and planning techniques to empower humans through the use of robotics and AI. Her PhD research centers in enabling robots to learn and create strategies for multi-step manipulation tasks by observing demonstrations, and develop efficient methods for robots to employ these skills in collaboration with humans, either for shared workspace collaboration, such as assembly in manufacturing, or for remote robot control in shared autonomy, such as emergency response scenarios. Web:http://people.csail.mit.edu/cdarpino/", "title": "Learning How to Plan for Multi-Step Manipulation in Collaborative Robotics", "abstract": "The use of robots for complex manipulation tasks is currently challenged by the limited ability of robots to construct a rich representation of the activity at both the motion and tasks levels in ways that are both functional and apt for human-supervised execution. For instance, the operator of a remote robot would benefit from planning assistance, as opposed to the currently used method of joint-by-joint direct teleoperation. In manufacturing, robots are increasingly expected to execute manipulation tasks in shared workspace with humans, which requires the robot to be able to predict the human actions and plan around these predictions. In both cases, it is beneficial to deploy systems that are capable of learning skills from observed demonstrations, as this would enable the application of robotics by users without programming skills. However, previous work on learning from demonstrations is limited in the range of tasks that can be learned and generalized across different skills and different robots. I this talk, I present C-LEARN, a method of learning from demonstrations that supports the use of hard geometric constraints for planning multi-step functional manipulation tasks with multiple end effectors in quasi-static settings, and show the advantages of using the method in a shared autonomy framework.", "affiliation": "MIT", "semester": "Fall", "speaker": "Claudia P\u00e9rez D\u2019Arpino", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-20", "video": ""}, {"website": "https://zstevenwu.com/", "bio": "Steven Wu is currently a Post-Doctoral Researcher at Microsoft Research in New York City, where he is a member of the Machine Learning and Algorithmic Economics groups. He will be joining the Department of Computer Science and Engineering at the University of Minnesota as an Assistant Professor starting in fall 2018. He received his Ph.D. in Computer Science from the University of Pennsylvania in 2017, under the supervision of Michael Kearns and Aaron Roth. His doctoral dissertation \u201cData Privacy Beyond Differential Privacy\u201d received the 2017 Morris and Dorothy Rubinoff Dissertation Award. His research focuses on algorithm design under different social constraints. In particular, his primary research interest is on data privacy, specifically differential privacy, where he builds tools for data analysis under the constraint of privacy preservation. His recent research also studies algorithmic fairness, especially in the context of machine learning, where he investigates how we can prevent bias and unfairness in algorithmic decision making. He examines problems in these areas using methods and models from machine learning theory, economics, optimization, and beyond.", "title": "A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem", "abstract": "Bandit learning is characterized by the tension between long-term exploration and short-term exploitation. However, as has recently been noted, in settings in which the choices of the learning algorithm correspond to important decisions about individual people (such as criminal recidivism prediction, lending, and sequential drug trials), exploration corresponds to explicitly sacrificing the well-being of one individual for the potential future benefit of others. This raises a fairness concern. In such settings, one might like to run a \u201cgreedy\u201d algorithm, which always makes the (myopically) optimal decision for the individuals at hand \u2014 but doing this can result in a catastrophic failure to learn. In this paper, we consider the linear contextual bandit problem and revisit the performance of the greedy algorithm. We give a smoothed analysis, showing that even when contexts may be chosen by an adversary, small perturbations of the adversary\u2019s choices suffice for the algorithm to achieve \u201cno regret\u201d, perhaps (depending on the specifics of the setting) with a constant amount of initial training data. This suggests that \u201cgenerically\u201d (i.e. in slightly perturbed environments), exploration and exploitation need not be in conflict in the linear setting.", "affiliation": "MSR", "semester": "Fall", "speaker": "Steven Wu", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-16", "video": ""}, {"website": "http://www.ccs.neu.edu/home/luwang/", "bio": "Lu Wang is an Assistant Professor in College of Computer and Information Science at Northeastern University since 2015. She received her Ph.D. in Computer Science from Cornell University and her bachelor degrees in Intelligence Science and Technology and Economics from Peking University. Her research mainly focuses on designing machine learning algorithms and statistical models for natural language processing (NLP) tasks, including abstractive text summarization, language generation, argumentation mining, information extraction, and their applications in interdisciplinary subjects (e.g., computational social science). Lu and her collaborators received an outstanding short paper award at ACL 2017 and a best paper nomination award at SIGDIAL 2012. Her group's work is funded by National Science Foundation (NSF), Intelligence Advanced Research Projects Activity (IARPA), and several industry gifts (Toutiao AI Lab, and NVIDIA GPU program). More information about her research can be found at www.ccs.neu.edu/home/luwang/.", "title": "What Makes a Good Argument: Understanding and Predicting High Quality Arguments Using NLP Methods", "abstract": "Debate and deliberation play essential roles in politics and civil discourse. While argument content and linguistic style both affect debate outcomes, limited work has been done on studying the interplay between the two. In the first part of this talk, I will present a joint model that estimates the inherent persuasive strengths of different topics, the effects of numerous linguistic features, and the interactions between the two as they affect debate audience. By experimenting with Oxford-style debates, our model predicts audience-adjudicated winners with 74% accuracy, significantly outperforming models based on linguistic features alone. We also find that winning sides employ more strong arguments (as corroborated by human judgment) and debaters all tend to shift topics to stronger ground. The model further allows us to identify the linguistic features associated with strong or weak arguments.  In the second part of my talk, I will present our recent study on retrieving diverse types of supporting arguments from relevant documents for user-specified topics. We find that human writers often use different types of arguments to promote persuasiveness, which can be characterized with different linguistic features. We then show how to leverage argument type to assist the task of supporting argument detection. I will also discuss our follow-up work on automatic argument generation. ", "affiliation": "Northeastern", "semester": "Fall", "speaker": "Lu Wang", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-09", "video": "https://www.youtube.com/watch?v=JviDF2VasLc"}, {"website": "https://people.csail.mit.edu/beomjoon/", "bio": "Beomjoon Kim is a PhD student at MIT CSAIL under the supervision of Leslie Pack Kaelbling and Tomas Lozano-Perez. His recent research focuses on developing machine learning algorithms for complex robot planning problems, in which problems involve reasoning about both discrete, logical structures and continuous, geometric structures of the world. In the past, he has worked on robot learning from demonstrations and reinforcement learning. He received his MS.c from McGill University under the supervision of Joelle Pineau, and received BMath from University of Waterloo.", "title": "Learning to Guide Task and Motion Planning by Predicting Constraints", "abstract": "In robotics, it is essential to be able to plan efficiently in high-dimensional continuous state-action spaces for long horizons. For such complex planning problems, unguided uniform sampling of actions until a path to a goal is found is hopelessly inefficient, and gradient-based approaches often fall short when the optimization manifold of a given problem is not smooth. In this talk, I will introduce two of our recent approaches for using past planning experience to learn to predict constraints for guiding a planner. In the first part, I will introduce a technique that uses generative adversarial networks and importance sampling estimation to learn an action distribution that restricts the search space to a promising region, when an input is represented with a vector. In the second part, I will discuss the limitation of a vector representation in complex robot planning settings, and propose a more suitable representation for guiding a search, called a score-space representation. With this representation, we can predict a constraint on the search space by optimizing a black-box function. We empirically show that a planner is able to find a solution more efficiently using these approaches on a various robot task and motion planning problems.", "affiliation": "MIT", "semester": "Fall", "speaker": "Beomjoon Kim", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-02", "video": ""}, {"website": "http://www.kyunghyuncho.me/", "bio": "Kyunghyun Cho is an assistant professor of computer science and data science at New York University. He was a postdoctoral fellow at University of Montreal until summer 2015, and received PhD and MSc degrees from Aalto University early 2014. He tries best to find a balance among machine learning, natural language processing and life, but often fails to do so.", "title": "Deep Learning, Where are you going?", "abstract": "There are three axes along which advances in machine learning and deep learning happen. They are (1) network architectures, (2) learning algorithms and (3) spatio-temporal abstraction. In this talk, I will describe a set of research topics I've pursued in each of these axes. For network architectures, I will describe how recurrent neural networks, which were largely forgotten during 90s and early 2000s, have evolved over time and have finally become a de facto standard in machine translation. I continue on to discussing various learning paradigms, how they related to each other, and how they are combined in order to build a strong learning system. Along this line, I briefly discuss my latest research on designing a query-efficient imitation learning algorithm for autonomous driving. Lastly, I present my view on what it means to be a higher-level learning system. Under this view each and every end-to-end trainable neural network serves as a module, regardless of how they were trained, and interacts with each other in order to solve a higher-level task. I will describe my latest research on trainable decoding algorithm as a first step toward building such a framework.", "affiliation": "NYU", "semester": "Fall", "speaker": "Kyunghyun Cho", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-20", "video": "https://www.youtube.com/watch?v=3B5Ty5VD-5Q"}, {"website": "https://varunjampani.github.io/", "bio": "Varun Jampani works as a research scientist at Nvidia Research in Westford, US. He obtained his PhD at Max Planck Institute for Intelligent Systems (MPI) in T\u00fcbingen, Germany under the supervision of Prof. Peter V. Gehler. He works in the areas of machine learning and computer vision and his main research interests include probabilistic inference and neural networks. He obtained his BTech and MS from International Institute of Information Technology, Hyderabad (IIIT-H), India, where he was a gold medalist. During his studies, he did internships at Microsoft research institutes in Redmond (US), Cambridge (UK) and Cairo (Egypt); MPI, T\u00fcbingen (Germany) and; GE global research, Bangalore (India). He also worked as a volunteer teacher in Tibetan Children\u2019s Village, Dharamsala, India.", "title": "Bilateral Neural Networks for Image, Video and 3D Vision", "abstract": "Natural images exhibit high information correlation across pixels. Bilateral filtering provides a simple yet powerful framework for information propagation across pixels. The common use-case is to manually choose a parametric filter type, usually a Gaussian filter. We generalize the parameterization using a high-dimensional linear approximation and derive a gradient descent algorithm so the filter parameters can be learned from data. We demonstrate the use of learned bilateral filters in several applications where Gaussian bilateral filters are traditionally employed where we consistently observed improvements with filter learning. In addition, the ability to learn generic high-dimensional sparse filters allows us to stack several parallel and sequential filters like in convolutional neural networks (CNN) resulting in a new breed of neural networks which we call \u2018Bilateral Neural Networks\u2019 (BNN). We demonstrate the use of BNNs on several 2D, video and 3D vision tasks. Experiments on diverse datasets and tasks demonstrate the use BNNs for a range of vision problems.", "affiliation": "Nvidia", "semester": "Fall", "speaker": "Varun Jampani", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-12", "video": "https://www.youtube.com/watch?v=6LIcXwhOrGY"}, {"website": "http://francesco.orabona.com/", "bio": "Francesco Orabona is an Assistant Professor at Stony Brook University. His research interests are in the area of theoretically motivated and efficient machine learning algorithms, with emphasis on online and stochastic methods. He received the PhD degree in Electrical Engineering at the University of Genoa, in 2007. He is (co)author of more than 60 peer reviewed papers.", "title": "Coin Betting for Backprop without Learning Rates and More", "abstract": "Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this talk, I will propose a new stochastic gradient descent procedure that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a non-stochastic coin and we propose an optimal strategy based on a generalization of Kelly betting. Moreover, this reduction can be also used for other machine learning problems. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.", "affiliation": "Stony Brook", "semester": "Fall", "speaker": "Francesco Orabona", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-05", "video": "https://www.youtube.com/watch?v=61o-TMEcDMM"}, {"website": "https://www.cs.cornell.edu/~nika/", "bio": "Nika Haghtalab is a Ph.D. student at the Computer Science department of Carnegie Mellon University, co-advised by Avrim Blum and Ariel Procaccia. Her research interests include machine learning theory, computational aspects of economics, and algorithms. Nika is a recipient of the IBM and Microsoft Research Ph.D. fellowships.", "title": "Oracle-efficient Online Learning and Applications to Auction Design", "abstract": "We consider the fundamental problem of learning from expert advice, a.k.a online no-regret learning, where we have access to an offline optimization oracle that can be used to compute, in constant time, the best performing expert at any point in time. We consider the design of no-regret algorithms that are computationally efficient using such an oracle. We present structural properties under which we show oracle-efficient no-regret algorithms exist, even when the set of experts is exponentially large in a natural representation of the problem. Our algorithm is a generalization of the Follow-The-Perturbed-Leader algorithm of Kalai and Vempala that at every step follows the best-performing expert subject to some perturbations. Our design uses a shared source of randomness across all experts that can be efficiently implemented by using an oracle on a random modification of the history of the play at every time step.  Our second main contribution is showing that the structural properties required for our oracle-efficient online algorithm are present in a large class problems. As an example, we discuss applications of our oracle-efficient learning results to the adaptive optimization of a large class of auctions, including (1) VCG auctions with bidder-specific reserves in single-parameter settings, (2) envy-free item pricing in multi-item auctions, and (3) Myerson-like auctions for single-item settings. ", "affiliation": "CMU", "semester": "Fall", "speaker": "Nika Haghtalab", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-28", "video": ""}, {"website": "http://www.cs.umd.edu/~yogarshi/", "bio": "Yogarshi Vyas is a fourth year PhD student in the Department of Computer Science at the University of Maryland, College Park. His broad research interests lie in semantics, multilingual NLP, and machine translation, and the intersection of these. His current research focus is on comparing and contrasting the meaning of text in different languages using the idea of entailment as well as learning representations for multilingual data that facilitate meaningful and easy comparisons across languages. He recently won the Adam Kilgarriff Best Paper award at *SEM 2017.", "title": "Detecting Asymmetric Semantic Relations in Context : A Case-Study on Hypernymy Detection", "abstract": "Comparing the meaning of words and understanding how they relate is a fundamental challenge in natural language understanding. In this talk, I\u2019ll introduce WHiC, a challenging testbed for detecting hypernymy, an asymmetric relation between words. While previous work has focused on detecting hypernymy between word types, we ground the meaning of words in specific contexts drawn from WordNet examples, and require predictions to be sensitive to changes in contexts. WHiC also lets us analyze different properties of two approaches of inducing vector representations of word meaning in context, allowing us to identify their strengths and weaknesses. I\u2019ll also show that such contextualized word representations also improve detection of a wider range of semantic relations in context.", "affiliation": "UMD", "semester": "Fall", "speaker": "Yogarshi Vyas", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-21", "video": "https://www.youtube.com/watch?v=cEoqQQgyLuE"}, {"website": "http://people.math.umass.edu/~flaherty/?_ga=2.230150364.1118255471.1504663390-490697572.1416926222", "bio": "Patrick Flaherty is a Professor in the Department of Mathematics & Statistics at UMass Amherst. He received his PhD in Electrical Engineering and Computer Science from the University of California, Berkeley and he was a postdoctoral scholar at Stanford University in the Department of Biochemistry. His research focuses on scalable, statistical methods for analyzing large genomic data sets.", "title": "A Nonparametric Bayesian Model for Single-cell Variant Calling", "abstract": "Advances in DNA sequencing technology have enabled surprising discoveries in basic science and novel diagnostics in personalized medicine. Recently, the ability to read the DNA sequence of a single cell has presented new statistical and computational challenges. We address the problem of calling single-nucleotide mutations in single-cell sequencing data. We present some results evaluating existing mutation calling algorithms on data generated from a single-cell sequence data simulator. We describe a nonparametric Bayesian generative model for combining single-cell and bulk DNA sequencing data, and we show preliminary results from this model.", "affiliation": "UMass", "semester": "Fall", "speaker": "Pat Flaherty", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-14", "video": "https://www.youtube.com/watch?v=hjnyoNZ1RQw"}, {"website": "https://www.deaneckles.com/", "bio": "Dean Eckles is a social scientist, statistician, and faculty at MIT. Dean is the KDD Career Development Professor in Communications and Technology, an assistant professor in the MIT Sloan School of Management, and affiliated faculty at the MIT Institute for Data, Systems & Society. He was previously a member of the Core Data Science team at Facebook. He studies how interactive technologies affect human behavior by mediating, amplifying, and directing social influence \u2014 and statistical methods to study these processes. Dean\u2019s empirical work uses large field experiments and observational studies. His research appears in the Proceedings of the National Academy of Sciences and other peer-reviewed journals and proceedings in statistics, computer science, and marketing. Dean holds degrees from Stanford University in philosophy (BA), cognitive science (BS, MS), statistics (MS), and communication (PhD).", "title": "Learning from many experiments using regularized instrumental variable methods: Applications to peer effects in online networks", "abstract": "The widespread adoption of randomized experiments (i.e. A/B tests) in the Internet industry means that there are often numerous well-powered experiments on a given product. Individual experiments are often simple \"bake-off\" evaluations of a new intervention: They allow us to estimate effects of that particular intervention on outcomes of interest, but they are often not informative about the mechanisms for these effects or what other inventions might do. We consider what else we can learn from a large set of experiments. In particular, we use many experiments to learn about the effects of the various endogenous variables (or mechanisms) via which the experiments affect outcomes. This involves treating the experiments as instrumental variables, and so this setting is similar to, but somewhat different from, \"many instrument\" settings in econometrics and biostatistics. Motivated by the distribution of experiment first-stage effects, we present and evaluate sparsity-inducing regularization methods and cross-validation for instrumental variables. Our applications are to estimating peer effects in online social networks mediated by ranking systems.  Joint work with Alex Peysakhovich (Facebook) and including additional joint work with Eytan Bakshy (Facebook) and Ren\u00e9 Kizilcec (Stanford). ", "affiliation": "MIT", "semester": "Fall", "speaker": "Dean Eckles", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-07", "video": "https://www.youtube.com/watch?v=grDtaryIU60"}]}