{"data": [{"": "", "website": "http://cs-people.bu.edu/sbargal/", "title": "Grounding Deep Models of Visual Data", "abstract": "Deep models are state-of-the-art for many computer vision tasks including object classification, action recognition, and captioning. As Artificial Intelligence systems that utilize deep models are becoming ubiquitous, it is also becoming crucial to explain why they make certain decisions: Grounding model decisions. In this talk I will present: 1) Spatial Grounding for Improving Model Classification at Training Time. We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction. This approach penalizes neurons that are most relevant for model prediction. By dropping such high-saliency neurons, the network is forced to learn alternative paths in order to maintain loss minimization. We demonstrate better generalization ability, an increased utilization of network neurons, and a higher resilience to network compression. 2) Spatial Grounding for Improving Model Classification at Test Time. We propose Guided Zoom, an approach that utilizes spatial grounding to make more informed predictions at test time. Guided Zoom compares the evidence used to make a preliminary decision with the evidence of correctly classified training examples to ensure evidence/prediction consistency, otherwise refines the prediction. We demonstrate accuracy gains for fine-grained classification. 3) Spatiotemporal Grounding. We devise a formulation that simultaneously grounds evidence in space and time, in a single pass, using top-down saliency. We visualize the spatiotemporal cues that contribute to a deep recurrent neural network's classification/captioning output. Based on these spatiotemporal cues, we are able to localize segments within a video that correspond with a specific action, or phrase from a caption, without explicitly optimizing/training for these tasks.", "affiliation": "Boston University", "semester": "Spring", "speaker": "Sarah Adel Bargal", "sponsor": "Oracle Labs", "bio": "Sarah is a Postdoctoral Associate in the Image and Video Computing Group working with Prof. Stan Sclaroff and Prof. Kate Saenko. Sarah first joined the Image and Video Computing Group in 2013 where she then completed her PhD with Prof. Stan Sclaroff. She is a recipient of the IBM PhD Fellowship and the Hariri Graduate Fellowship. Her research interests lie in the intersection of Computer Vision and Machine Learning.", "year": "2019", "date": "2019-01-31", "video": ""}, {"": "", "website": "http://alanesuhr.com/", "title": "Modeling and Learning Agents that Understand Language in Context", "abstract": "The meaning of a natural language utterance is influenced by the context in which it occurs, including interaction history and situated context. I will discuss two recent projects in context-dependent natural language understanding for building natural language interfaces to databases and following sequences of instructions. In the first part, I will introduce a model for mapping from natural language to executable SQL queries in an interaction. To resolve the meaning of later utterances, the system must consider the interaction history, including previous user utterances and previously-generated queries. We show how using both implicit and explicit mechanisms for making use of interaction history allows the system to effectively generate context-dependent representations. In the second part, I will describe an approach to map sequences of natural language instructions to system actions that modify an environment, focusing on learning without direct supervision on action sequences. We introduce an exploration-based learning approach that effectively learns to compose system actions to carry out user instructions in context of the environment and interaction.", "affiliation": "Cornell University", "semester": "Spring", "speaker": "Alane Suhr", "sponsor": "Oracle Labs", "bio": "Alane Suhr is a PhD student in the Computer Science department at Cornell University, focusing on building agents that understand natural language grounded in complex interactions. She is the recipient of an AI2 Key Scientific Challenges Award and a Microsoft Research Women's Fellowship, and is a National Science Foundation Graduate Research Fellow. She has received paper awards at ACL 2017 and NAACL 2018. Alane received a Bachelor's degree in Computer Science and Engineering from Ohio State University in 2016.", "year": "2019", "date": "2019-02-07", "video": ""}, {"": "", "website": "https://people.cs.umass.edu/~pat/", "title": "Neural Knowledge Representation and Reasoning", "abstract": "Making complex decisions in science, government policy, finance, and clinical treatments all require integrating and reasoning over disparate sources of information. While some decisions can be made from a single piece of evidence, others require considering information that exists outside of the current context. A long-term store of abstracted knowledge over related concepts can facilitate this type of reasoning, while also influencing interpretation as well as enhancing the acquisition of new knowledge. A symbolic graph over a fixed, human-defined schema encoding facts about entities and their relations is the predominant method of representing knowledge, but this method is brittle, lacks specificity, and is inevitably highly incomplete. On the other extreme, recent work on purely text based knowledge models lack abstractions necessary for complex reasoning. In this talk I will present a middle ground incorporating powerful neural network models with rich structured ontologies and unstructured raw text to improve the representations of entities and their relations. We first discuss our work on universal schema, a method for learning a latent schema over both existing structured resources and unstructured free text data, embedding them jointly within a shared semantic space. Next we inject additional hierarchical structure into the embedding space of concepts, resulting in more efficient statistical sharing amongst related concepts and improving accuracy in both fine-grained entity typing and linking. We then present initial work to represent knowledge in context, including a single model for extracting all entities and long-range relations simultaneously over full paragraphs while jointly linking these entities to a knowledge graph. Lastly, we propose future directions for representing knowledge in context by incorporating cognitive theories of human memory systems and discuss how these models can address longstanding shortcomings in knowledge representation.", "affiliation": "UMass, Amherst", "semester": "Spring", "speaker": "Patrick Verga", "sponsor": "Oracle Labs", "bio": "Patrick Verga is a final year PhD candidate in the College of Information and Computer Sciences at UMass Amherst, advised by Andrew McCallum. His research contributes to knowledge representation and reasoning, with a focus on large knowledge base construction from unstructured text, with applications to general domain, commonsense, and biomedicine. Pat previously interned at Google and the Chan Zuckerberg Initiative and received the best long paper award at EMNLP 2018. Over the past several years he has advised multiple M.S. and junior PhD students, resulting in published research in fine-grained entity typing, unsupervised parsing, and partially labeled named entity extraction. He holds M.S. and B.A degrees in computer science as well as a B.S. in neuroscience.", "year": "2019", "date": "2019-02-14", "video": "https://youtube.com/BNQLWb4V7s0"}, {"": "", "website": "http://irenechen.net/", "title": "Why is my classifier discriminatory?", "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.", "affiliation": "MIT CSAIL", "semester": "Spring", "speaker": "Irene Chen", "sponsor": "Oracle Labs", "bio": "Irene Chen is a PhD student at MIT in Electrical Engineering and Computer Science in the Clinical Machine Learning Group. Her research focuses on building machine learning methods that to advance knowledge in health care and fairness. Before MIT, she received her AB/SM from Harvard in Applied Math and Computational Engineering and worked at Dropbox for two years as a Data Scientist, Machine Learning Engineer, and Chief of Staff.", "year": "2019", "date": "2019-02-21", "video": "https://youtube.com/gbvloQN2NiA"}, {"": "", "website": "https://www.uml.edu/sciences/computer-science/faculty/pourkamali-anaraki-farhad.aspx", "title": "Scalable and Robust Sparse Subspace Clustering", "abstract": "Sparse subspace clustering (SSC) is a popular method in machine learning and computer vision for clustering high-dimensional data points that lie near a union of low-dimensional linear or affine subspaces. Using a two-step approach, the first step involves representing each data point as a linear combination of all other data points, so-called self-expressiveness property, to form an undirected similarity graph. Spectral clustering is then applied to produce the final segmentation and infer the underlying subspaces. The sparse optimization program in the first step of SSC is typically solved by the alternating direction method of multipliers (ADMM) that scales cubically with the number of data points. In addition, the process of optimal parameter selection for ADMM requires a significantly increased amount of computational time. Orthogonal matching pursuit (OMP) has been used as a more efficient alternative; however, OMP is incapable of handling affine subspaces and the choice of sparsity parameter notably impacts the accuracy of SSC.", "affiliation": "UMass Lowell", "semester": "Spring", "speaker": "Farhad Pourkamali Anaraki", "sponsor": "Oracle Labs", "bio": "Farhad Pourkamali Anaraki is an Assistant Professor of Computer Science at UMass Lowell. He received his PhD from University of Colorado Boulder under the supervision of Prof. Stephen Becker in 2017. His current research focuses on theoretical foundations of modern data science, and developing efficient and robust machine learning algorithms. He also works on extending the use of machine learning algorithms to other domains, including \u00e5reliability analysis of critical infrastructures in Civil Engineering and advanced manufacturing in Mechanical Engineering.", "year": "2019", "date": "2019-02-28", "video": ""}, {"": "", "website": "http://www.cs.rpi.edu/~gittea/", "title": "Intelligent Randomized Algorithms for the Low CP-Rank Tensor Approximation Problem", "abstract": "In the context of numerical linear algebra algorithms, where it is natural to sacrifice accuracy in return for quicker computation of solutions whose errors are only slightly larger than optimal, the time-accuracy tradeoff of randomized sketching has been well-characterized. Algorithms such as Blendenpik and LSRN have shown that carefully designed randomized algorithms can outperform industry standard linear algebra codes such as those provided in LAPACK. For numerical tensor algorithms, where the size of problems grow exponentially with the order of the tensor, it is even more desirable to use randomization. However, in this setting, the time-accuracy tradeoff of randomized sketching is more difficult to understand and exploit, as: (1) in the first place, tensor problems are non-convex, (2) the properties of the data change from iteration to iteration, and (3) straightforward applications of standard results on randomized sketching allow for the error to increase from iteration to iteration. On the other hand, the iterative nature of such algorithms opens up the opportunity to learn how to sketch more accurately in an online manner. In this talk we consider the problem of speeding up the computation of low CP-rank (canonical polyadic) approximations of tensors through regularized sketching. We establish for the first time a sublinear convergence rate to approximate critical points of the objective under standard conditions, and further provide algorithms that adaptively select the sketching and regularization rates.", "affiliation": "Rensselaer Polytechnic Institute", "semester": "Spring", "speaker": "Alex Gittens", "sponsor": "Oracle Labs", "bio": "Alex Gittens is an assistant professor of computer science at Rensselaer Polytechnic Institute. He obtained his PhD in applied mathematics from CalTech in 2013, and BSes in mathematics and electrical engineering from the University of Houston. After his PhD, he joined the eBay machine learning research group, then the AMPLab (now the RISELab) at UC Berkeley, before joining RPI. His research interests lie at the intersection of randomized linear algebra and large-scale machine learning, in particular encompassing nonlinear and multilinear low-rank approximations; sketching for nonlinear and multilinear problems; and scalable and data-dependent kernel learning.", "year": "2019", "date": "2019-03-07", "video": ""}, {"": "", "website": "https://imisra.github.io/", "title": "Scaling Self-supervised Visual Representation Learning", "abstract": "Self-supervised learning aims to learn representations from the data itself without explicit manual supervision. Existing efforts ignore a crucial aspect of self-supervised learning - the ability to scale to large amount of data because self-supervision requires no manual labels. In this work, we revisit this principle and scale two popular self-supervised approaches to 100 million images. Scaling these methods also provides many interesting insights into the limitations of current self-supervised techniques and evaluations. We conclude that current self-supervised methods are not complex enough to take full advantage of large scale data and do not seem to learn effective high level semantic representations. Finally, we show how scaling current self-supervised methods provides state-of-the-art results that sometimes match or surpass supervised representations on tasks such as object detection, surface normal estimation and visual navigation.", "affiliation": "Facebook AI Research, NY", "semester": "Spring", "speaker": "Ishan Misra", "sponsor": "Oracle Labs", "bio": "Ishan is a Research Scientist at Facebook AI Research. He graduated from Carnegie Mellon University where his PhD thesis was titled \"Visual Learning with Minimal Human Supervision\" and got the Runner Up SCS Distinguished Dissertation Award. This work was about learning recognition models with minimal supervision by exploring structure and biases in the labels (multi-task), classifiers (meta learning) and data (self supervision). His current research interests are in self supervised approaches, understanding vision and language models, and in compositional models for small sample learning.", "year": "2019", "date": "2019-03-28", "video": ""}, {"": "", "website": "http://swabhs.com/", "title": "Learning Challenges in Natural Language Processing", "abstract": "As the availability of data for language learning grows, the role of linguistic structure is under scrutiny. At the same time, it is imperative to closely inspect patterns in data which might present loopholes for models to obtain high performance on benchmarks. In a two-part talk, I will address each of these challenges.| First, I will introduce the paradigm of scaffolded learning. Scaffolds enable us to leverage inductive biases from one structural source for prediction of a different, but related structure, using only as much supervision as is necessary. We show that the resulting representations achieve improved performance across a range of tasks, indicating that linguistic structure remains beneficial even with powerful deep learning architectures. In the second part of the talk, I will showcase some of the properties exhibited by NLP models in large data regimes. Even as these models report excellent performance, sometimes claimed to beat humans, a closer look reveals that predictions are not a result of complex reasoning, and the task is not being completed in a generalizable way. Instead, this success can be largely attributed to exploitation of some artifacts of annotation in the datasets. I will discuss some questions our finding raises, as well as directions for future work.", "affiliation": "CMU", "semester": "Spring", "speaker": "Swabha Swayampdipta", "sponsor": "Oracle Labs", "bio": "Swabha Swayamdipta is a PhD candidate at the Language Technologies Institute at Carnegie Mellon University (currently a visiting student at University of Washington). She works with Noah Smith and Chris Dyer on developing efficient algorithms for linguistic structured prediction, with a focus on incorporating syntactic inductive biases. Prior to joining her PhD program, she earned a Masters degree from Columbia University. She has done research internships at Google AI, New York and at Allen Institute of Artificial Intelligence in Seattle.", "year": "2019", "date": "2019-04-02", "video": ""}, {"": "", "website": "http://nlp.seas.harvard.edu/rush.html", "title": "Controllable Text Generation with Deep Latent-Variable Models", "abstract": "Progress in deep learning has led to optimism for automatic text generation. Yet state-of-the-art systems still predict inaccurate output on a non-trivial percentage of examples. Lack of user control to correct these issues makes it difficult to deploy these models in real applications. In this talk, I will argue that discrete latent-variable models provide a natural declarative framework for more controllable text models. I will present two recent works exploring this theme: (1) a method for learning neural template models that can be adjusted directly by users; (2) a variational approach to soft attention that learns alignment as a latent variable. I will end by discussing research challenges for making it easy to design and fit these models for large scale applications.", "affiliation": "Harvard University", "semester": "Spring", "speaker": "Alexander Rush", "sponsor": "Oracle Labs", "bio": "Alexander \"Sasha\" Rush is an Assistant Professor at Harvard University, where he studies natural language processing and machine learning. Sasha received his PhD from MIT supervised by Michael Collins and was a postdoc at Facebook NY under Yann LeCun. His group supports open-source development, running several projects including OpenNMT. His research has received several best paper awards at NLP conferences, an NSF Career award, and faculty awards from Google, Facebook, and others. He is currently the senior program chair of ICLR 2019.", "year": "2019", "date": "2019-04-04", "video": ""}, {"": "", "website": "https://christophriedl.net/", "title": "Quantifying Reputation and Success in Art", "abstract": "In areas of human activity where performance is difficult to quantify in an objective fashion, reputation and networks of influence play a key role in determining access to resources and rewards. To understand the role of these factors, we reconstructed the exhibition history of half a million artists, mapping out the co-exhibition network that captures the movement of art between institutions. Centrality within this network captured institutional prestige, allowing us to explore the career trajectory of individual artists in terms of access to coveted institutions. Early access to prestigious central institutions offered life-long access to high-prestige venues and reduced dropout rate. By contrast, starting at the network periphery resulted in a high dropout rate, limiting access to central institutions. A Markov model predicts the career trajectory of individual artists and documents the strong path and history dependence of valuation in art.", "affiliation": "Northeastern University", "semester": "Spring", "speaker": "Christoph Riedl", "sponsor": "Oracle Labs", "bio": "Christoph Riedl is assistant professor for Information Systems at the D'Amore-McKim School of Business at Northeastern University. He holds a joint appointment with the Khoury College of Computer Sciences and is a core faculty member at the Network Science Institute. He is a fellow at the Institute for Quantitative Social Science (IQSS) at Harvard. He is recipient of a Young Investigator Award (YIP) from the Army Research Office (ARO) for his work on social networks in collaborative decision-making. Before joining Northeastern University he was a post-doctoral fellow at Harvard Business School and IQSS. He received a PhD in Information Systems from Technische Universitat Munchen (TUM), Germany in 2011, a MSc in Information Systems in 2007, and a BSc in Computer Science in 2006. His work has been funded by NSF, ARO, ONR, and DARPA, and has been published in leading journals including Science, Organization Science, Management Science, Information Systems Research, Academy of Management Discoveries, and the Journal of the Royal Society Interface.", "year": "2019", "date": "2019-04-11", "video": ""}, {"": "", "website": "https://dylanfoster.net/", "title": "Logistic Regression: The Importance of Being Improper", "abstract": "Logistic regression is a fundamental task in machine learning and statistics. For the simple case of linear models, Hazan et al. (2014) showed that any logistic regression algorithm that estimates model weights from samples must exhibit exponential dependence on the weight magnitude. As an alternative, we explore a counterintuitive technique called improper learning, whereby one estimates a linear model by fitting a non-linear model. Past success stories for improper learning have focused on cases where it can improve computational complexity. Surprisingly, we show that for sample complexity (number of examples needed to achieve a desired accuracy level), improper learning leads to a doubly-exponential improvement in dependence on weight magnitude over estimation of model weights, and more broadly over any so-called \"proper\" learning algorithm. This provides a positive resolution to a COLT 2012 open problem of McMahan and Streeter. As a consequence of this improvement, we also resolve two open problems on the sample complexity of boosting and bandit multi-class classification.", "affiliation": "MIT", "semester": "Spring", "speaker": "Dylan Foster", "sponsor": "Oracle Labs", "bio": "Dylan Foster is a postdoctoral researcher at the MIT Institute for Foundations of Data Science. In 2018 he received his PhD in computer science at Cornell University, advised by Karthik Sridharan. His research focuses on theory for machine learning in real-world settings. He is particularly interested in all aspects of generalization theory and related algorithmic questions, particularly as it applies to interactive learning, deep learning, and non-convex optimization. Dylan previously received his BS and MS in Electrical Engineering from USC in 2014. He has received awards including the NDSEG PhD fellowship, Facebook PhD fellowship, and best student paper award at COLT 2018.", "year": "2019", "date": "2019-04-18", "video": ""}, {"": "", "website": "https://research.fb.com/people/roller-stephen/", "title": "ParlAI and Open-Domain Dialogue Research", "abstract": "We present ParlAI (pronounced \"parley\"), an all-in-one dialogue and chatbot research platform. ParlAI provides tools for all aspects of conversational research, including allowing one to develop novel models; train and test models on a wide variety of existing datasets; compare to standard baselines; collect rich new datasets and conduct human evaluations using Mechanical Turk, and deploy models to users over Facebook Messenger. We present two research projects built using ParlAI. The first paper we present, \"What Makes a Good Conversation?\", compares two methods for controllable text generation in neural sequence models, and applies them to chit chat. We consider four controllable variables for text, and provide a detailed analysis of their effects on high-level human judgements of conversational aspects. We show that by controlling combinations of these variables, our models demonstrate clear improvements in human quality judgements. The second paper we present, \"The Wizard of Wikipedia\", considers the expectation of users that chatbots should exhibit strong, open-domain factual world knowledge. We present a new dataset of conversations which contains explicit groundings in facts from Wikipedia. We propose novel models for integrating knowledge into conversations, and compare to standard \"generate and hope\" neural models. We show our models exhibit the ability to recall and incorporate factual knowledge, even when discussing previously unseen topics.", "affiliation": "FAIR, NY", "semester": "Spring", "speaker": "Stephen Roller", "sponsor": "Oracle Labs", "bio": "Stephen Roller is a Research Engineer at Facebook AI Research. His research focuses primarily on generation in neural dialogue agents. Before joining FAIR, Stephen completed his PhD at the University of Texas at Austin under the supervision of Katrin Erk, where his research focused primarily on hypernymy and lexical entailment. Stephen additionally completed part of studies as a visiting PhD student at the University of Stuttgart, where he researched multimodal lexical semantics under the supervision of Sabine Schulte im Walde.", "year": "2019", "date": "2019-04-25", "video": ""}]}