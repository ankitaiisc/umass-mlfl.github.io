{"data": [{"semester": "Spring", "year": "2022", "date": "2022-02-03", "speaker": "Swetasudha Panda", "website": "https://swetapanda.github.io", "title": "Addressing Biases in Pre-Trained Language Models", "affiliation": "Oracle", "sponsor": "Oracle Labs", "video": "", "abstract": "Large-scale pre-trained Language Models (LMs) have seen enormous success across many NLP tasks. However, there is evidence that these models reflect societal biases in the learned representations and the downstream applications. We find that de-biasing approaches in the contextual  embeddings space can be ineffective at the downstream task level, since biases can be re-introduced during fine-tuning. We investigate whether biases internalized by large LMs during pre-training affect downstream behavior after fine-tuning. For two classification tasks, we find that reducing representation bias with interventions before fine-tuning has little impact on task-specific predictions (after fine-tuning). In fact, downstream disparities are better explained by biases in the fine-tuning dataset. Motivated by these observations, we present a de-biasing approach based on stochastic word dropout. Our approach acts on the task-specific data during fine-tuning and it selectively attenuates contribution from words which are highly correlated with words indicative of societal biases. Our approach encourages practitioners to focus more on the task-specific dataset and the context-specific harms.", "bio": "Swetasudha (Sweta) Panda is a research scientist at the Machine Learning Research Group of Oracle Labs located in Burlington, MA. Previously, she received a Ph.D. in Computer Science from Vanderbilt University, working with Yevgeniy Vorobeychik. She graduated with B.Tech. in Electrical Engineering from Indian Institute of Technology, Kharagpur. Her research interests span fairness-aware ML and NLP, algorithms for social good, stochastic planning and computational game theory.", "area": "ML Fairness, NLP, Game Theory", "key": "SwetasudhaPanda", "prettyDate": "February 03"}, {"semester": "Spring", "year": "2022", "date": "2022-02-10", "speaker": "Varun Jampani", "website": "https://varunjampani.github.io", "title": "Practical 3D Object Understanding from Image Collections and Videos", "affiliation": "Google Research", "sponsor": "Oracle Labs", "video": "", "abstract": "Much of computer vision is understanding objects around us. In this talk, I will give an overview of our research works on understanding 3D object properties from 2D image collections and videos. Annotating several of the 3D object properties such as 3D shape, material properties, etc. is very labor-intensive and can not easily scale to large-scale datasets and new object categories. So, techniques that can estimate these object properties with minimal supervision are important for practical purposes.   In the first part of the talk, I will present an overview of our research works that can simultaneously learn object shape and material properties i.e., estimating re-lightable 3D assets from an image collection of an object that is captured under unconstrained variable lighting environments. In the second part, I will present techniques to estimate articulated 3D object shape given a single monocular video of a moving object. These works are category-agnostic and only assume a weak form of 2D supervision (object segmentations), thereby providing important steps towards practical 3D object understanding from the 2D world imagery. ", "bio": "Varun Jampani is a researcher at Google Research in Cambridge, US. Prior to that, he was a researcher at NVIDIA. He works in the areas of machine learning and computer vision and his main research interests include content-adaptive neural networks, self-supervised visual discovery and novel view synthesis. He obtained his PhD with highest honors at Max Planck Institute for Intelligent Systems (MPI) and the University of T\u00fcbingen in T\u00fcbingen, Germany. He obtained his BTech and MS from the International Institute of Information Technology, Hyderabad (IIIT-H), India, where he was a gold medalist. His work on 'SplatNet' has received 'Best Paper Honorable Mention' award at CVPR'18.", "area": "Computer Vision", "key": "VarunJampani", "prettyDate": "February 10"}, {"semester": "Spring", "year": "2022", "date": "2022-02-17", "speaker": "Anjalie Field", "website": "https://www.cs.cmu.edu/~anjalief/", "title": "TBA", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "NLP, AI Ethics", "key": "AnjalieField", "prettyDate": "February 17"}, {"semester": "Spring", "year": "2022", "date": "2022-02-24", "speaker": "Gautam Kamath", "website": "http://www.gautamkamath.com/", "title": "Differentially Private Fine-tuning of Language Models", "affiliation": "University of Waterloo", "sponsor": "Oracle Labs", "video": "", "abstract": "We give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks. We propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. Our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. On many commonly studied datasets, the utility of private models approaches that of non-private models. For example, on the MNLI dataset we achieve an accuracy of 87.8% using RoBERTa-Large and 83.5% using RoBERTa-Base with a privacy budget of \u03f5=6.7. In comparison, absent privacy constraints, RoBERTa-Large achieves an accuracy of 90.2%. Our findings are similar for natural language generation tasks. Privately fine-tuning with DART, GPT-2-Small, GPT-2-Medium, GPT-2-Large, and GPT-2-XL achieve BLEU scores of 38.5, 42.0, 43.1, and 43.8 respectively (privacy budget of \u03f5=6.8,\u03b4= 1e-5) whereas the non-private baseline is 48.1. All our experiments suggest that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced.   No knowledge of differential privacy will be assumed. Based on joint work with Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A. Inan, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang. Paper to appear in ICLR 2022, and available on arXiv (https://arxiv.org/abs/2110.06500). ", "bio": "Gautam Kamath is an Assistant Professor at the David R. Cheriton School of Computer Science at the University of Waterloo, and a faculty affiliate at the Vector Institute. He has a B.S. in Computer Science and Electrical and Computer Engineering from Cornell University, and an M.S. and Ph.D. in Computer Science from the Massachusetts Institute of Technology. His research interests lie in methods for statistics and machine learning, with a focus on challenges related to trustworthy machine learning, including data privacy and robustness. He was a Microsoft Research Fellow, as a part of the Simons-Berkeley Research Fellowship Program at the Simons Institute for the Theory of Computing. He is recipient of an NSERC Discovery Accelerator Supplement, and was awarded the Best Student Presentation Award at the ACM Symposium on Theory of Computing in 2012.", "area": "Privacy, ML Security, ML Theory", "key": "GautamKamath", "prettyDate": "February 24"}, {"semester": "Spring", "year": "2022", "date": "2022-03-03", "speaker": "Colin Raffel", "website": "https://colinraffel.com/", "title": "A call to build models like we build open-source software", "affiliation": "UNC Chapel Hill", "sponsor": "Oracle Labs", "video": "", "abstract": "Large pre-trained models have become a cornerstone of modern ML pipelines thanks to the fact that they facilitate improved performance with less labeled data on downstream tasks. However, these models are typically created by a resource-rich research group that unilaterally decides how a given model should be built, trained, and released, after which point it is left as-is until a better pre-trained model comes along to completely supplant it. In contrast, open-source development has proven that it is possible for a distributed community of contributors to work together to iteratively build complex and widely-used software. This kind of large-scale distributed collaboration is made possible through a mature set of tools including version control, continuous integration, merging, and more. In this talk, I will present a vision for building machine learning models in the way that open-source software is developed, including preliminary work from my lab on \"merging\" and \"patching\" models. I will also give some insight into the future work required to make this vision a reality.", "bio": "Colin Raffel is an assistant professor at UNC Chapel Hill. He also spends one day a week as a faculty researcher at Hugging Face.", "area": "NLP, Machine Learning", "key": "ColinRaffel", "prettyDate": "March 03"}, {"semester": "Spring", "year": "2022", "date": "2022-03-10", "speaker": "Marine Carpuat", "website": "http://www.cs.umd.edu/~marine/", "title": "TBA (tentative date)", "affiliation": "UMD College Park", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "NLP", "key": "MarineCarpuat", "prettyDate": "March 10"}, {"semester": "Spring", "year": "2022", "date": "2022-03-24", "speaker": "Despoina Paschalidou", "website": "https://paschalidoud.github.io/", "title": "TBA (tentative date)", "affiliation": "MPI / ETH Zurich", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Computer Vision", "key": "DespoinaPaschalidou", "prettyDate": "March 24"}, {"semester": "Spring", "year": "2022", "date": "2022-03-31", "speaker": "Vinodkumar Prabhakaran", "website": "https://www.cs.stanford.edu/~vinod/", "title": "TBA", "affiliation": "Google Research", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "NLP, AI Ethics", "key": "VinodkumarPrabhakaran", "prettyDate": "March 31"}, {"semester": "Spring", "year": "2022", "date": "2022-04-07", "speaker": "Gauri Joshi", "website": "https://www.andrew.cmu.edu/user/gaurij/", "title": "TBA (tentative date)", "affiliation": "CMU", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Distributed ML, Parallel Computing, Federated Learning", "key": "GauriJoshi", "prettyDate": "April 07"}, {"semester": "Spring", "year": "2022", "date": "2022-04-14", "speaker": "Andrea Tagliasacchi", "website": "https://taiya.github.io/", "title": "TBA", "affiliation": "Google Research / Simon Fraser", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Computer Vision", "key": "AndreaTagliasacchi", "prettyDate": "April 14"}, {"semester": "Spring", "year": "2022", "date": "2022-04-21", "speaker": "Georgios Pavlakos", "website": "https://geopavlakos.github.io/", "title": "TBA (tentative date)", "affiliation": "UC Berkeley", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Computer Vision", "key": "GeorgiosPavlakos", "prettyDate": "April 21"}]}