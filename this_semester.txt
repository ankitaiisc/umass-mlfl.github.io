{"data": [{"website": "https://people.csail.mit.edu/tbroderick/", "bio": "Tamara Broderick is an Associate Professor in the Department of Electrical Engineering and Computer Science at MIT. She is a member of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), the MIT Statistics and Data Science Center, and the Institute for Data, Systems, and Society (IDSS). She completed her Ph.D. in Statistics at the University of California, Berkeley in 2014. Previously, she received an AB in Mathematics from Princeton University (2007), a Master of Advanced Study for completion of Part III of the Mathematical Tripos from the University of Cambridge (2008), an MPhil by research in Physics from the University of Cambridge (2009), and an MS in Computer Science from the University of California, Berkeley (2013). Her recent research has focused on developing and analyzing models for scalable Bayesian machine learning. She has been awarded an Early Career Grant (ECG) from the Office of Naval Research (2020), an AISTATS Notable Paper Award (2019), an NSF CAREER Award (2018), a Sloan Research Fellowship (2018), an Army Research Office Young Investigator Program (YIP) award (2017), Google Faculty Research Awards, an Amazon Research Award, the ISBA Lifetime Members Junior Researcher Award, the Savage Award (for an outstanding doctoral dissertation in Bayesian theory and methods), the Evelyn Fix Memorial Medal and Citation (for the Ph.D. student on the Berkeley campus showing the greatest promise in statistical research), the Berkeley Fellowship, an NSF Graduate Research Fellowship, a Marshall Scholarship, and the Phi Beta Kappa Prize (for the graduating Princeton senior with the highest academic average).", "prettyDate": "February 11", "title": "An Automatic Finite-Sample Robustness Metric: Can Dropping a Little Data Change Conclusions?", "abstract": "We propose a method to assess the sensitivity of data analyses to the removal of a small fraction of the data set. Analyzing all possible data subsets of a certain size is computationally prohibitive, so we provide a finite-data metric to approximately compute the number (or fraction) of observations that has the greatest influence on a given result when dropped. We call our resulting metric the Approximate Maximum Influence Perturbation. Our approximation is automatically computable and works for common estimators (including OLS, IV, GMM, MLE, and variational Bayes). We provide explicit finite-sample error bounds on our approximation for linear and instrumental variables regressions. At minimal computational cost, our metric provides an exact finite-sample lower bound on sensitivity for any estimator, so any non-robustness our metric finds is conclusive. We demonstrate that the Approximate Maximum Influence Perturbation is driven by the signal-to-noise ratio in the inference problem, is not reflected in standard errors, does not disappear asymptotically, and is not a product of misspecification. We focus on econometric analyses in our applications. Several empirical applications show that even 2-parameter linear regression analyses of randomized trials can be highly sensitive. While we find some applications are robust, in others the sign of a treatment effect can be changed by dropping less than 1% of the sample even when standard errors are small. ", "area": "ML Theory", "affiliation": "MIT", "semester": "Spring", "speaker": "Tamara Broderick", "sponsor": "Oracle Labs", "key": "TamaraBroderick", "year": "2021", "date": "2021-02-11", "video": "https://www.youtube.com/watch?v=w8OX0lK1CKo"}, {"website": "https://vered1986.github.io/", "bio": "Vered Shwartz is a postdoctoral researcher at the Allen Institute for AI (AI2) and the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Previously, she completed her PhD in Computer Science from Bar-Ilan University, under the supervision of Prof. Ido Dagan. Her research interests include commonsense reasoning, lexical and compositional semantics.", "prettyDate": "February 18", "title": "Commonsense Knowledge and Reasoning in Natural Language", "abstract": "Natural language understanding models are trained on a sample of the real-world situations they may encounter. Commonsense and world knowledge, language, and reasoning skills can help them address unknown situations sensibly.\u00a0 In this talk I will present two lines of work addressing commonsense knowledge and reasoning in natural language. I will first present a method for discovering relevant knowledge which is unstated but may be required for solving a particular problem, e.g., to correctly resolve \"Children need to eat more vegetables because they [children / vegetables] are healthy\" one needs to know that \"vegetables are healthy\". Such knowledge is discovered through a process of asking information seeking clarification questions (e.g. \"what is the purpose of vegetables?\") and answering them (\"to provide nutrients\"). I will then discuss nonmonotonic reasoning in natural language, a core human reasoning ability that has been studied in classical AI but mostly overlooked in modern NLP. I will talk about several recent papers addressing abductive reasoning (reasoning about plausible explanations), counterfactual reasoning (what if?) and defeasible reasoning (updating beliefs given additional information). Finally, I will discuss open problems in language, knowledge, and reasoning. ", "area": "NLP", "affiliation": "AI2", "semester": "Spring", "speaker": "Vered Shwartz", "sponsor": "Oracle Labs", "key": "VeredShwartz", "year": "2021", "date": "2021-02-18", "video": ""}, {"website": "http://www.columbia.edu/~skk2175/", "bio": "I graduated (Sept 2010) in Computer Science at the University of California, San Diego, advised by Sanjoy Dasgupta. I then was a researcher at the Max Planck Institute for Intelligent Systems. At the MPI I worked in the department of Bernhard Schoelkopf, in the learning theory group of Ulrike von Luxburg. Following this, I spent a couple years as an Assistant Research Professor at the Toyota Technological Institute at Chicago. I then spent 4 years at ORFE, Princeton University as an Assistant Professor. Recently I was a visiting member at the Institute of Advanced Study from January to July 2020.", "prettyDate": "February 25", "title": "Some Recent Insights on Transfer-Learning", "abstract": "A common situation in Machine Learning is one where training data is not fully representative of a target population due to bias in the sampling mechanism or due to prohibitive target sampling costs. In such situations, we aim to \u2019transfer\u2019 relevant information from the training data (a.k.a. source data) to the target application. How much information is in the source data about the target application? Would some amount of target data improve transfer? These are all practical questions that depend crucially on 'how far' the source domain is from the target. However, how to properly measure 'distance' between source and target domains remains largely unclear. In this talk we will argue that much of the traditional notions of 'distance' (e.g. KL-divergence, extensions of TV such as D_A discrepancy, density-ratios, Wasserstein distance) can yield an over-pessimistic picture of transferability. Instead, we show that some new notions of 'relative dimension' between source and target (which we simply term 'transfer-exponents') capture a continuum from easy to hard transfer. Transfer-exponents uncover a rich set of situations where transfer is possible even at fast rates; they encode relative benefits of source and target samples, and have interesting implications for related problems such as 'multi-task or multi-source learning'. In particular, in the case of transfer from multiple sources, we will discuss (if time permits) a strong dichotomy between minimax and adaptive rates: no adaptive procedure exists that can achieve the same rates as minimax (oracle) procedures.\u00a0 The talk is based on earlier work with Guillaume Martinet, and ongoing work with Steve Hanneke.", "area": "ML Theory", "affiliation": "Columbia University", "semester": "Spring", "speaker": "Samory Kpotufe", "sponsor": "Oracle Labs", "key": "SamoryKpotufe", "year": "2021", "date": "2021-02-25", "video": ""}, {"website": "http://stanford.edu/~hamidi/", "bio": "Nima Hamidi is a sixth year Ph.D. student in the Stanford Department of Statistics. He received a B.Sc. degree in Software Engineering and Pure Mathematics and a M.Sc. degree in Pure Mathematics from Sharif University. His research interests include multi-armed bandit experiments and low-rank matrix estimation.", "prettyDate": "March 04", "title": "On Worst-case Regret of Linear Thompson Sampling", "abstract": "In this paper, we consider the worst-case regret of Linear Thompson Sampling (LinTS) for the linear bandit problem. Russo and Van Roy (2014) show that the Bayesian regret of LinTS is bounded above by $\\widetilde{\\mathcal{O}}(d\\sqrt{T})$ where $T$ is the time horizon and $d$ is the number of parameters. While this bound matches the minimax lower-bounds for this problem up to logarithmic factors, the existence of a similar worst-case regret bound is still unknown. The only known worst-case regret bound for LinTS, due to Agrawal and Goyal (2013b); Abeille et al. (2017), is $\\widetilde{\\mathcal{O}}(d\\sqrt{dT})$ which requires the posterior variance to be inflated by a factor of $\\widetilde{\\mathcal{O}}(\\sqrt{d})$. While this bound is far from the minimax optimal rate by a factor of $\\sqrt{d}$, in this paper we show that it is the best possible one can get, settling an open problem stated in Russo et al. (2018). Specifically, we construct examples to show that, without the inflation, LinTS can incur linear regret up to time $\\exp(\\mathcal{O}(d))$. We then demonstrate that, under mild conditions, a slightly modified version of LinTS requires only an $\\widetilde{\\mathcal{O}}(1)$ inflation where the constant depends on the diversity of the optimal arm.", "area": "ML Theory", "affiliation": "Stanford University", "semester": "Spring", "speaker": "Nima Hamidi", "sponsor": "Oracle Labs", "key": "NimaHamidi", "year": "2021", "date": "2021-03-04", "video": ""}, {"website": "https://dbmi.hms.harvard.edu/people/marinka-zitnik", "bio": "TBA", "prettyDate": "March 11", "title": "TBA", "abstract": "TBA", "area": "Biomedical Informatics", "affiliation": "Harvard Medical School", "semester": "Spring", "speaker": "Marinka Zitnik", "sponsor": "Oracle Labs", "key": "MarinkaZitnik", "year": "2021", "date": "2021-03-11", "video": ""}, {"website": "", "bio": "", "prettyDate": "March 18", "title": "Data Science Conference week", "abstract": "", "area": "", "affiliation": "", "semester": "Spring", "speaker": "N/A", "sponsor": "Oracle Labs", "key": "N/A", "year": "2021", "date": "2021-03-18", "video": ""}, {"website": "https://gberta.github.io/", "bio": "TBA", "prettyDate": "March 25", "title": "TBA", "abstract": "TBA", "area": "Vision", "affiliation": "Facebook AI", "semester": "Spring", "speaker": "Gedas Bertasius", "sponsor": "Oracle Labs", "key": "GedasBertasius", "year": "2021", "date": "2021-03-25", "video": ""}, {"website": "", "bio": "", "prettyDate": "April 01", "title": "", "abstract": "", "area": "", "affiliation": "", "semester": "Spring", "speaker": "TBA", "sponsor": "", "key": "TBA", "year": "2021", "date": "2021-04-01", "video": ""}, {"website": "https://hhexiy.github.io/", "bio": "TBA", "prettyDate": "April 08", "title": "TBA", "abstract": "TBA", "area": "NLP", "affiliation": "NYU", "semester": "Spring", "speaker": "He He", "sponsor": "Oracle Labs", "key": "HeHe", "year": "2021", "date": "2021-04-08", "video": ""}, {"website": "https://twitter.com/lucianabenotti?lang=enn", "bio": "TBA", "prettyDate": "April 15", "title": "TBA", "abstract": "TBA", "area": "NLP", "affiliation": "Universidad Nacional de C\u00f3rdoba", "semester": "Spring", "speaker": "Luciana Benotti", "sponsor": "Oracle Labs", "key": "LucianaBenotti", "year": "2021", "date": "2021-04-15", "video": ""}, {"website": "", "bio": "", "prettyDate": "April 22", "title": "", "abstract": "", "area": "", "affiliation": "", "semester": "Spring", "speaker": "TBA", "sponsor": "", "key": "TBA", "year": "2021", "date": "2021-04-22", "video": ""}, {"website": "https://adam-dziedzic.github.io/", "bio": "TBA", "prettyDate": "April 29", "title": "TBA", "abstract": "TBA", "area": "ML security", "affiliation": "the Vector Institute and the University of Toronto", "semester": "Spring", "speaker": "Adam Dziedzic", "sponsor": "Oracle Labs", "key": "AdamDziedzic", "year": "2021", "date": "2021-04-29", "video": ""}]}