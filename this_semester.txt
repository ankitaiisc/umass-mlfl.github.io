{"data": [{"semester": "Fall", "year": "2021", "date": "2021-09-16", "speaker": "Trapit Bansal", "website": "https://trapitbansal.com", "title": "Few-Shot Natural Language Processing via Self-Supervised Meta-Learning", "affiliation": "UMass", "sponsor": "Oracle Labs", "video": "", "abstract": "Humans show a remarkable capability to accurately solve a wide range of problems efficiently -- utilizing a limited amount of computation and experience. Deep learning models, by stark contrast, can be trained to be highly accurate on a narrow task while being highly inefficient in terms of the amount of compute and data required to reach that accuracy. Few-shot learning considers this problem of learning models that generalize to new tasks with very little supervision. Natural language processing (NLP) has seen recent breakthroughs with unsupervised pre-training of large models that can be applied to many NLP tasks, however, few-shot learning of new tasks is still inefficient. In this talk, I will present a sequence of work on meta-learning for improving few-shot learning of NLP tasks. Meta-learning, or learning to learn, treats the learning process itself as a learning problem from data, to learn systems that can generalize to new tasks efficiently. However, meta-learning requires a distribution over tasks with relevant labeled data that can be difficult to obtain, severely limiting the practical utility of meta-learning methods. I will present solutions that construct task distributions from unlabeled text data to enable large-scale meta-learning. The resulting self-supervised meta-learning methods optimize the pre-training directly for future fine-tuning with few examples, which leads to improved few-shot learning of new tasks. By providing useful training tasks for meta-learning, these approaches help lift a pertinent bottleneck for training meta-learning methods and should enable many future applications of meta-learning in NLP, such as hyper-parameter optimization, continual learning, neural architecture search, and more.", "bio": "Trapit is a Ph.D. student advised by Prof. Andrew McCallum at UMass Amherst. His recent research focuses on improving the generalization of natural language processing models with limited human-labeled data through meta-learning, self-supervised learning, and multi-task learning. In the past, he has also worked on machine learning methods for recommendation systems, information extraction, knowledge representation, and reinforcement learning for multi-agent systems. During his Ph.D., he has interned at Facebook, OpenAI, Google Research, and Microsoft Research. His work has also received a best paper award at ICLR 2018. Before starting his Ph.D., he obtained a B.S. and M.S. in Mathematics from the Indian Institute of Technology, Kanpur.", "area": "Meta-learning", "key": "TrapitBansal", "prettyDate": "September 16"}, {"semester": "Fall", "year": "2021", "date": "2021-09-23", "speaker": "Antonio Khalil Moretti (tentative)", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "AntonioKhalilMoretti(tentative)", "prettyDate": "September 23"}, {"semester": "Fall", "year": "2021", "date": "2021-09-30", "speaker": "Jean Honorio (tentative)", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "JeanHonorio(tentative)", "prettyDate": "September 30"}, {"semester": "Fall", "year": "2021", "date": "2021-10-07", "speaker": "Rose Yu", "website": "https://roseyu.com", "title": "Towards Generalizable Deep Dynamics Learning ", "affiliation": "UC San Diego", "sponsor": "Oracle Labs", "video": "", "abstract": "Deep learning holds great promise in accelerating the prediction of physical dynamics relative to numerical solvers. However, current deep learning models for dynamics forecasting struggle with generalization. They only work in a specific domain and fail when applied to systems with different parameters, external forces, or boundary conditions. In this talk, I will demonstrate our efforts in improving the generalization of deep learning for forecasting physical dynamics. I will introduce (1) Equivariant-Net: a model that is inherently equivariant to groups of symmetries and thus generalizes automatically across groups. (2) DyAd: a model-based meta-learning method which can generalize across heterogeneous domains with latent task inference. I will showcase the advantage of our approaches on forecasting Rayleigh B\u00e9nard convection, real-world ocean currents, and temperatures.", "bio": "Dr. Rose Yu is an assistant professor at the University of California San Diego, Department of Computer Science and Engineering. She was a Postdoctoral Fellow at the California Institute of Technology.  Her research focuses on advancing machine learning techniques for large-scale spatiotemporal data analysis, with applications to sustainability, health, and physical sciences. A particular emphasis of her research is on physics-guided AI which aims to integrate first-principles with data-driven models. Among her awards, she has won Faculty Research Award from Facebook, Google, Amazon, and Adobe, Several Best Paper Awards, Best Dissertation Award in USC, and was nominated as one of the \u2019MIT Rising Stars in EECS\u2019. ", "area": "", "key": "RoseYu", "prettyDate": "October 07"}, {"semester": "Fall", "year": "2021", "date": "2021-10-14", "speaker": "Zhou Yu", "website": "http://www.cs.columbia.edu/~zhouyu/", "title": "TBA", "affiliation": "Coumbia University", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "NLP", "key": "ZhouYu", "prettyDate": "October 14"}, {"semester": "Fall", "year": "2021", "date": "2021-10-21", "speaker": "TBA", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "TBA", "prettyDate": "October 21"}, {"semester": "Fall", "year": "2021", "date": "2021-10-28", "speaker": "TBA", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "TBA", "prettyDate": "October 28"}, {"semester": "Fall", "year": "2021", "date": "2021-11-04", "speaker": "TBA", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "TBA", "prettyDate": "November 04"}, {"semester": "Fall", "year": "2021", "date": "2021-11-18", "speaker": "Swetasudha Panda", "website": "", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "", "key": "SwetasudhaPanda", "prettyDate": "November 18"}, {"semester": "Fall", "year": "2021", "date": "2021-12-02", "speaker": "Jonathan Spencer", "website": "https://jspencer12.github.io", "title": "TBA", "affiliation": "", "sponsor": "Oracle Labs", "video": "", "abstract": "TBA", "bio": "TBA", "area": "Imitiation learning", "key": "JonathanSpencer", "prettyDate": "December 02"}]}