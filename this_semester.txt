{"data": [{"semester": "Spring", "year": "2021", "date": "2021-02-11", "speaker": "Tamara Broderick", "website": "https://people.csail.mit.edu/tbroderick/", "title": "An Automatic Finite-Sample Robustness Metric: Can Dropping aLittle Data Change Conclusions?", "affiliation": "MIT", "sponsor": "Oracle Labs", "video": "", "abstract": "We propose a method to assess the sensitivity of data analyses to the removal of a small fraction of the data set. Analyzing all possible data subsets of a certain size is computationally prohibitive, so we provide a finite-data metric to approximately compute the number (or fraction) of observations that has the greatest influence on a given result when dropped. We call our resulting metric the Approximate Maximum Influence Perturbation. Our approximation is automatically computable and works for common estimators (including OLS, IV, GMM, MLE, and variational Bayes). We provide explicit finite-sample error bounds on our approximation for linear and instrumental variables regressions. At minimal computational cost, our metric provides an exact finite-sample lower bound on sensitivity for any estimator, so any non-robustness our metric finds is conclusive. We demonstrate that the Approximate Maximum Influence Perturbation is driven by the signal-to-noise ratio in the inference problem, is not reflected in standard errors, does not disappear asymptotically, and is not a product of misspecification. We focus on econometric analyses in our applications. Several empirical applications show that even 2-parameter linear regression analyses of randomized trials can be highly sensitive. While we find some applications are robust, in others the sign of a treatment effect can be changed by dropping less than 1% of the sample even when standard errors are small. ", "bio": "Tamara Broderick is an Associate Professor in the Department of Electrical Engineering and Computer Science at MIT. She is a member of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), the MIT Statistics and Data Science Center, and the Institute for Data, Systems, and Society (IDSS). She completed her Ph.D. in Statistics at the University of California, Berkeley in 2014. Previously, she received an AB in Mathematics from Princeton University (2007), a Master of Advanced Study for completion of Part III of the Mathematical Tripos from the University of Cambridge (2008), an MPhil by research in Physics from the University of Cambridge (2009), and an MS in Computer Science from the University of California, Berkeley (2013). Her recent research has focused on developing and analyzing models for scalable Bayesian machine learning. She has been awarded an Early Career Grant (ECG) from the Office of Naval Research (2020), an AISTATS Notable Paper Award (2019), an NSF CAREER Award (2018), a Sloan Research Fellowship (2018), an Army Research Office Young Investigator Program (YIP) award (2017), Google Faculty Research Awards, an Amazon Research Award, the ISBA Lifetime Members Junior Researcher Award, the Savage Award (for an outstanding doctoral dissertation in Bayesian theory and methods), the Evelyn Fix Memorial Medal and Citation (for the Ph.D. student on the Berkeley campus showing the greatest promise in statistical research), the Berkeley Fellowship, an NSF Graduate Research Fellowship, a Marshall Scholarship, and the Phi Beta Kappa Prize (for the graduating Princeton senior with the highest academic average).", "area": "ML Theory", "key": "TamaraBroderick", "prettyDate": "February 11"}, {"semester": "Spring", "year": "2021", "date": "2021-02-18", "speaker": "Vered Shwartz", "website": "https://vered1986.github.io/", "title": "Commonsense Knowledge and Reasoning in Natural Language", "affiliation": "AI2", "sponsor": "Oracle Labs", "video": "", "abstract": "Natural language understanding models are trained on a sample of the real-world situations they may encounter. Commonsense and world knowledge, language, and reasoning skills can help them address unknown situations sensibly.\u00a0 In this talk I will present two lines of work addressing commonsense knowledge and reasoning in natural language. I will first present a method for discovering relevant knowledge which is unstated but may be required for solving a particular problem, e.g., to correctly resolve \"Children need to eat more vegetables because they [children / vegetables] are healthy\" one needs to know that \"vegetables are healthy\". Such knowledge is discovered through a process of asking information seeking clarification questions (e.g. \"what is the purpose of vegetables?\") and answering them (\"to provide nutrients\"). I will then discuss nonmonotonic reasoning in natural language, a core human reasoning ability that has been studied in classical AI but mostly overlooked in modern NLP. I will talk about several recent papers addressing abductive reasoning (reasoning about plausible explanations), counterfactual reasoning (what if?) and defeasible reasoning (updating beliefs given additional information). Finally, I will discuss open problems in language, knowledge, and reasoning. ", "bio": "Vered Shwartz is a postdoctoral researcher at the Allen Institute for AI (AI2) and the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Previously, she completed her PhD in Computer Science from Bar-Ilan University, under the supervision of Prof. Ido Dagan. Her research interests include commonsense reasoning, lexical and compositional semantics.", "area": "NLP", "key": "VeredShwartz", "prettyDate": "February 18"}, {"semester": "Spring", "year": "2021", "date": "2021-02-25", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "February 25"}, {"semester": "Spring", "year": "2021", "date": "2021-03-04", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "March 04"}, {"semester": "Spring", "year": "2021", "date": "2021-03-11", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "March 11"}, {"semester": "Spring", "year": "2021", "date": "2021-03-25", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "March 25"}, {"semester": "Spring", "year": "2021", "date": "2021-04-01", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "April 01"}, {"semester": "Spring", "year": "2021", "date": "2021-04-08", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "April 08"}, {"semester": "Spring", "year": "2021", "date": "2021-04-15", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "April 15"}, {"semester": "Spring", "year": "2021", "date": "2021-04-29", "speaker": "TBA", "website": "", "title": "", "affiliation": "", "sponsor": "", "video": "", "abstract": "", "bio": "", "area": "", "key": "TBA", "prettyDate": "April 29"}]}
