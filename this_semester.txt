{"data": [{"website": "https://www.cs.cmu.edu/~jwieting/", "bio": "John Wieting is a recent PhD graduate of the Language Technology Institute at Carnegie Mellon University, where he was supervised by Graham Neubig and Taylor Berg-Kirkpatrick. He currently is a research scientist at Google Research. Previously he worked with Kevin Gimpel at the Toyota Technological Institute-Chicago, and completed his MS under the guidance of Dan Roth at the University of Illinois Urbana-Champaign. His research focuses on representation learning and its applications for natural language processing. He is also interested in language generation, with a particular interest in paraphrasing and related tasks.", "prettyDate": "September 24", "title": "Learning and Applications of Paraphrastic Representations for Natural Language", "abstract": "Representation learning has had a tremendous impact in machine learning and natural language processing (NLP), especially in recent years. Learned representations provide useful features needed for downstream tasks, allowing models to incorporate knowledge from billions of tokens of text. The result is better performance and generalization on many important problems of interest. This talk focuses on the problem of learning paraphrastic representations for units of language spanning from sub-words to full sentences \u2013 the latter being a focal point. Our primary goal is to learn models that can encode arbitrary word sequences into a vector with the property that sequences with similar semantics are near each other in the learned vector space, and that this property transfers across domains. We first show several simple, but effective, models to learn word and sentence representations on noisy paraphrases automatically extracted from bilingual corpora. These models outperform contemporary models on a variety of semantic evaluations. We then propose techniques to enable deep networks to learn effective semantic representations, addressing a limitation of our prior work. We also automatically construct a large paraphrase corpus that improves the performance of all our studied models, especially those using deep architectures, and has found uses for a variety of generation tasks such as paraphrase generation and style-transfer. We next propose models for multilingual paraphrastic sentence representations. Again, we first propose a simple and effective approach that outperforms more complicated methods on cross-lingual sentence similarity and mining bitext. We then propose a generative model that concentrates semantic information into a single interlingua representations and pushes information responsible for linguistic variation to separate language-specific representations. We show that this model has improved performance on both monolingual and cross-lingual tasks over prior work and successfully disentangles these two sources of information. Finally, we apply our representations to the task of fine-tuning neural machine translation systems using minimum risk training. The conventional approach is to use BLEU (Papineni et al., 2002), since that is commonly used for evaluation. However, we found that using an embedding model to evaluate similarity allows the range of possible scores to be continuous and, as a result, introduces fine-grained distinctions between similar translations. The result is better performance on both human evaluations and BLEU score, along with faster convergence during training.", "area": "NLP", "affiliation": "CMU", "semester": "Fall", "speaker": "John Wieting", "sponsor": "Oracle Labs", "key": "JohnWieting", "year": "2020", "date": "2020-09-24", "video": "https://youtu.be/tQc1i4mgH-A"}, {"website": "https://people.csail.mit.edu/dharwath/", "bio": "David Harwath is an assistant professor in the computer science department at The University of Texas at Austin. Prior to joining UT, he was a research scientist in the Spoken Language Systems group at the MIT Computer Science and Artificial Intelligence Lab (CSAIL). His research focuses on multi-modal learning algorithms for speech, audio, vision, and text. His work has been published at venues such as NeurIPS, ACL, ICASSP, ECCV, and CVPR, and was nominated for a best paper award at ASRU 2015. Under the supervision of James Glass, his doctoral thesis introduced models for the joint perception of speech and vision. This work was awarded the 2018 George M. Sprowls Award for the best Ph.D. thesis in computer science at MIT. He holds a Ph.D. in computer science from MIT (2018), a S.M. in computer science from MIT (2013), and a\u00a0 B.S. in electrical engineering from UIUC (2010).", "prettyDate": "October 01", "title": "Learning Spoken Language Through Vision", "abstract": "Humans learn spoken language and visual perception at an early age by being immersed in the world around them. Why can't computers do the same? In this talk, I will describe our work to develop methodologies for grounding continuous speech signals at the raw waveform level to natural image scenes. I will first present self-supervised models capable of jointly discovering spoken words and the visual objects to which they refer, all without conventional annotations in either modality. I will show how the representations learned by these models implicitly capture meaningful linguistic structure directly from the speech signal. Finally, I will demonstrate that these models can be applied across multiple languages, and that the visual domain can function as an \"interlingua,\" enabling the discovery of word-level semantic translations at the waveform level.", "area": "Multimodal perception", "affiliation": "MIT", "semester": "Fall", "speaker": "David Harwath", "sponsor": "Oracle Labs", "key": "DavidHarwath", "year": "2020", "date": "2020-10-01", "video": ""}, {"website": "https://people.csail.mit.edu/liyunzhu/", "bio": "TBA", "prettyDate": "October 08", "title": "TBA", "abstract": "TBA", "area": "Vision/Robotics", "affiliation": "MIT", "semester": "Fall", "speaker": "Yunzhu Li", "sponsor": "Oracle Labs", "key": "YunzhuLi", "year": "2020", "date": "2020-10-08", "video": ""}, {"website": "https://cseweb.ucsd.edu/~fmireshg/", "bio": "TBA", "prettyDate": "October 15", "title": "TBA", "abstract": "TBA", "area": "Privacy for ML", "affiliation": "UCSD", "semester": "Fall", "speaker": "Fatemeh Mireshghallah", "sponsor": "Oracle Labs", "key": "FatemehMireshghallah", "year": "2020", "date": "2020-10-15", "video": ""}, {"website": "https://www.ccs.neu.edu/home/mgualti/", "bio": "TBA", "prettyDate": "October 22", "title": "TBA", "abstract": "TBA", "area": "Deep RL", "affiliation": "Northeastern University", "semester": "Fall", "speaker": "Marcus Gualtieri", "sponsor": "Oracle Labs", "key": "MarcusGualtieri", "year": "2020", "date": "2020-10-22", "video": ""}, {"website": "https://www.kaleshabullard.com/", "bio": "TBA", "prettyDate": "October 29", "title": "TBA", "abstract": "TBA", "area": "Multi-Agent Reinforcement Learning", "affiliation": "FAIR", "semester": "Fall", "speaker": "Kalesha Bullard", "sponsor": "Oracle Labs", "key": "KaleshaBullard", "year": "2020", "date": "2020-10-29", "video": ""}, {"website": "https://research.google/people/104995/", "bio": "TBA", "prettyDate": "November 05", "title": "TBA", "abstract": "TBA", "area": "NLP", "affiliation": "Google", "semester": "Fall", "speaker": "Ankur Parikh", "sponsor": "Oracle Labs", "key": "AnkurParikh", "year": "2020", "date": "2020-11-05", "video": ""}, {"website": "https://web.mit.edu/krallen/www/", "bio": "TBA", "prettyDate": "November 19", "title": "TBA", "abstract": "TBA", "area": "Robotics", "affiliation": "MIT", "semester": "Fall", "speaker": "Kelsey Allen", "sponsor": "Oracle Labs", "key": "KelseyAllen", "year": "2020", "date": "2020-11-19", "video": ""}, {"website": "https://mariadearteaga.com/", "bio": "TBA", "prettyDate": "November 12", "title": "TBA", "abstract": "TBA", "area": "Human-centered ML", "affiliation": "UT Austin", "semester": "Fall", "speaker": "Maria De-Arteaga", "sponsor": "Oracle Labs", "key": "MariaDe-Arteaga", "year": "2020", "date": "2020-11-12", "video": ""}]}