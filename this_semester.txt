{"data": [{"website": "http://www.ccs.neu.edu/home/mgualti/", "bio": "TBA", "prettyDate": "April 23", "title": "Postponed to Fall 2020 due to COVID-19", "abstract": "TBA", "area": "Deep RL", "affiliation": "Northeastern University", "semester": "Spring", "speaker": "Marcus Gualtieri", "sponsor": "Oracle Labs", "key": "MarcusGualtieri", "year": "2020", "date": "2020-04-23", "video": ""}, {"website": "https://people.csail.mit.edu/liyunzhu/", "bio": "TBA", "prettyDate": "April 15", "title": "Postponed to Fall 2020 due to COVID-19", "abstract": "TBA", "area": "Vision/Robotics", "affiliation": "MIT", "semester": "Spring", "speaker": "Yunzhu Li", "sponsor": "Oracle Labs", "key": "YunzhuLi", "year": "2020", "date": "2020-04-15", "video": ""}, {"website": "https://web.mit.edu/krallen/www/", "bio": "TBA", "prettyDate": "April 09", "title": "Postponed to Fall 2020 due to COVID-19", "abstract": "TBA", "area": "Robotics", "affiliation": "MIT", "semester": "Spring", "speaker": "Kelsey Allen", "sponsor": "Oracle Labs", "key": "KelseyAllen", "year": "2020", "date": "2020-04-09", "video": ""}, {"website": "https://people.csail.mit.edu/belinkov/", "bio": "Yonatan Belinkov is a Postdoctoral Fellow at the Harvard School of Engineering and Applied Sciences (SEAS) and the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). His research focuses on interpretability and robustness of neural network models of human language. His research has been published at various NLP/ML venues. His PhD dissertation at MIT analyzed internal language representations in deep learning models, with applications to machine translation and speech recognition. He is a Harvard Mind, Brain, and Behavior Fellow. He will be joining the Technion Computer Science department in Fall 2020.", "prettyDate": "April 02", "title": "Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias", "abstract": "The success of neural network models in various tasks, coupled with their opaque nature, has led to much interest in interpreting and analyzing such models. Common analysis methods for interpreting neural models in natural language processing typically examine either their structure (for example, probing classifiers) or their behavior (challenge sets, saliency methods), but not both. In this talk, I will propose a new methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. This methodology enables us to analyze the mechanisms by which information flows from input to output through various model components, known as mediators. I will demonstrate an application of this methodology to analyzing gender bias in pre-trained Transformer language models. In particular, we study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model\u2019s sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are (i) sparse, concentrated in a small part of the network; (ii) synergistic, amplified or repressed by different components; and (iii) de-composable into effects flowing directly from the input and indirectly through the mediators. I will conclude by laying out a few ideas for future work on analyzing neural NLP models. ", "area": "NLP", "affiliation": "MIT", "semester": "Spring", "speaker": "Yonatan Belinkov", "sponsor": "Oracle Labs", "key": "YonatanBelinkov", "year": "2020", "date": "2020-04-02", "video": ""}, {"website": "https://www.bu.edu/cs/profiles/kate-saenko/", "bio": "TBA", "prettyDate": "March 26", "title": "Postponed to Fall 2020 due to COVID-19", "abstract": "TBA", "area": "Vision", "affiliation": "BU", "semester": "Spring", "speaker": "Kate Saenko", "sponsor": "Oracle Labs", "key": "KateSaenko", "year": "2020", "date": "2020-03-26", "video": ""}, {"website": "https://sfish0101.bitbucket.io/", "bio": "Hsiao-Yu (Fish) Tung is a fifth-year PhD student in the Machine Learning Department at CMU, advised by Professor Katerina Fragkiadaki. She is interested in building machines that can understand and interact with the world. Her research spans across unsupervised learning, computer vision, graphics, robotics, and language. She is selected for the 2019 Rising Stars in EECS program. Her research is supported by the Yahoo InMind fellowship. She received her M.S. in CMU MLD and B.S. in Electrical Engineering from National Taiwan University. During her master degree, she worked with Professor Alex Smola on spectral method for Bayesian models and had designed efficient and provable algorithms for unsupervised topic discovery.", "prettyDate": "March 12", "title": "Postponed to Fall 2020 due to COVID-19", "abstract": "Current state-of-the-art CNNs can localize and name objects in internet photos, yet, they miss the basic knowledge that a two-year-old toddler has possessed: objects persist over time despite changes in the camera view, they have 3D extent, they do not 3D intersect, and so on. In this talk, I will introduce neural architectures that learn to parse video streams of a static scene into world-centric 3D feature maps by disentangling camera motion from scene appearance.  I will show the proposed architectures learn object permanence, can generate RGB views from novel viewpoints in truly novel scenes, can infer affordability in sentences by grounding language in 3D visual simulations, and can learn intuitive physics in a persistent 3D feature space. Our experiments suggest that the proposed architecture is essential to generalize across objects and locations, and it overcomes many limitations of 2D CNNs.", "area": "Vision", "affiliation": "CMU", "semester": "Spring", "speaker": "Hsiao-Yu (Fish) Tung", "sponsor": "Oracle Labs", "key": "Hsiao-Yu(Fish)Tung", "year": "2020", "date": "2020-03-12", "video": ""}, {"website": "https://cra.org/cra-wp/amanda-stent/", "bio": "Amanda Stent is a NLP architect in the data science group in the office of the CTO at Bloomberg LP. Previously, she was a director of research and principal research scientist at Yahoo Labs, a principal member of technical staff at AT&T Labs - Research, and an associate professor in the Computer Science Department at Stony Brook University. Her research interests center on natural language processing and its applications. She holds a PhD in computer science from the University of Rochester. She is co-editor of the book Natural Language Generation in Interactive Systems (Cambridge University Press), has co-authored over 100 papers on natural language processing and is co-inventor on over 25 patents and patent applications.", "prettyDate": "March 05", "title": "NLP for Natural Documents", "abstract": "Today's finance industry is continuously searching for alpha, through more advanced modeling and through alternative sources of data. Many alternative sources of data are not raw numerical data but natural documents - human-readable documents containing tables, graphics and text. In this talk, I will present an overview of how we use NLP at Bloomberg to extract information from natural documents, and highlight some research challenges. I also present a case study of how such information can be combined with market data for better predictive modeling.", "area": "NLP", "affiliation": "Bloomberg", "semester": "Spring", "speaker": "Amanda Stent", "sponsor": "Oracle Labs", "key": "AmandaStent", "year": "2020", "date": "2020-03-05", "video": ""}, {"website": "", "bio": "Weiwei received her Ph.D. in pure math from Wesleyan University, where she specialized in higher categorical structures in algebraic topology, and her post-doctoral work at Goettingen Unversity involved categorification of knot invariants. At Harvard, Weiwei works with Finale Doshi-Velez (Harvard dtak) on deep Bayesian and generative models focusing on modeling complex forms of uncertainty and noise, as well as on developing inference methods that enforce down-stream task desiderata.", "prettyDate": "February 20", "title": "What Are Useful Uncertainties in Deep Learning and How Do We Get Them?", "abstract": "While deep learning has demonstrable success on many tasks, the point estimates provided by standard deep models can lead to overfitting and provide no uncertainty quantification on predictions.\u00a0 However, when models are applied to critical domains such as autonomous driving, precision health care, or criminal justice, reliable measurements of a model's predictive uncertainty may be as crucial as correctness of its predictions. At the same time, increasing attention in recent literature is being paid to separating sources of predictive uncertainty, with the goal of separating types of uncertainties reducible through additional data collection from those that represent stochasticity inherent in the data generation process. In this talk, we examine a number of deep (Bayesian) models that promise to capture complex forms for predictive uncertainties, we also examine metrics commonly used to such uncertainties. We aim to highlight strengths and limitations of the models as well as the metrics; we also discuss potential ways to improve both in meaningful ways for downstream tasks.", "area": "ML", "affiliation": "Harvard University", "semester": "Spring", "speaker": "Weiwei Pan", "sponsor": "Oracle Labs", "key": "WeiweiPan", "year": "2020", "date": "2020-02-20", "video": ""}, {"website": "http://people.inf.ethz.ch/ganeao/", "bio": "I am a postdoctoral researcher in the group of prof. T. Jaakkola and prof. R. Barzilay at CSAIL-MIT. Previously I obtained my PhD from the Data Analytics Lab at ETH Zurich under the supervision of prof. Thomas Hofmann. I am broadly interested in representation learning for text, graphs or images through statistical or geometric models that could be devised and understood in a mathematically principled manner. In particular, I have recently explored finding and learning latent hierarchical structures in data via hyperbolic geometry.  ", "prettyDate": "February 13", "title": "Hyperbolic Geometry in Machine Learning", "abstract": "Based on my PhD work. Slides: https://docs.google.com/presentation/d/1dheg6Ul6zQj9tlMLIf-YnU2sNzWI0MbJCej5xAzRL5c/edit#slide=id.p", "area": "NLP", "affiliation": "MIT", "semester": "Spring", "speaker": "Octavian Ganea", "sponsor": "Oracle Labs", "key": "OctavianGanea", "year": "2020", "date": "2020-02-13", "video": ""}, {"website": "https://yangqian.myportfolio.com/", "bio": "Qian Yang is an interaction design researcher and a Ph.D. candidate at the Human-Computer Interaction Institute at Carnegie Mellon University. Her research focuses on the design and innovation of human-AI interactions. She is best known for designing machine learning systems that effectively aided doctors in making critical clinical decisions. During her Ph.D., Yang has published fifteen peer-reviewed publications on the topic of human-AI interaction at premiere HCI research venus. Four of these papers have received awards. Yang has won a fellowship from the Center for Machine Learning and Health, a Microsoft Research Dissertation Grant, and the Innovation by Design award from Fast Company. This Spring she will be speaking at SXSW on how to design AI products and services.", "prettyDate": "January 30", "title": "Leveraging AI as a Material for User Experience Design", "abstract": "Advances in AI promise to improve people's lives and societies. As these systems migrate from research labs into the real world, new challenges have emerged. For example, how should predictive models form an effective team with physicians in clinical decision making? How could the designs of AI-mediated social networks prevent unintended consequences such as data-driven inequality? These are challenges of translation: translating AI's algorithmic advances into valuable, situated human experiences. This talk focuses on this critical translation. I will share a range of human-AI interaction design projects: from designing a system that helps doctors make life-and-death clinical decisions in real practice, to leveraging Natural Language Generation systems to improve authors\u2019 writing experience. Each design addressed a critical challenge in moving AI from research labs valuably into the real world. I outline a new framework that scaffolds the problem space of human-AI interaction design. I discuss the opportunities and challenges it reveals for both AI and user experience research.  ", "area": "HCI + ML", "affiliation": "CMU", "semester": "Spring", "speaker": "Qian Yang", "sponsor": "Oracle Labs", "key": "QianYang", "year": "2020", "date": "2020-01-30", "video": "https://www.youtube.com/watch?v=Oxgal1rfJss"}]}