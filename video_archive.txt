{"data": [{"": "", "website": "https://people.cs.umass.edu/~pat/", "title": "Neural Knowledge Representation and Reasoning", "abstract": "Making complex decisions in science, government policy, finance, and clinical treatments all require integrating and reasoning over disparate sources of information. While some decisions can be made from a single piece of evidence, others require considering information that exists outside of the current context. A long-term store of abstracted knowledge over related concepts can facilitate this type of reasoning, while also influencing interpretation as well as enhancing the acquisition of new knowledge. A symbolic graph over a fixed, human-defined schema encoding facts about entities and their relations is the predominant method of representing knowledge, but this method is brittle, lacks specificity, and is inevitably highly incomplete. On the other extreme, recent work on purely text based knowledge models lack abstractions necessary for complex reasoning. In this talk I will present a middle ground incorporating powerful neural network models with rich structured ontologies and unstructured raw text to improve the representations of entities and their relations. We first discuss our work on universal schema, a method for learning a latent schema over both existing structured resources and unstructured free text data, embedding them jointly within a shared semantic space. Next we inject additional hierarchical structure into the embedding space of concepts, resulting in more efficient statistical sharing amongst related concepts and improving accuracy in both fine-grained entity typing and linking. We then present initial work to represent knowledge in context, including a single model for extracting all entities and long-range relations simultaneously over full paragraphs while jointly linking these entities to a knowledge graph. Lastly, we propose future directions for representing knowledge in context by incorporating cognitive theories of human memory systems and discuss how these models can address longstanding shortcomings in knowledge representation.", "affiliation": "UMass, Amherst", "semester": "Spring", "speaker": "Patrick Verga", "sponsor": "Oracle Labs", "bio": "Patrick Verga is a final year PhD candidate in the College of Information and Computer Sciences at UMass Amherst, advised by Andrew McCallum. His research contributes to knowledge representation and reasoning, with a focus on large knowledge base construction from unstructured text, with applications to general domain, commonsense, and biomedicine. Pat previously interned at Google and the Chan Zuckerberg Initiative and received the best long paper award at EMNLP 2018. Over the past several years he has advised multiple M.S. and junior PhD students, resulting in published research in fine-grained entity typing, unsupervised parsing, and partially labeled named entity extraction. He holds M.S. and B.A degrees in computer science as well as a B.S. in neuroscience.", "year": "2019", "date": "2019-02-14", "video": "https://youtube.com/BNQLWb4V7s0"}, {"": "", "website": "http://irenechen.net/", "title": "Why is my classifier discriminatory?", "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.", "affiliation": "MIT CSAIL", "semester": "Spring", "speaker": "Irene Chen", "sponsor": "Oracle Labs", "bio": "Irene Chen is a PhD student at MIT in Electrical Engineering and Computer Science in the Clinical Machine Learning Group. Her research focuses on building machine learning methods that to advance knowledge in health care and fairness. Before MIT, she received her AB/SM from Harvard in Applied Math and Computational Engineering and worked at Dropbox for two years as a Data Scientist, Machine Learning Engineer, and Chief of Staff.", "year": "2019", "date": "2019-02-21", "video": "https://youtube.com/gbvloQN2NiA"}]}