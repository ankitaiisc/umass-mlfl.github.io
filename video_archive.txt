{"data": [{"website": "https://www.cs.cmu.edu/~bdhingra/", "bio": "Bhuwan Dhingra is a final year PhD student at Carnegie Mellon University, advised by William Cohen and Ruslan Salakhutdinov. His research uses natural language processing and machine learning to build an interface between AI applications and world knowledge (facts about people, places and things). His work is supported by the Siemens FutureMakers PhD fellowship. Prior to joining CMU, Bhuwan completed his undergraduate studies at IIT Kanpur in 2013, and spent two years at Qualcomm Research in the beautiful city of San Diego.", "title": "Text as a Virtual Knowledge Base", "abstract": "Structured Knowledge Bases (KBs) are extremely useful for applications such as question answering and dialog, but are difficult to populate and maintain. People prefer expressing information in natural language, and hence text corpora, such as Wikipedia, contain more detailed up-to-date information. This raises the question -- can we directly treat text corpora as knowledge bases for extracting information on demand? In this talk I will focus on two problems related to this question. First, I will look at augmenting incomplete KBs with textual knowledge for question answering. I will describe a graph neural network model for processing heterogeneous data from the two sources. Next, I will describe a scalable approach for compositional reasoning over the contents of the text corpus, analogous to following a path of relations in a structured KB to answer multi-hop queries. I will conclude by discussing interesting future research directions in this domain.", "affiliation": "Carnegie Mellon University", "semester": "Fall", "speaker": "Bhuwan Dhingra", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-12-05", "video": "https://www.youtube.com/watch?v=0qaL7A7gM8U"}, {"website": "https://www.cc.gatech.edu/~dyang888/", "bio": "Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech, also affiliated with the Machine Learning Center (ML@GT) at Georgia Tech. Diyi received her PhD from the Language Technologies Institute at Carnegie Mellon University, and her bachelor's degree from Shanghai Jiao Tong University, China. She is interested in computational semantics of human language (such as text analysis, generation, discourse) and computational social science. She has published more than 40 papers at leading NLP/HCI conferences and journals, and received one Notable Dataset Award from EMNLP 2015, one Best Paper Award Nomination from ICWSM 2016, and two Best Paper Honorable Mentions from SIGCHI 2019. Diyi has been awarded Carnegie Mellon Presidential Fellowship and Facebook Ph.D. Fellowship.", "title": "Building Language Technologies for Better Online Communities", "abstract": "We live in an era where many aspects of our daily activities are recorded as textual and activity data, from social media posts, to medical and financial records, to work activities captured by Wikipedia and other online tools. My research combines techniques in natural language processing, machine learning and theories in social science to study human behavior in online communities, with the goal of developing theories and systems to build better socio-technical systems. In this talk, I will explain my research from two specific studies. The first one studies what makes language persuasive by introducing a simple semi-supervised neural network to recognize persuasion strategies in loan requests on crowdfunding platforms.  The second focuses on modeling how people seek and offer support via language in online cancer support communities and building interventions to support patient communication.  Through these two examples, I show how we can accurately and efficiently model human communication to build better social systems", "affiliation": "Georgia Tech", "semester": "Fall", "speaker": "Diyi Yang", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-21", "video": "https://www.youtube.com/watch?v=19UgKTd2rFA"}, {"website": "https://sites.google.com/site/ssamadi/", "bio": "Samira Samadi is a Ph.D. candidate at the School of Computer Science, Georgia Tech where she works with Santosh Vempala. Prior to this, she was a research associate at the School of Computer Science at the University of Waterloo where she worked with Shai Ben-David. She received her M.Sc. in Computer Science from the University of British Columbia under the supervision of Nick Harvey and her B.Sc. in Mathematics at the Sharif University of Technology. Her primary research interests are in ethics in AI, machine learning, algorithms, and human computation.", "title": "Fair Machine Learning: PCA and Spectral Clustering", "abstract": "In this talk, I investigate several ML paradigms from the viewpoint of fairness. In the first line of work, I study fairness for Principal Component Analysis (PCA), one of the most commonly used dimensionality reduction techniques. I show on real-world data sets that PCA can inadvertently produce low-dimensional representations with different fidelity for two different demographics. This motivates our study of Fair PCA and more generally multi-criteria dimensionality reduction. I present an exact polynomial-time algorithm for Fair PCA when there are two demographics in the data and approximation algorithms for a broad class of multi-criteria dimensionality reduction when there are multiple demographic groups. In the second line of work, I study spectral clustering (SC) with the constraint that every demographic is proportionally represented in each cluster. We develop variants of both normalized and unnormalized constrained SC and show that they help find fairer clusterings on both synthetic and real data. We also provide a theoretical analysis of our algorithms on a natural variant of the stochastic block model, where the demographic groups have strong inter-group connectivity, but also exhibit a \u201cnatural\u201d clustering structure which is proportionally balanced. We prove that our algorithms can recover this underlying balanced clustering with high probability.", "affiliation": "Georgia Tech", "semester": "Fall", "speaker": "Samira Samadi", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-14", "video": "https://www.youtube.com/watch?v=drkJcv9WT6Y"}, {"website": "http://www.cs.columbia.edu/~vondrick/", "bio": "Carl Vondrick is an Assistant Professor of Computer Science at Columbia University. Previously, he was a research scientist at Google. He completed his Ph.D. at the Massachusetts Institute of Technology in 2017.", "title": "Learning from Unlabeled Video", "abstract": "I will discuss our research to use large amounts of unlabeled video in order to efficiently train models for visual recognition. Leveraging millions of videos, our work develops methods for machines to learn perception tasks such as anticipating human actions in the immediate future, tracking visual objects, and recognizing ambient sounds.  We show how to take advantage of the natural context available in video in order to learn without human supervision, for example through the natural synchronization of vision and sound, or the temporal coherence of motion and color.", "affiliation": "Columbia University.", "semester": "Fall", "speaker": "Carl Vondrick", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-11-06", "video": "https://www.youtube.com/watch?v=9aR0-mK1GhI"}, {"website": "https://ziw.mit.edu/", "bio": "Zi Wang is a Ph.D. candidate at MIT Computer Science and Artificial Intelligence Laboratory advised by Prof. Leslie Pack Kaelbling and Prof. Tomas Lozano-Perez. Her PhD research focuses on tackling problems related to robot learning, active learning for planning and Bayesian optimization. She received her M.S. degree in Electrical Engineering and Computer Science from MIT in Feb 2016 and B.Eng. degree in Computer Science and Technology from Tsinghua University in Jul 2014. Zi is a recipient of MIT Graduate Women of Excellence Award, Rising Star in EECS and Google Anita Borg Scholarship. While at MIT, she served as co-president of Graduate Women in Course 6 (EECS), co-organizer of the first Machine Learning Across MIT Retreat and research mentor for several undergraduate and MEng students.", "title": "Bayesian Optimization for Global Optimization of Expensive Black-box Functions", "abstract": "Many problems in areas ranging from finance and product design to engineering in general all boil down to the problem of optimizing expensive black-box functions. Bayesian optimization uses probabilistic methods to address this problem with assumptions usually expressed by a Gaussian process prior. Motivated by real-world applications in high-dimensional parameter-tuning problems for complex machine learning algorithms and expensive active learning problems in robotics, we study the theoretical understandings of Bayesian optimization, connections among existing methods, and develop efficient and provably correct Bayesian optimization methods for these applications. In this talk, I will give an in-depth tour of our study of Bayesian optimization on how to design a better data acquisition strategy, how to scale up the method to higher-dimensional and larger-scale data and how to analyze the sample complexity without assuming the full knowledge of the prior. Finally, I will also briefly show how we utilized some of these ideas to tackle problems in robot learning and planning for complex long-horizon problems.", "affiliation": "MIT", "semester": "Fall", "speaker": "Zi Wang", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-31", "video": "https://www.youtube.com/watch?v=Fufcr5As3AI"}, {"website": "https://www.cs.cornell.edu/~laurejt/", "bio": "Laure Thompson is a final-year Ph.D. candidate in Computer Science at Cornell University where she is advised by David Mimno. Her research interests are in the areas of natural language processing, machine learning, and digital humanities. Driven by humanistic applications, her work uses a wide range of cultural heritage corpora: from texts of science fiction novels and the Patrologia Graeca to images of avant-garde journals and engraved gemstones. Laure is a recipient of an NSF Graduate Research Fellowship and a COLING best paper award. She received her bachelor's degrees in computer science and electrical engineering with minors in mathematics and classical studies from the University of Washington in 2013.", "title": "Understanding and Directing What Models Learn", "abstract": "Machine learning and statistical methods, such as unsupervised semantic models, are popular and useful techniques for making massive digital collections more explorable and analyzable. But what underlying patterns do these models actually learn, and which patterns are they most likely to repeatedly learn? Moreover, how might we direct what these models learn so that they are useful to a wider range of scholarly inquiry? For example, while it might be useful to organize novels by authors, learning this structure is seldom useful when already known and can be problematic if it is mischaracterized as a cross-cutting pattern. In this talk, I will discuss my recent work on measuring and mitigating topic-metadata correlation in topic models. I will show how intentional data modification can make topics more cross-cutting, specific, and stable.", "affiliation": "Cornell University", "semester": "Fall", "speaker": "Laure Thompson", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-23", "video": "https://www.youtube.com/watch?v=_0NDe9EU88s"}, {"website": "https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Veronika.Thost", "bio": "Veronika is a Postdoctoral Researcher in the MIT-IBM Watson AI Lab at IBM Research, Cambridge, MA. Her work focuses on the combination of symbolic knowledge representations and reasoning with learning: on learning logical theories and to guide reasoning over such theories, and on how the information in knowledge graphs can be used as structured, external knowledge to support learning. Previously, Veronika worked as a Postdoctoral Researcher at TU Dresden, Germany, where she also received her Ph.D. in Computer Science in 2017. At that time, she worked on query answering over knowledge graphs, existential rules, and in description logics. Her work has been published at IJCAI, KR, ISWC, ESWC, KR, JWS, and TOCL", "title": "Knowledge Representations & Reasoning Meets Machine Learning", "abstract": "In many domains, there is structured knowledge which can be leveraged for reasoning in an informed way in order to obtain high quality answers. Symbolic approaches for knowledge representation and reasoning are less prominent today - mainly due to their lack of scalability - but their strength lies in the verifiable and interpretable reasoning that can be accomplished. In this talk, we present work about how symbolic knowledge representations and reasoning can be combined with machine learning. We will present new datasets to evaluate logical rule learning, show how reinforcement learning can support logical reasoning, and consider knowledge graphs as external information for learning (e.g., for recognizing textual entailment).", "affiliation": "", "semester": "Fall", "speaker": "Veronika Thost", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-16", "video": "https://www.youtube.com/watch?v=2lXEv2sph2I"}, {"website": "https://gvanhorn38.github.io/", "bio": "Grant is a postdoc at Cornell Lab of Ornithology. He earned his PhD at Caltech advised by Prof. Pietro Perona, and BS and MS degrees at UCSD advised by Prof. Serge Belongie. His research focuses on efficient dataset collection and fine-grained visual categorization, particularly for the natural world. He works closely with iNaturalist and the Cornell Lab of Ornithology where he puts his research into production.", "title": "Visipedia + iNaturalist: integrating machine learning into a naturalist community", "abstract": "iNaturalist is a community of over 2 million nature enthusiasts that share observations of the natural world. These observations consist of at least one photo, a GPS coordinate, and a taxonomic label from the tree of life. The iNaturalist community has recorded over 30 million observations of organisms from around the world. These recordings are exported to GBIF for scientists and conservationists to use in research and reports. As the iNaturalist community grows and the expertise becomes more diffuse, the need for automation becomes crucial for maintaining an engaging user experience and for ensuring the accuracy of data exported to GBIF. In this talk I will describe our work on learning the taxonomic identification skills of iNaturalist users, using these skills to assign taxonomic labels to images, and subsequently training computer vision systems on the resulting dataset. These computer vision systems can be accessed in the Apple App Store or Google Play Store in both the \u201ciNaturalist\u201d and \u201cSeek by iNaturalist\u201d apps as well as the iNaturalist website.", "affiliation": "", "semester": "Fall", "speaker": "Grant Van Horn", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-10", "video": "https://www.youtube.com/watch?v=KRTj3Xl6ldw"}, {"website": "https://www.cs.cmu.edu/~sprabhum/", "bio": "Shrimai is a second-year Ph.D. student at Language Technologies, School of Computer Science, Carnegie Mellon University. She is advised by\u00a0Prof. Alan W Black\u00a0and\u00a0Prof. Ruslan Salakhutdinov. She is broadly interested in natural language generation with special focus on style transfer and content transfer. During the course of her Ph.D., she has interned at Facebook AI Research and Microsoft Research.", "title": "Controlling style, content, and structure in natural language generation", "abstract": "The 21st century is witnessing a major shift in the way people interact with technology and Natural Language Generation (NLG) is playing a central role. The increasing ubiquity of computing technologies has led to situation-aware applications that are required to produce naturalistic (informative, coherent, and appropriate) outputs. But situation-aware NLG is hard. Devices must not only generate natural sentences - already a challenging task - but include ever more complex data as inputs, and sound more natural every year. How can we expect machines to understand this and make the right choice for what to say? Solving a problem like this requires tackling at least three core tasks of NLG. The first is content determination: the information to be conveyed. Next comes discourse planning: the structure that a document will take on when it is articulated, given the preceding context and the rhetorical intent of the speaker. And finally, lexicalization: the particular words and phrases that convey the content of a sentence with a particular style or tone, given the appropriate structure in the discourse context.", "affiliation": "Carnegie Mellon University", "semester": "Fall", "speaker": "Shrimai Prabhumoye", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-10-03", "video": "https://www.youtube.com/watch?v=p3XRBkvCUrg"}, {"website": "http://www.byronwallace.com/", "bio": "Byron Wallace is an assistant professor in the Khoury College of Computer Sciences at Northeastern University. He holds a PhD in Computer Science from Tufts University, where he was advised by Carla Brodley. He has previously held faculty positions at the University of Texas at Austin and at Brown University. His research is in machine learning and natural language processing, with an emphasis on their application in health informatics.  Wallace's work has been supported by grants from the National Science Foundation (including a CAREER award), the National Institutes for Health, and the Army Research Office. He won the Tufts University 2012 Outstanding Graduate Researcher award, and his thesis work was recognized as The Runner Up for the 2013 ACM Special Interest Group on Knowledge Discovery and Data Mining (SIG KDD) Dissertation Award. He co-authored the winning submission for the Health Care Data Analytics Challenge at the 2015 IEEE International Conference on Healthcare Informatics, and co-authored the 2017 Distinguished Clinical Research Informatics Paper Award winner at the American Medical Informatics Association Joint Summits on Translational Sciences. He also received the 2018 Early Career Award from the Society for Research Synthesis.", "title": "What does the evidence say? Models to help make sense of the biomedical literature", "abstract": "How do we know if a particular medical intervention actually works better than the alternatives for a given condition and outcome? Ideally one would consult all available evidence from relevant trials that have been conducted to answer this question. Unfortunately, such results are primarily disseminated in natural language articles that describe the conduct and results of clinical trials. This imposes substantial burden on physicians and other domain experts trying to make sense of the evidence. In this talk I will discuss work on designing tasks, corpora, and models that aim to realize natural language technologies that can extract key attributes of clinical trials from articles describing them, and infer the reported findings regarding these. The hope is to use such methods to help domain experts (such as physicians) access and make sense of unstructured biomedical evidence.  More specifically, I will discuss models to automatically extract trial population characteristics (e.g., conditions), interventions/comparators (treatments), and outcomes studied in a given clinical trial; together these \"PICO\" elements compose well-formed clinical questions. I will then present ongoing work on corpora and models for inferring the comparative effectiveness of a given treatment, as compared to a specified comparator, and with respect to a particular outcome of interest. If successfully realized (a big if), such models would effectively facilitate real-time clinical question answering over reports of clinical trials, in turn enabling evidence-based care", "affiliation": "Northeastern University", "semester": "Fall", "speaker": "Byron Wallace", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-09-26", "video": "https://www.youtube.com/watch?v=qsw5QPtEwiU"}, {"website": "", "bio": "Ehi Nosakhare is an AI Data Scientist at Microsoft's New England Research and Development Center (NERD). She designs, develops and leads the implementation of machine learning solutions in application projects for Microsoft's products and services. In August 2018, she earned her Ph.D. in Electrical Engineering and Computer Science (EECS) from the Massachusetts Institute of Technology (MIT), Cambridge, MA. Her PhD research focused on probabilistic latent variable models and applying them to understand subjective well-being. She is generally interested in developing interpretable ML models and using these models to solve real world problems, as a result, she is curious about the ethical implications of AI/ML. Ehi got her S.M. in EECS from MIT, and graduated with a B.Sc. in Electrical Engineering, summa cum laude, from Howard University, Washington DC. As a student, she completed internships at Microsoft and IBM T. J. Watson Research Center. She is a recipient of a best paper award at the NeurIPS ML for Healthcare Workshop. In 2017, she was an organizer for the Women in Machine Learning (WiML) workshop, co-located with NeurIPS. Ehi has been honored as a Tau Beta Pi Scholar and Fellow. In her spare time, she enjoys reading and re-learning to play the cello.  ", "title": "Probabilistic Latent Variable Modeling for Predicting Future Well-Being and Assessing Behavioral Influences on Stress", "abstract": "Health research has an increasing focus on promoting well-being and positive mental health, to prevent disease and to more effectively treat disorders. The availability of rich multi-modal datasets and advances in machine learning methods are now enabling data science research to begin to objectively assess well-being. However, most existing studies focus on detecting the current state or predicting the future state of well-being using stand-alone health behaviors. There is a need for methods that can handle a complex combination of health behaviors, as arise in real-world data. Building on our previous work where we predict future well-being, in this talk, I'll present a framework to 1) map multi-modal messy data collected in the \"wild\" to meaningful feature representations of health behavior, 2) uncover latent patterns comprising multiple health behaviors that best predict well-being, and 3) propose how these patterns may be used to recommend healthy behaviors to participants. We show how to use supervised latent Dirichlet allocation (sLDA) to model the observed behaviors, and we apply variational inference to uncover the latent patterns. Implementing and evaluating the model on 5,397 days of data from a group of 244 college students, we find that these latent patterns are indeed predictive of self-reported stress, one of the largest components affecting well-being. We investigate the modifiable behaviors present in these patterns and uncover some ways in which the factors work together to influence well-being. This work contributes a new method using objective data analysis to help individuals monitor their well-being using real-world measurements. Insights from this study advance scientific knowledge on how combinations of daily modifiable human behaviors relate to human well-being.", "affiliation": "Microsoft NERD", "semester": "Fall", "speaker": "Ehimwenma Nosakhare", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-09-12", "video": "https://www.youtube.com/watch?v=KiAtYSRmVog"}, {"website": "http://irenechen.net/", "bio": "Irene Chen is a PhD student at MIT in Electrical Engineering and Computer Science in the Clinical Machine Learning Group. Her research focuses on building machine learning methods that to advance knowledge in health care and fairness. Before MIT, she received her AB/SM from Harvard in Applied Math and Computational Engineering and worked at Dropbox for two years as a Data Scientist, Machine Learning Engineer, and Chief of Staff.", "title": "Why is my classifier discriminatory?", "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.", "affiliation": "MIT CSAIL", "semester": "Spring", "speaker": "Irene Chen", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-21", "video": "https://www.youtube.com/watch?v=gbvloQN2NiA"}, {"website": "https://people.cs.umass.edu/~pat/", "bio": "Patrick Verga is a final year PhD candidate in the College of Information and Computer Sciences at UMass Amherst, advised by Andrew McCallum. His research contributes to knowledge representation and reasoning, with a focus on large knowledge base construction from unstructured text, with applications to general domain, commonsense, and biomedicine. Pat previously interned at Google and the Chan Zuckerberg Initiative and received the best long paper award at EMNLP 2018. Over the past several years he has advised multiple M.S. and junior PhD students, resulting in published research in fine-grained entity typing, unsupervised parsing, and partially labeled named entity extraction. He holds M.S. and B.A degrees in computer science as well as a B.S. in neuroscience.", "title": "Neural Knowledge Representation and Reasoning", "abstract": "Making complex decisions in science, government policy, finance, and clinical treatments all require integrating and reasoning over disparate sources of information. While some decisions can be made from a single piece of evidence, others require considering information that exists outside of the current context. A long-term store of abstracted knowledge over related concepts can facilitate this type of reasoning, while also influencing interpretation as well as enhancing the acquisition of new knowledge. A symbolic graph over a fixed, human-defined schema encoding facts about entities and their relations is the predominant method of representing knowledge, but this method is brittle, lacks specificity, and is inevitably highly incomplete. On the other extreme, recent work on purely text based knowledge models lack abstractions necessary for complex reasoning. In this talk I will present a middle ground incorporating powerful neural network models with rich structured ontologies and unstructured raw text to improve the representations of entities and their relations. We first discuss our work on universal schema, a method for learning a latent schema over both existing structured resources and unstructured free text data, embedding them jointly within a shared semantic space. Next we inject additional hierarchical structure into the embedding space of concepts, resulting in more efficient statistical sharing amongst related concepts and improving accuracy in both fine-grained entity typing and linking. We then present initial work to represent knowledge in context, including a single model for extracting all entities and long-range relations simultaneously over full paragraphs while jointly linking these entities to a knowledge graph. Lastly, we propose future directions for representing knowledge in context by incorporating cognitive theories of human memory systems and discuss how these models can address longstanding shortcomings in knowledge representation.", "affiliation": "UMass, Amherst", "semester": "Spring", "speaker": "Patrick Verga", "sponsor": "Oracle Labs", "year": "2019", "date": "2019-02-14", "video": "https://www.youtube.com/watch?v=BNQLWb4V7s0"}, {"website": "https://cs.brown.edu/people/epavlick/", "bio": "Ellie Pavlick is an Assistant Professor of Computer Science and Brown University and a Research Scientist at Google AI. Ellie received her PhD from University of Pennsylvania under the supervision of Chris Callison-Burch. Her current research focus is on semantics, pragmatics, and building cognitively-plausible computational models of natural language inference.", "title": "Why should we care about linguistics?", "abstract": "In just the past few months, a flurry of adversarial studies have pushed back on the apparent progress of neural networks, with multiple analyses suggesting that deep models of text fail to capture even basic properties of language, such as negation, word order, and compositionality. Alongside this wave of negative results, our field has stated ambitions to move beyond task-specific models and toward \"general purpose\" word, sentence, and even document embeddings. This is a tall order for the field of NLP, and, I argue, marks a significant shift in the way we approach our research. I will discuss what we can learn from the field of linguistics about the challenges of codifying all of language in a \"general purpose\" way. Then, more importantly, I will discuss what we cannot learn from linguistics. I will argue that the state-of-the-art of NLP research is operating close to the limits of what we know about natural language semantics, both within our field and outside it. I will conclude with thoughts on why this opens opportunities for NLP to advance both technology and basic science as it relates to language, and the implications for the way we should conduct empirical research.", "affiliation": "Brown University", "semester": "Fall", "speaker": "Ellie Pavlick", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-24", "video": "https://www.youtube.com/watch?v=PDi1z9sb_Z0"}, {"website": "https://people.csail.mit.edu/junyanz/", "bio": "Jun-Yan Zhu is a postdoctoral researcher at MIT CSAIL. He obtained his Ph.D. in Electrical Engineering and Computer Sciences from UC Berkeley in 2017 after spending five years at CMU and UC Berkeley. He received his B.E in Computer Sciences from Tsinghua University in 2012. His research interests are in computer vision, computer graphics, and machine learning, with the goal of building machines capable of understanding and recreating our visual world. His Ph.D. work was supported by a Facebook Fellowship. His dissertation won the 2018 ACM SIGGRAPH Outstanding Doctoral Dissertation Award from SIGGRAPH and 2017-18 David J. Sakrison Memorial Prize for outstanding doctoral research from the UC Berkeley EECS Department. He has served as a Technical Paper Committee member at SIGGRAPH Asia 2018 and a guest editor of International Journal of Computer Vision.", "title": "Learning to Generate Images", "abstract": "Deep learning has revolutionized the field of visual recognition. Since 2012, we witnessed an enormous jump in recognition performance on the standard benchmarks as well as many real-world applications. Meantime, many people in computer vision and graphics were wondering if deep learning can help visual synthesis. Unfortunately, it turned out that using deep neural networks to generate high-dimensional data such as images was extremely difficult. In this talk, I will discuss its main challenges and present a few end-to-end learning frameworks (e.g., pix2pix, CycleGAN, pix2pixHD) for generating and manipulating natural images. Then, I will show various applications such as generating synthetic training data (computer vision), photo manipulation and synthesis (computer graphics), converting MRIs into CT scans (medical imaging), and applications in NLP and speech synthesis. Finally, I will briefly discuss our ongoing efforts on learning to synthesize 3D textured objects and high-res videos, with the ultimate goal of recreating our visual world.", "affiliation": "MIT", "semester": "Fall", "speaker": "Jun-Yan Zhu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-10-04", "video": "https://www.youtube.com/watch?v=0jVcWgTxfTc"}, {"website": "http://www.cs.uml.edu/~arogers/", "bio": "Anna is a post-doctoral associate in the Computer Science Department at Text Machine lab, University of Massachusetts (Lowell). She works at the intersection of linguistics, natural language processing, and machine learning. She holds a Ph.D. degree from the Department of Language and Information Sciences at the University of Tokyo (Japan). Her current research focuses on interpretability of deep learning, evaluation of distributional meaning representations, and semantic compositionality. She also leads annotation projects for sentiment analysis and temporal reasoning. ", "title": "What's in your embedding, and how it predicts task performance", "abstract": "Word embeddings are the most widely used kind of distributional meaning representations in both industrial and academic NLP systems, and they can make dramatic difference in the performance of the system. However, the absence of a reliable intrinsic evaluation metric makes it hard to choose between dozens of models and their parameters. This work presents Linguistic Diagnostics (LD), a new methodology for evaluation, error analysis and development of word embedding models that is implemented in an open-source Python library. In a large-scale experiment with 14 datasets LD successfully highlights the differences in the output of GloVe and word2vec algorithms that correlate with their performance on different NLP tasks.", "affiliation": "UMass Lowell", "semester": "Fall", "speaker": "Anna Rogers", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-27", "video": "https://www.youtube.com/watch?v=heKsgZSOB1Q"}, {"website": "https://mymakar.github.io/", "bio": "Maggie Makar is a graduate student at CSAIL, MIT. She works on developing models and inference tools to analyze interaction data (e.g., interactions on social networks and diffusion of contagions). She focuses on untangling causal mechanisms that govern diffusion dynamics and quantifying heterogeneous effects of interventions in connected communities. She received her BA in Mathematics and Economics from the University of Massachusetts in Amherst.", "title": "Spread of contagions in the presence of latent spreaders: identifying hidden culprits and learning the probability of infection", "abstract": "When an infection spreads in a community, an individual's probability of becoming infected depends on both her susceptibility and exposure to the contagion through contact with others. While one often has knowledge regarding an individual's susceptibility, in many cases, whether or not an individual's contacts are contagious is unknown. We study the problem of predicting if an individual will adopt a contagion in the presence of multiple modes of infection (exposure/susceptibility) and latent neighbor influence. We present a generative probabilistic model and a variational inference method to learn the parameters of our model. Through a series of experiments on synthetic data, we measure the ability of the proposed model to identify latent spreaders, and predict the risk of infection. Applied to a real dataset of 20 thousand hospital patients, we demonstrate the utility of our model in predicting the onset of a healthcare associated infection using patient room-sharing and nurse-sharing networks. Our model outperforms existing benchmarks and provides actionable insights for the design and implementation of targeted interventions to curb the spread of the infection.", "affiliation": "MIT", "semester": "Fall", "speaker": "Maggie Makar", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-20", "video": "https://www.youtube.com/watch?v=MhQ7iOlT4aE"}, {"website": "https://www.eecs.tufts.edu/~liulp/", "bio": "Liping Liu holds the position of \"The Schwartz Family Assistant Professor'' at Tufts University. His research interests include variational inference, generative models, and embedding models. Prior to joining Tufts, Liu worked as a postdoctoral associate at Columbia University. Advised by Prof. David Blei, he worked on probabilistic embedding models. He earned his doctorate degree at Oregon State University, where he studied probabilistic models and applied these techniques to ecology studies. He also has industry experiences at IBM T.J. Watson Research and Alibaba. He is a reviewer for main machine learning conferences and journals, such as ICML, NIPS, ICLR, AISTATS, JMLR, and TPAMI.", "title": "Embedding: Choose Right Relations to Embed", "abstract": "Word embeddings are a widely-used tool to analyze language. Exponential family embeddings generalize the technique to other types of data by modeling the conditional probability of a target observation (a word or an item) conditioned on the elements in the context (other words or items). One challenge to fitting embedding methods is sparse data, such as a document/term matrix that contains many zeros. We develop zero-inflated embeddings to address this issue. In a zero-inflated embedding (ZIE), a zero in the data can come from an interaction to other data (i.e., an embedding) or from a separate process by which many observations are equal to zero (i.e. a probability mass at zero). Fitting a ZIE naturally down-weights the zeros and dampens their influence on the model. Another challenge is that the appear-to-be context often contains unrelated items. The embedding model considering all context elements will encode noisy co-occurrences as item relations in the embedding. We improve the quality of the embedding representations by choosing a subset of context elements for the embedding model. We develop a probabilistic attention model and use amortized variational inference to automatically choose this subset. ", "affiliation": "Tufts", "semester": "Fall", "speaker": "Liping Liu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-09-13", "video": "https://www.youtube.com/watch?v=hJ8TE5zudUw"}, {"website": "https://maithraraghu.com/", "bio": "Maithra Raghu is a PhD student at Cornell, working with Jon Kleinberg, and a research resident at Google Brain. Her research interests are broadly in developing a better understanding of latent representations learned by deep neural networks, and using these insights to help guide new improvements. ", "title": "Insights from Deep Representations", "abstract": "To continue the successes of deep learning, it becomes increasingly important to better understand the phenomena exhibited by these models, ideally through a combination of systematic experiments and theory. Central to this challenge is a better understanding of deep representations. In this talk I discuss some of our work addressing questions in this space. I overview our development of measures of neural network expressivity, and quantify and empirically measure the effect of network depth and width on the latent representations. I then describe adapting Canonical Correlation Analysis (SVCCA) as a tool to directly compare latent representations, across layers, training steps, and even different networks. The results show differences in per-layer convergence and also help identify parts of the representation critical to the task. Finally, I introduce a new testbed of environments for Deep Reinforcement Learning that lets us study different RL algorithms, single agent, multiagent and self play settings, and evaluate generalization in a systematic way. ", "affiliation": "Cornell", "semester": "Spring", "speaker": "Maithra Raghu", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-04-10", "video": "https://www.youtube.com/watch?v=gCia3v5Niig"}, {"website": "https://adjidieng.github.io/", "bio": "Adji Bousso Dieng is a PhD student at Columbia University where she works with David Blei and John Paisley. Her work at Columbia is about combining probabilistic graphical modeling and deep learning to design better sequence models. She develops these models within the framework of variational inference which enables efficient and scalable learning. Her hope is that her research can be applied to many real world applications particularly to natural language understanding.  Prior to joining Columbia, she worked as a Junior Professional Associate at the World Bank. She did her undergraduate training in France where she attended Lycee Henri IV and Telecom ParisTech---France's Grandes Ecoles system. She holds a Diplome d'Ingenieur from Telecom ParisTech and spent the third year of Telecom ParisTech's curriculum at Cornell University where she earned a Master in Statistics.  Learn more on her homepage http://stat.columbia.edu/~diengadji/ ", "title": "Deep Sequence Models: Context Representation, Regularization, and Application to Language", "abstract": "Recurrent Neural Networks (RNNs) are the most successful models for sequential data. They have achieved state-of-the-art results in many tasks including language modeling, image and text generation, speech recognition, and machine translation. Despite all these successes, RNNs still face some challenges: they fail to capture long-term dependencies (don't believe the myth that they do!) and they easily overfit.  The ability to capture long-term dependencies in sequential data depends on the way context is represented. Theoretically, RNNs capture all the dependencies in the sequence via the use of recurrence and parameter sharing. However practically, RNNs face optimization issues. Assumptions made to counter these optimization challenges hinder the capability of RNNs to capture long-term dependencies. On the other hand, the overfitting problem of RNNs stem from the strong dependence of the hidden units to each other.  I will talk about my research on context representation and regularization for RNNs. First, I will make the case that in the context of language, topic models are very effective at representing context and can be used jointly with RNNs to facilitate learning and capture long-term dependencies. Second, I will discuss our new proposed method to regularize RNNs called NOISIN. NOISIN relies on the concept of unbiased noise injection in the hidden units of RNNs to reduce co-adaptation. It significantly improves the generalization capabilities of existing RNN-based models including RNNs with dropout. ", "affiliation": "Columbia", "semester": "Spring", "speaker": "Adji Dieng", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-15", "video": "https://www.youtube.com/watch?v=0nj1hD4-9gE"}, {"website": "http://home.bharathh.info/", "bio": "Bharath Hariharan is an assistant professor at Cornell. Before joining Cornell, he spent two years as a postdoc in Facebook AI Research after obtaining a PhD from UC Berkeley with Jitendra Malik. At Berkeley, he was the recepient of the Microsoft Research fellowship. His interests are in all things visual recognition. Of late, he has become bothered by the reliance on massive labeled datasets and the scalability of such datasets to harder problems such as visual reasoning. His current work is on building recognition systems that learn with less data and / or output a much deeper understanding of images.", "title": "Visual recognition beyond large labeled training sets", "abstract": "The performance of recognition systems has grown by leaps and bounds these last 5 years. However, modern recognition systems still require thousands of examples per class to train. Furthermore, expanding the capabilities of the system by introducing new visual concepts again requires collecting thousands of examples for the new concept. In contrast, humans are known to quickly learn new visual concepts from as few as 1 example, and indeed require very little labeled data to build their powerful visual systems from scratch. The requirement for large training sets also makes it infeasible to use current machine vision systems for rare or hard-to-annotate visual concepts or new imaging modalities.  I will talk about some of our work on reducing this need for large labeled training sets. I will describe novel loss functions for training convolutional network-based feature representations so that new concepts can be learned from a few examples, and ways of hallucinating additional examples for data-starved classes. I will also discuss our attempt to learn feature representations without any labeled data by leveraging motion-based grouping cues. I will end with a discussion of where we are and thoughts on the way forward. ", "affiliation": "Cornell", "semester": "Spring", "speaker": "Bharath Hariharan", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-08", "video": "https://www.youtube.com/watch?v=rBrstWqWzbc"}, {"website": "http://www.phontron.com/", "bio": "Graham Neubig is an assistant professor at the Language Technologies Institute of Carnegie Mellon University. His work focuses on natural language processing, specifically multi-lingual models that work in many different languages, and natural language interfaces that allow humans to communicate with computers in their own language. Much of this work relies on machine learning to create these systems from data, and he is also active in developing methods and algorithms for machine learning over natural language data. He publishes regularly in the top venues in natural language processing, machine learning, and speech, and his work occasionally wins awards such as best papers at EMNLP, EACL, and WNMT. He is also active in developing open-source software, and is the main developer of the DyNet neural network toolkit.", "title": "What Can Neural Networks Teach us about Language?", "abstract": "Neural networks have led to large improvements in the accuracy of natural language processing systems. These have mainly been based on supervised learning: we create linguistic annotations for a large amount of training data, and train networks to faithfully reproduce these annotations. But what if we didn't tell the neural net about explicitly, but instead *asked it what it thought* about language without injecting our prior biases? Would the neural network be able to learn from large amounts of data and confirm or discredit our existing linguistic hypotheses? Would we be able to learn linguistic information from lower-resourced languages where this information has not been annotated? In this talk I will discuss methods for unsupervised learning of linguistic information using neural networks that attempt to answer these questions. I will also explain briefly about automatic mini-batching, a computational method (implemented in the DyNet neural network toolkit), which greatly speeds large-scale experiments with complicated network structures needed for this type of unsupervised learning.", "affiliation": "CMU", "semester": "Spring", "speaker": "Graham Neubig", "sponsor": "Oracle Labs", "year": "2018", "date": "2018-02-01", "video": "https://www.youtube.com/watch?v=D0TEo_5EdWY"}, {"website": "http://www.ccs.neu.edu/home/luwang/", "bio": "Lu Wang is an Assistant Professor in College of Computer and Information Science at Northeastern University since 2015. She received her Ph.D. in Computer Science from Cornell University and her bachelor degrees in Intelligence Science and Technology and Economics from Peking University. Her research mainly focuses on designing machine learning algorithms and statistical models for natural language processing (NLP) tasks, including abstractive text summarization, language generation, argumentation mining, information extraction, and their applications in interdisciplinary subjects (e.g., computational social science). Lu and her collaborators received an outstanding short paper award at ACL 2017 and a best paper nomination award at SIGDIAL 2012. Her group's work is funded by National Science Foundation (NSF), Intelligence Advanced Research Projects Activity (IARPA), and several industry gifts (Toutiao AI Lab, and NVIDIA GPU program). More information about her research can be found at www.ccs.neu.edu/home/luwang/.", "title": "What Makes a Good Argument: Understanding and Predicting High Quality Arguments Using NLP Methods", "abstract": "Debate and deliberation play essential roles in politics and civil discourse. While argument content and linguistic style both affect debate outcomes, limited work has been done on studying the interplay between the two. In the first part of this talk, I will present a joint model that estimates the inherent persuasive strengths of different topics, the effects of numerous linguistic features, and the interactions between the two as they affect debate audience. By experimenting with Oxford-style debates, our model predicts audience-adjudicated winners with 74% accuracy, significantly outperforming models based on linguistic features alone. We also find that winning sides employ more strong arguments (as corroborated by human judgment) and debaters all tend to shift topics to stronger ground. The model further allows us to identify the linguistic features associated with strong or weak arguments.  In the second part of my talk, I will present our recent study on retrieving diverse types of supporting arguments from relevant documents for user-specified topics. We find that human writers often use different types of arguments to promote persuasiveness, which can be characterized with different linguistic features. We then show how to leverage argument type to assist the task of supporting argument detection. I will also discuss our follow-up work on automatic argument generation. ", "affiliation": "Northeastern", "semester": "Fall", "speaker": "Lu Wang", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-11-09", "video": "https://www.youtube.com/watch?v=JviDF2VasLc"}, {"website": "http://www.kyunghyuncho.me/", "bio": "Kyunghyun Cho is an assistant professor of computer science and data science at New York University. He was a postdoctoral fellow at University of Montreal until summer 2015, and received PhD and MSc degrees from Aalto University early 2014. He tries best to find a balance among machine learning, natural language processing and life, but often fails to do so.", "title": "Deep Learning, Where are you going?", "abstract": "There are three axes along which advances in machine learning and deep learning happen. They are (1) network architectures, (2) learning algorithms and (3) spatio-temporal abstraction. In this talk, I will describe a set of research topics I've pursued in each of these axes. For network architectures, I will describe how recurrent neural networks, which were largely forgotten during 90s and early 2000s, have evolved over time and have finally become a de facto standard in machine translation. I continue on to discussing various learning paradigms, how they related to each other, and how they are combined in order to build a strong learning system. Along this line, I briefly discuss my latest research on designing a query-efficient imitation learning algorithm for autonomous driving. Lastly, I present my view on what it means to be a higher-level learning system. Under this view each and every end-to-end trainable neural network serves as a module, regardless of how they were trained, and interacts with each other in order to solve a higher-level task. I will describe my latest research on trainable decoding algorithm as a first step toward building such a framework.", "affiliation": "NYU", "semester": "Fall", "speaker": "Kyunghyun Cho", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-20", "video": "https://www.youtube.com/watch?v=3B5Ty5VD-5Q"}, {"website": "https://varunjampani.github.io/", "bio": "Varun Jampani works as a research scientist at Nvidia Research in Westford, US. He obtained his PhD at Max Planck Institute for Intelligent Systems (MPI) in T\u00fcbingen, Germany under the supervision of Prof. Peter V. Gehler. He works in the areas of machine learning and computer vision and his main research interests include probabilistic inference and neural networks. He obtained his BTech and MS from International Institute of Information Technology, Hyderabad (IIIT-H), India, where he was a gold medalist. During his studies, he did internships at Microsoft research institutes in Redmond (US), Cambridge (UK) and Cairo (Egypt); MPI, T\u00fcbingen (Germany) and; GE global research, Bangalore (India). He also worked as a volunteer teacher in Tibetan Children\u2019s Village, Dharamsala, India.", "title": "Bilateral Neural Networks for Image, Video and 3D Vision", "abstract": "Natural images exhibit high information correlation across pixels. Bilateral filtering provides a simple yet powerful framework for information propagation across pixels. The common use-case is to manually choose a parametric filter type, usually a Gaussian filter. We generalize the parameterization using a high-dimensional linear approximation and derive a gradient descent algorithm so the filter parameters can be learned from data. We demonstrate the use of learned bilateral filters in several applications where Gaussian bilateral filters are traditionally employed where we consistently observed improvements with filter learning. In addition, the ability to learn generic high-dimensional sparse filters allows us to stack several parallel and sequential filters like in convolutional neural networks (CNN) resulting in a new breed of neural networks which we call \u2018Bilateral Neural Networks\u2019 (BNN). We demonstrate the use of BNNs on several 2D, video and 3D vision tasks. Experiments on diverse datasets and tasks demonstrate the use BNNs for a range of vision problems.", "affiliation": "Nvidia", "semester": "Fall", "speaker": "Varun Jampani", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-12", "video": "https://www.youtube.com/watch?v=6LIcXwhOrGY"}, {"website": "http://francesco.orabona.com/", "bio": "Francesco Orabona is an Assistant Professor at Stony Brook University. His research interests are in the area of theoretically motivated and efficient machine learning algorithms, with emphasis on online and stochastic methods. He received the PhD degree in Electrical Engineering at the University of Genoa, in 2007. He is (co)author of more than 60 peer reviewed papers.", "title": "Coin Betting for Backprop without Learning Rates and More", "abstract": "Deep learning methods achieve state-of-the-art performance in many application scenarios. Yet, these methods require a significant amount of hyperparameters tuning in order to achieve the best results. In particular, tuning the learning rates in the stochastic optimization process is still one of the main bottlenecks. In this talk, I will propose a new stochastic gradient descent procedure that does not require any learning rate setting. Contrary to previous methods, we do not adapt the learning rates nor we make use of the assumed curvature of the objective function. Instead, we reduce the optimization process to a game of betting on a non-stochastic coin and we propose an optimal strategy based on a generalization of Kelly betting. Moreover, this reduction can be also used for other machine learning problems. Theoretical convergence is proven for convex and quasi-convex functions and empirical evidence shows the advantage of our algorithm over popular stochastic gradient algorithms.", "affiliation": "Stony Brook", "semester": "Fall", "speaker": "Francesco Orabona", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-10-05", "video": "https://www.youtube.com/watch?v=61o-TMEcDMM"}, {"website": "http://www.cs.umd.edu/~yogarshi/", "bio": "Yogarshi Vyas is a fourth year PhD student in the Department of Computer Science at the University of Maryland, College Park. His broad research interests lie in semantics, multilingual NLP, and machine translation, and the intersection of these. His current research focus is on comparing and contrasting the meaning of text in different languages using the idea of entailment as well as learning representations for multilingual data that facilitate meaningful and easy comparisons across languages. He recently won the Adam Kilgarriff Best Paper award at *SEM 2017.", "title": "Detecting Asymmetric Semantic Relations in Context : A Case-Study on Hypernymy Detection", "abstract": "Comparing the meaning of words and understanding how they relate is a fundamental challenge in natural language understanding. In this talk, I\u2019ll introduce WHiC, a challenging testbed for detecting hypernymy, an asymmetric relation between words. While previous work has focused on detecting hypernymy between word types, we ground the meaning of words in specific contexts drawn from WordNet examples, and require predictions to be sensitive to changes in contexts. WHiC also lets us analyze different properties of two approaches of inducing vector representations of word meaning in context, allowing us to identify their strengths and weaknesses. I\u2019ll also show that such contextualized word representations also improve detection of a wider range of semantic relations in context.", "affiliation": "UMD", "semester": "Fall", "speaker": "Yogarshi Vyas", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-21", "video": "https://www.youtube.com/watch?v=cEoqQQgyLuE"}, {"website": "http://people.math.umass.edu/~flaherty/?_ga=2.230150364.1118255471.1504663390-490697572.1416926222", "bio": "Patrick Flaherty is a Professor in the Department of Mathematics & Statistics at UMass Amherst. He received his PhD in Electrical Engineering and Computer Science from the University of California, Berkeley and he was a postdoctoral scholar at Stanford University in the Department of Biochemistry. His research focuses on scalable, statistical methods for analyzing large genomic data sets.", "title": "A Nonparametric Bayesian Model for Single-cell Variant Calling", "abstract": "Advances in DNA sequencing technology have enabled surprising discoveries in basic science and novel diagnostics in personalized medicine. Recently, the ability to read the DNA sequence of a single cell has presented new statistical and computational challenges. We address the problem of calling single-nucleotide mutations in single-cell sequencing data. We present some results evaluating existing mutation calling algorithms on data generated from a single-cell sequence data simulator. We describe a nonparametric Bayesian generative model for combining single-cell and bulk DNA sequencing data, and we show preliminary results from this model.", "affiliation": "UMass", "semester": "Fall", "speaker": "Pat Flaherty", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-14", "video": "https://www.youtube.com/watch?v=hjnyoNZ1RQw"}, {"website": "https://www.deaneckles.com/", "bio": "Dean Eckles is a social scientist, statistician, and faculty at MIT. Dean is the KDD Career Development Professor in Communications and Technology, an assistant professor in the MIT Sloan School of Management, and affiliated faculty at the MIT Institute for Data, Systems & Society. He was previously a member of the Core Data Science team at Facebook. He studies how interactive technologies affect human behavior by mediating, amplifying, and directing social influence \u2014 and statistical methods to study these processes. Dean\u2019s empirical work uses large field experiments and observational studies. His research appears in the Proceedings of the National Academy of Sciences and other peer-reviewed journals and proceedings in statistics, computer science, and marketing. Dean holds degrees from Stanford University in philosophy (BA), cognitive science (BS, MS), statistics (MS), and communication (PhD).", "title": "Learning from many experiments using regularized instrumental variable methods: Applications to peer effects in online networks", "abstract": "The widespread adoption of randomized experiments (i.e. A/B tests) in the Internet industry means that there are often numerous well-powered experiments on a given product. Individual experiments are often simple \"bake-off\" evaluations of a new intervention: They allow us to estimate effects of that particular intervention on outcomes of interest, but they are often not informative about the mechanisms for these effects or what other inventions might do. We consider what else we can learn from a large set of experiments. In particular, we use many experiments to learn about the effects of the various endogenous variables (or mechanisms) via which the experiments affect outcomes. This involves treating the experiments as instrumental variables, and so this setting is similar to, but somewhat different from, \"many instrument\" settings in econometrics and biostatistics. Motivated by the distribution of experiment first-stage effects, we present and evaluate sparsity-inducing regularization methods and cross-validation for instrumental variables. Our applications are to estimating peer effects in online social networks mediated by ranking systems.  Joint work with Alex Peysakhovich (Facebook) and including additional joint work with Eytan Bakshy (Facebook) and Ren\u00e9 Kizilcec (Stanford). ", "affiliation": "MIT", "semester": "Fall", "speaker": "Dean Eckles", "sponsor": "Oracle Labs", "year": "2017", "date": "2017-09-07", "video": "https://www.youtube.com/watch?v=grDtaryIU60"}]}